[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to Data Science with Python",
    "section": "",
    "text": "Preface\nThis book is developed for the course STAT303-1 (Data Science with Python-1). The first two chapters of the book are a review of python, and will be covered very quickly. Students are expected to know the contents of these chapters beforehand, or be willing to learn it quickly. Students may use the STAT201 book (https://nustat.github.io/Intro_to_programming_for_data_sci/) to review the python basics required for the STAT303 sequence. The core part of the course begins from the third chapter - Reading data.\nPlease feel free to let the instructors know in case of any typos/mistakes/general feedback in this book."
  },
  {
    "objectID": "Introduction to Python and Jupyter Notebooks.html#python-language-basics",
    "href": "Introduction to Python and Jupyter Notebooks.html#python-language-basics",
    "title": "1  Python Basics",
    "section": "1.1 Python language basics",
    "text": "1.1 Python language basics\n\n1.1.1 Object Oriented Programming\nPython is an object-oriented programming language. In layman terms, it means that every number, string, data structure, function, class, module, etc., exists in the python interpreter as a python object. An object may have attributes and methods associated with it. For example, let us define a variable that stores an integer:\n\nvar = 2\n\nThe variable var is an object that has attributes and methods associated with it. For example a couple of its attributes are real and imag, which store the real and imaginary parts respectively, of the object var:\n\nprint(\"Real part of 'var': \",var.real)\nprint(\"Real part of 'var': \",var.imag)\n\nReal part of 'var':  2\nReal part of 'var':  0\n\n\nAttribute: An attribute is a value associated with an object, defined within the class of the object.\nMethod: A method is a function associated with an object, defined within the class of the object, and has access to the attributes associated with the object.\nFor looking at attributes and methods associated with an object, say obj, press tab key after typing obj..\nConsider the example below of a class example_class:\n\nclass example_class:\n    class_name = 'My Class'\n    def my_method(self):\n        print('Hello World!')\n\ne = example_class()\n\nIn the above class, class_name is an attribute, while my_method is a method.\n\n\n1.1.2 Assigning variable name to object\n\n1.1.2.1 Call by reference\nPython utilizes a system, which is known as Call by Object Reference. When an object is assigned to a variable name, the variable name serves as a reference to the object. For example, consider the following assignment:\n\nx = [5,3]\n\nThe variable name x is a reference to the memory location where the object [5, 3] is stored. Now, suppose we assign x to a new variable y:\n\ny = x\n\nIn the above statement the variable name y now refers to the same object [5,3]. The object [5,3] does not get copied to a new memory location referred by y. To prove this, let us add an element to y:\n\ny.append(4)\nprint(y)\n\n[5, 3, 4]\n\n\n\nprint(x)\n\n[5, 3, 4]\n\n\nWhen we changed y, note that x also changed to the same object, showing that x and y refer to the same object, instead of referring to different copies of the same object.\n\n\n1.1.2.2 Assigning multiple variable names\nValues can be assigned to multiple variables in a single statement by separating the variable names and values with commas.\n\ncolor1, color2, color3 = \"red\", \"green\", \"blue\"\n\n\ncolor1\n\n'red'\n\n\n\ncolor3\n\n'blue'\n\n\nThe same value can be assigned to multiple variables by chaining multiple assignment operations within a single statement.\n\ncolor4 = color5 = color6 = \"magenta\"\n\n\n\n1.1.2.3 Rules for variable names\nVariable names can be short (a, x, y, etc.) or descriptive ( my_favorite_color, profit_margin, the_3_musketeers, etc.). However, we recommend that you use descriptive variable names as it makes it easier to understand the code.\nThe rules below must be followed while naming Python variables:\n\nA variable’s name must start with a letter or the underscore character _. It cannot begin with a number.\nA variable name can only contain lowercase (small) or uppercase (capital) letters, digits, or underscores (a-z, A-Z, 0-9, and _).\nVariable names are case-sensitive, i.e., a_variable, A_Variable, and A_VARIABLE are all different variables.\n\nHere are some valid variable names:\n\na_variable = 23\nis_today_Saturday = False\nmy_favorite_car = \"Delorean\"\nthe_3_musketeers = [\"Athos\", \"Porthos\", \"Aramis\"] \n\nLet’s try creating some variables with invalid names. Python prints a syntax error if the variable’s name is invalid.\n\nSyntax: The syntax of a programming language refers to the rules that govern the structure of a valid instruction or statement. If a statement does not follow these rules, Python stops execution and informs you that there is a syntax error. Syntax can be thought of as the rules of grammar for a programming language.\n\n\na variable = 23\n\n\nis_today_$aturday = False\n\n\nmy-favorite-car = \"Delorean\"\n\n\n3_musketeers = [\"Athos\", \"Porthos\", \"Aramis\"]\n\n\n\n\n1.1.3 Built-in objects\n\n1.1.3.1 Built-in data types\nVariable is created as soon as a value is assigned to it. We don’t have to define the type of variable explicitly as in other programming languages because Python can automatically guess the type of data entered (dynamically typed).\nAny data or information stored within a Python variable has a type. We can view the type of data stored within a variable using the type function.\n\na_variable\n\n23\n\n\n\ntype(a_variable)\n\nint\n\n\n\nis_today_Saturday\n\nFalse\n\n\n\ntype(is_today_Saturday)\n\nbool\n\n\n\nmy_favorite_car\n\n'Delorean'\n\n\n\ntype(my_favorite_car)\n\nstr\n\n\n\nthe_3_musketeers\n\n['Athos', 'Porthos', 'Aramis']\n\n\n\ntype(the_3_musketeers)\n\nlist\n\n\nPython has several built-in data types for storing different kinds of information in variables.\n\n\n\n\n\nPrimitive: Integer, float, boolean, None, and string are primitive data types because they represent a single value.\nContainers: Other data types like list, tuple, and dictionary are often called data structures or containers because they hold multiple pieces of data together. We’ll discuss these datatypes in chapter 2.\nThe data type of the object can be identified using the in-built python function type(). For example, see the following objects and their types:\n\ntype(4)\n\nint\n\n\n\ntype(4.4)\n\nfloat\n\n\n\ntype('4')\n\nstr\n\n\n\ntype(True)\n\nbool\n\n\n\n\n1.1.3.2 Built-in modules and functions\nBuilt-in functions in Python are a set of predefined functions that are available for use without the need to import any additional libraries or modules. The Python Standard Library is very extensive. Besides built-in functions, it also contains many Python scripts (with the . py extension) containing useful utilities and modules written in Python that provide standardized solutions for many problems that occur in everyday programming.\nBelow are a couple of examples:\nrange(): The range() function returns a sequence of evenly-spaced integer values. It is commonly used in for loops to define the sequence of elements over which the iterations are performed.\nBelow is an example where the range() function is used to create a sequence of whole numbers upto 10:\n\nprint(list(range(1,10)))\n\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\nThe advantage of the range type over a regular list or tuple is that a range object will always take the same (small) amount of memory, no matter the size of the range it represents (as it only stores the start, stop and step values, calculating individual items and subranges as needed).\nDate time: Python as a built-in datetime module for handling date/time objects:\n\nimport datetime as dt\n\n\n#Defining a date-time object \ndt_object = dt.datetime(2022, 9, 20, 11,30,0)\n\nInformation about date and time can be accessed with the relevant attribute of the datetime object.\n\ndt_object.day\n\n20\n\n\n\ndt_object.year\n\n2022\n\n\nThe strftime method of the datetime module formats a datetime object as a string. There are several types of formats for representing date as a string:\n\ndt_object.strftime('%m/%d/%Y')\n\n'09/20/2022'\n\n\n\ndt_object.strftime('%m/%d/%y %H:%M')\n\n'09/20/22 11:30'\n\n\n\ndt_object.strftime('%h-%d-%Y')\n\n'Sep-20-2022'\n\n\n\n\n\n1.1.4 Importing libraries\nThere are several built-in functions in python like print(), abs(), max(), sum() etc., which do not require importing any library. However, these functions will typically be insufficient for a analyzing data. Some of the popular libraries and their primary purposes are as follows:\n\nNumPy: NumPy is a fundamental library for numerical computing in Python. It provides support for arrays, matrices, and mathematical functions, making it essential for scientific and data analysis tasks.. It is mostly used for performing numerical operations and efficiently storing numerical data.\nPandas: Pandas is a powerful data manipulation and analysis library. It offers data structures like DataFrames and Series, which facilitate data reading, cleaning, transformation, and analysis, making it indispensable in data science projects.\nMatplotlib, Seaborn: Matplotlib is a comprehensive library for creating static, animated, or interactive plots and visualizations. It is commonly used for data visualization and exploration in data science. Seaborn is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.\nSciPy: SciPy is used for performing scientific computing such as solving differential equations, optimization, statistical tests, etc.\nScikit-learn: Scikit-learn is a machine learning library that provides a wide range of tools for data pre-procesing, classification, regression, clustering, dimensionality reduction, and more. It simplifies the implementation of machine learning algorithms and model evaluation.\nStatsmodels: Statsmodels is used for developing statistical models with a focus on inference (in contrast to focus on prediction as in scikit-learn).\n\nTo use libraries like NumPy, pandas, Matplotlib, and scikit-learn in Python, you typically need to follow these steps:\n\nInstall the libraries (Anaconda already does this)\nImport the libraries in the python script or jupyter notebook\nUse the Library Functions and Classes: After importing the libraries, you can use their functions, classes, and methods in your code. For instance, you can create NumPy arrays, manipulate data with pandas, create plots with Matplotlib, or train machine learning models with scikit-learn.\n\nA library can be imported using the import keyword. For example, a NumPy library can be imported as:\n\nimport numpy as np\n\nUsing the as keyboard, the NumPy library has been given the name np. All the functions and attributes of the library can be called using the ‘np.’ prefix. For example, let us generate a sequence of whole numbers upto 10 using the NumPy function arange():\n\nnp.arange(8)\n\narray([0, 1, 2, 3, 4, 5, 6, 7])\n\n\nThere’s different ways to import:\n\nImport the whole module using its original name:  import math, os\nImport specific things from the module:  from random import randint  from math import pi\nImport the whole library and rename it, usually using a shorter variable name:  import pandas as pd\nImport a specific method from the module and rename it as it is imported:  from os.path import join as join_path\n\n\n\n1.1.5 User-defined functions\nA function is a reusable set of instructions that takes one or more inputs, performs some operations, and often returns an output. Indeed, while python’s standard library and ecosystem libraries offer a wealth of pre-defined functions for a wide range of tasks, there are situations where defining your own functions is not just beneficial but necessary. \n\n1.1.5.1 Creating and using functions\nYou can define a new function using the def keyword.\n\ndef say_hello():\n    print('Hello there!')\n    print('How are you?')\n\nNote the round brackets or parentheses () and colon : after the function’s name. Both are essential parts of the syntax. The function’s body contains an indented block of statements. The statements inside a function’s body are not executed when the function is defined. To execute the statements, we need to call or invoke the function.\n\nsay_hello()\n\nHello there!\nHow are you?\n\n\n\ndef say_hello_to(name):\n    print('Hello ', name)\n    print('How are you?')\n\n\nsay_hello_to('Lizhen')\n\nHello  Lizhen\nHow are you?\n\n\n\nname = input ('Please enter your name: ')\nsay_hello_to(name)\n\nPlease enter your name: George\nHello  George\nHow are you?\n\n\n\n\n1.1.5.2 Variable scope: Local and global Variables\nLocal variable: When we declare variables inside a function, these variables will have a local scope (within the function). We cannot access them outside the function. These types of variables are called local variables. For example,\n\ndef greet(): \n    message = 'Hello'  # local variable\n    print('Local', message)\ngreet()\n\nLocal Hello\n\n\n\nprint(message) # try to access message variable outside greet() function\n\nNameError: name 'message' is not defined\n\n\nAs message was defined within the function greet(), it is local to the function, and cannot be called outside the function.\nGlobal variable: Aa variable declared outside of the function or in global scope is known as a global variable. This means that a global variable can be accessed inside or outside of the function.\nLet’s see an example of how a global variable is created.\n\nmessage = 'Hello'  # declare global variable\n\ndef greet():\n    print('Local', message)  # declare local variable\n\ngreet()\nprint('Global', message)\n\nLocal Hello\nGlobal Hello\n\n\n\n\n1.1.5.3 Named arguments\nInvoking a function with many arguments can often get confusing and is prone to human errors. Python provides the option of invoking functions with named arguments for better clarity. You can also split function invocation into multiple lines.\n\ndef loan_emi(amount, duration, rate, down_payment=0):\n    loan_amount = amount - down_payment\n    emi = loan_amount * rate * ((1+rate)**duration) / (((1+rate)**duration)-1)\n    return emi\n\n\nemi1 = loan_emi(\n    amount=1260000, \n    duration=8*12, \n    rate=0.1/12, \n    down_payment=3e5\n)\n\n\nemi1\n\n14567.19753389219\n\n\n\n\n1.1.5.4 Optional Arguments\nFunctions with optional arguments offer more flexibility in how you can use them. You can call the function with or without the argument, and if there is no argument in the function call, then a default value is used.\n\nemi2 = loan_emi(\n    amount=1260000, \n    duration=8*12, \n    rate=0.1/12)\n\nemi2\n\n19119.4467632335\n\n\n\n\n1.1.5.5 *args and **kwargs\nWe can pass a variable number of arguments to a function using special symbols. There are two special symbols:\n\nSpecial Symbols Used for passing arguments: 1. *args (Non-Keyword Arguments) 2. *kwargs (Keyword Arguments) &gt; Note: “We use the “wildcard” or “” notation like this – *args OR **kwargs – as our function’s argument when we have doubts about the number of arguments we should pass in a function.”\n\ndef myFun(*args,**kwargs):\n    print(\"args: \", args)\n    print(\"kwargs: \", kwargs)\n \n \n# Now we can use both *args ,**kwargs\n# to pass arguments to this function :\nmyFun('John',22,'cs',name=\"John\",age=22,major=\"cs\")\n\nargs:  ('John', 22, 'cs')\nkwargs:  {'name': 'John', 'age': 22, 'major': 'cs'}\n\n\n\n\n\n1.1.6 Branching and looping (control flow)\n\nAs in other languages, python has built-in keywords that provide conditional flow of control in the code.\n\n1.1.6.1 Branching with if, else and elif\nOne of the most powerful features of programming languages is branching: the ability to make decisions and execute a different set of statements based on whether one or more conditions are true.\nThe if statement\nIn Python, branching is implemented using the if statement, which is written as follows:\nif condition:\n    statement1\n    statement2\nThe condition can be a value, variable or expression. If the condition evaluates to True, then the statements within the if block are executed. Notice the four spaces before statement1, statement2, etc. The spaces inform Python that these statements are associated with the if statement above. This technique of structuring code by adding spaces is called indentation.\n\nIndentation: Python relies heavily on indentation (white space before a statement) to define code structure. This makes Python code easy to read and understand. You can run into problems if you don’t use indentation properly. Indent your code by placing the cursor at the start of the line and pressing the Tab key once to add 4 spaces. Pressing Tab again will indent the code further by 4 more spaces, and press Shift+Tab will reduce the indentation by 4 spaces.\n\nFor example, let’s write some code to check and print a message if a given number is even.\n\na_number = 34\n\n\nif a_number % 2 == 0:\n    print(\"We're inside an if block\")\n    print('The given number {} is even.'.format(a_number))\n\nWe're inside an if block\nThe given number 34 is even.\n\n\nThe else statement\nWe may want to print a different message if the number is not even in the above example. This can be done by adding the else statement. It is written as follows:\nif condition:\n    statement1\n    statement2\nelse:\n    statement4\n    statement5\n\nIf condition evaluates to True, the statements in the if block are executed. If it evaluates to False, the statements in the else block are executed.\n\nif a_number % 2 == 0:\n    print('The given number {} is even.'.format(a_number))\nelse:\n    print('The given number {} is odd.'.format(a_number))\n\nThe given number 34 is even.\n\n\nThe elif statement\nPython also provides an elif statement (short for “else if”) to chain a series of conditional blocks. The conditions are evaluated one by one. For the first condition that evaluates to True, the block of statements below it is executed. The remaining conditions and statements are not evaluated. So, in an if, elif, elif… chain, at most one block of statements is executed, the one corresponding to the first condition that evaluates to True.\n\ntoday = 'Wednesday'\n\n\nif today == 'Sunday':\n    print(\"Today is the day of the sun.\")\nelif today == 'Monday':\n    print(\"Today is the day of the moon.\")\nelif today == 'Tuesday':\n    print(\"Today is the day of Tyr, the god of war.\")\nelif today == 'Wednesday':\n    print(\"Today is the day of Odin, the supreme diety.\")\nelif today == 'Thursday':\n    print(\"Today is the day of Thor, the god of thunder.\")\nelif today == 'Friday':\n    print(\"Today is the day of Frigga, the goddess of beauty.\")\nelif today == 'Saturday':\n    print(\"Today is the day of Saturn, the god of fun and feasting.\")\n\nToday is the day of Odin, the supreme diety.\n\n\nIn the above example, the first 3 conditions evaluate to False, so none of the first 3 messages are printed. The fourth condition evaluates to True, so the corresponding message is printed. The remaining conditions are skipped. Try changing the value of today above and re-executing the cells to print all the different messages.\nUsing if, elif, and else together\nYou can also include an else statement at the end of a chain of if, elif… statements. This code within the else block is evaluated when none of the conditions hold true.\n\na_number = 49\n\n\nif a_number % 2 == 0:\n    print('{} is divisible by 2'.format(a_number))\nelif a_number % 3 == 0:\n    print('{} is divisible by 3'.format(a_number))\nelif a_number % 5 == 0:\n    print('{} is divisible by 5'.format(a_number))\nelse:\n    print('All checks failed!')\n    print('{} is not divisible by 2, 3 or 5'.format(a_number))\n\nAll checks failed!\n49 is not divisible by 2, 3 or 5\n\n\nNon-Boolean Conditions\nNote that conditions do not necessarily have to be booleans. In fact, a condition can be any value. The value is converted into a boolean automatically using the bool operator. Any value in Python can be converted to a Boolean using the bool function.\nOnly the following values evaluate to False (they are often called falsy values):\n\nThe value False itself\nThe integer 0\nThe float 0.0\nThe empty value None\nThe empty text \"\"\nThe empty list []\nThe empty tuple ()\nThe empty dictionary {}\nThe empty set set()\nThe empty range range(0)\n\nEverything else evaluates to True (a value that evaluates to True is often called a truthy value).\n\nif '':\n    print('The condition evaluted to True')\nelse:\n    print('The condition evaluted to False')\n\nThe condition evaluted to False\n\n\n\nif 'Hello':\n    print('The condition evaluted to True')\nelse:\n    print('The condition evaluted to False')\n\nThe condition evaluted to True\n\n\n\nif { 'a': 34 }:\n    print('The condition evaluted to True')\nelse:\n    print('The condition evaluted to False')\n\nThe condition evaluted to True\n\n\n\nif None:\n    print('The condition evaluted to True')\nelse:\n    print('The condition evaluted to False')\n\nThe condition evaluted to False\n\n\nNested conditional statements\nThe code inside an if block can also include an if statement inside it. This pattern is called nesting and is used to check for another condition after a particular condition holds true.\n\na_number = 15\n\n\nif a_number % 2 == 0:\n    print(\"{} is even\".format(a_number))\n    if a_number % 3 == 0:\n        print(\"{} is also divisible by 3\".format(a_number))\n    else:\n        print(\"{} is not divisibule by 3\".format(a_number))\nelse:\n    print(\"{} is odd\".format(a_number))\n    if a_number % 5 == 0:\n        print(\"{} is also divisible by 5\".format(a_number))\n    else:\n        print(\"{} is not divisibule by 5\".format(a_number))\n\n15 is odd\n15 is also divisible by 5\n\n\nNotice how the print statements are indented by 8 spaces to indicate that they are part of the inner if/else blocks.\n\nNested if, else statements are often confusing to read and prone to human error. It’s good to avoid nesting whenever possible, or limit the nesting to 1 or 2 levels.\n\nShorthand if conditional expression\nA frequent use case of the if statement involves testing a condition and setting a variable’s value based on the condition.\nPython provides a shorter syntax, which allows writing such conditions in a single line of code. It is known as a conditional expression, sometimes also referred to as a ternary operator. It has the following syntax:\nx = true_value if condition else false_value\nIt has the same behavior as the following if-else block:\nif condition:\n    x = true_value\nelse:\n    x = false_value\nLet’s try it out for the example above.\n\nparity = 'even' if a_number % 2 == 0 else 'odd'\n\n\nprint('The number {} is {}.'.format(a_number, parity))\n\nThe number 15 is odd.\n\n\nThe pass statement\nif statements cannot be empty, there must be at least one statement in every if and elif block. We can use the pass statement to do nothing and avoid getting an error.\n\na_number = 9\n\n\nif a_number % 2 == 0:\n    \nelif a_number % 3 == 0:\n    print('{} is divisible by 3 but not divisible by 2')\n\nIndentationError: expected an indented block (1562158884.py, line 3)\n\n\nAs there must be at least one statement withihng the if block, the above code throws an error.\n\nif a_number % 2 == 0:\n    pass\nelif a_number % 3 == 0:\n    print('{} is divisible by 3 but not divisible by 2'.format(a_number))\n\n9 is divisible by 3 but not divisible by 2\n\n\n\n\n1.1.6.2 Iteration with while loops\nAnother powerful feature of programming languages, closely related to branching, is running one or more statements multiple times. This feature is often referred to as iteration on looping, and there are two ways to do this in Python: using while loops and for loops.\nwhile loops have the following syntax:\nwhile condition:\n    statement(s)\nStatements in the code block under while are executed repeatedly as long as the condition evaluates to True. Generally, one of the statements under while makes some change to a variable that causes the condition to evaluate to False after a certain number of iterations.\nLet’s try to calculate the factorial of 100 using a while loop. The factorial of a number n is the product (multiplication) of all the numbers from 1 to n, i.e., 1*2*3*...*(n-2)*(n-1)*n.\n\nresult = 1\ni = 1\n\nwhile i &lt;= 10:\n    result = result * i\n    i = i+1\n\nprint('The factorial of 100 is: {}'.format(result))\n\nThe factorial of 100 is: 3628800\n\n\n\n\n1.1.6.3 Infinite Loops\nSuppose the condition in a while loop always holds true. In that case, Python repeatedly executes the code within the loop forever, and the execution of the code never completes. This situation is called an infinite loop. It generally indicates that you’ve made a mistake in your code. For example, you may have provided the wrong condition or forgotten to update a variable within the loop, eventually falsifying the condition.\nIf your code is stuck in an infinite loop during execution, just press the “Stop” button on the toolbar (next to “Run”) or select “Kernel &gt; Interrupt” from the menu bar. This will interrupt the execution of the code. The following two cells both lead to infinite loops and need to be interrupted.\n\n# INFINITE LOOP - INTERRUPT THIS CELL\n\nresult = 1\ni = 1\n\nwhile i &lt;= 100:\n    result = result * i\n    # forgot to increment i\n\n\n# INFINITE LOOP - INTERRUPT THIS CELL\n\nresult = 1\ni = 1\n\nwhile i &gt; 0 : # wrong condition\n    result *= i\n    i += 1\n\n\n\n1.1.6.4 break and continue statements\nIn Python, break and continue statements can alter the flow of a normal loop. \nWe can use the break statement within the loop’s body to immediately stop the execution and break out of the loop. with the continue statement. If the condition evaluates to True, then the loop will move to the next iteration.\n\ni = 1\nresult = 1\n\nwhile i &lt;= 100:\n    result *= i\n    if i == 42:\n        print('Magic number 42 reached! Stopping execution..')\n        break\n    i += 1\n    \nprint('i:', i)\nprint('result:', result)\n\nMagic number 42 reached! Stopping execution..\ni: 42\nresult: 1405006117752879898543142606244511569936384000000000\n\n\n\ni = 1\nresult = 1\n\nwhile i &lt; 8:\n    i += 1\n    if i % 2 == 0:\n        print('Skipping {}'.format(i))\n        continue\n    print('Multiplying with {}'.format(i))\n    result = result * i\n    \nprint('i:', i)\nprint('result:', result)\n\nSkipping 2\nMultiplying with 3\nSkipping 4\nMultiplying with 5\nSkipping 6\nMultiplying with 7\nSkipping 8\ni: 8\nresult: 105\n\n\nIn the example above, the statement result = result * i inside the loop is skipped when i is even, as indicated by the messages printed during execution.\n\nLogging: The process of adding print statements at different points in the code (often within loops and conditional statements) for inspecting the values of variables at various stages of execution is called logging. As our programs get larger, they naturally become prone to human errors. Logging can help in verifying the program is working as expected. In many cases, print statements are added while writing & testing some code and are removed later.\n\nTask: Guess the output and explain it.\n\n# Use of break statement inside the loop\n\nfor val in \"string\":\n    if val == \"i\":\n        break\n    print(val)\n\nprint(\"The end\")\n\ns\nt\nr\nThe end\n\n\n\n# Program to show the use of continue statement inside loops\n\nfor val in \"string\":\n    if val == \"i\":\n        continue\n    print(val)\n\nprint(\"The end\")\n\ns\nt\nr\nn\ng\nThe end\n\n\n\n\n1.1.6.5 Iteration with for loops\nA for loop is used for iterating or looping over sequences, i.e., lists, tuples, dictionaries, strings, and ranges. For loops have the following syntax:\nfor value in sequence:\n    statement(s)\nThe statements within the loop are executed once for each element in sequence. Here’s an example that prints all the element of a list.\n\ndays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n\nfor day in days:\n    print(day)\n\nMonday\nTuesday\nWednesday\nThursday\nFriday\n\n\n\n# Looping over a string\nfor char in 'Monday':\n    print(char)\n\nM\no\nn\nd\na\ny\n\n\n\n# Looping over a dictionary\nperson = {\n    'name': 'John Doe',\n    'sex': 'Male',\n    'age': 32,\n    'married': True\n}\n\nfor key, value in person.items():\n    print(\"Key:\", key, \",\", \"Value:\", value)\n\nKey: name , Value: John Doe\nKey: sex , Value: Male\nKey: age , Value: 32\nKey: married , Value: True\n\n\n\n\n\n1.1.7 Iterating using range and enumerate\nThe range function is used to create a sequence of numbers that can be iterated over using a for loop. It can be used in 3 ways:\n\nrange(n) - Creates a sequence of numbers from 0 to n-1\nrange(a, b) - Creates a sequence of numbers from a to b-1\nrange(a, b, step) - Creates a sequence of numbers from a to b-1 with increments of step\n\nLet’s try it out.\n\nfor i in range(4):\n    print(i)\n\n0\n1\n2\n3\n\n\n\nfor i in range(3, 8):\n    print(i)\n\n3\n4\n5\n6\n7\n\n\n\nfor i in range(3, 14, 4):\n    print(i)\n\n3\n7\n11\n\n\nRanges are used for iterating over lists when you need to track the index of elements while iterating.\n\na_list = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n\nfor i in range(len(a_list)):\n    print('The value at position {} is {}.'.format(i, a_list[i]))\n\nThe value at position 0 is Monday.\nThe value at position 1 is Tuesday.\nThe value at position 2 is Wednesday.\nThe value at position 3 is Thursday.\nThe value at position 4 is Friday.\n\n\nAnother way to achieve the same result is by using the enumerate function with a_list as an input, which returns a tuple containing the index and the corresponding element.\n\nfor i, val in enumerate(a_list):\n    print('The value at position {} is {}.'.format(i, val))\n\nThe value at position 0 is Monday.\nThe value at position 1 is Tuesday.\nThe value at position 2 is Wednesday.\nThe value at position 3 is Thursday.\nThe value at position 4 is Friday."
  },
  {
    "objectID": "data_structures.html#tuple",
    "href": "data_structures.html#tuple",
    "title": "2  Data structures",
    "section": "2.1 Tuple",
    "text": "2.1 Tuple\nTuple is a sequence of python objects, with two key characteristics: (1) the number of objects are fixed, and (2) the objects are immutable, i.e., they cannot be changed.\nTuple can be defined as a sequence of python objects separated by commas, and enclosed in rounded brackets (). For example, below is a tuple containing three integers.\n\ntuple_example = (2,7,4)\n\nWe can check the data type of a python object using the in-built python function type(). Let us check the data type of the object tuple_example.\n\ntype(tuple_example)\n\ntuple\n\n\n\n2.1.1 Tuple Indexing\nTuple is ordered, meaning you can access specific elements in a list using their index. Indexing in lists includes both positive indexing (starting from 0 for the first element) and negative indexing (starting from -1 for the last element).\n\nElements of a tuple can be extracted using their index within square brackets. For example the second element of the tuple tuple_example can be extracted as follows:\n\ntuple_example[1]\n\n7\n\n\n\ntuple_example[-1]\n\n4\n\n\nNote that an element of a tuple cannot be modified. For example, consider the following attempt in changing the second element of the tuple tuple_example.\n\ntuple_example[1] = 8\n\nTypeError: 'tuple' object does not support item assignment\n\n\nThe above code results in an error as tuple elements cannot be modified.\n\n\n2.1.2 Concatenating tuples\nTuples can be concatenated using the + operator to produce a longer tuple:\n\n(2,7,4) + (\"another\", \"tuple\") + (\"mixed\",\"datatypes\",5)\n\n(2, 7, 4, 'another', 'tuple', 'mixed', 'datatypes', 5)\n\n\nMultiplying a tuple by an integer results in repetition of the tuple:\n\n(2,7,\"hi\") * 3\n\n(2, 7, 'hi', 2, 7, 'hi', 2, 7, 'hi')\n\n\n\n\n2.1.3 Unpacking tuples\nIf tuples are assigned to an expression containing multiple variables, the tuple will be unpacked and each variable will be assigned a value as per the order in which it appears. See the example below.\n\nx,y,z  = (4.5, \"this is a string\", ((\"Nested tuple\",5)))\n\n\nx\n\n4.5\n\n\n\ny\n\n'this is a string'\n\n\n\nz\n\n('Nested tuple', 5)\n\n\nIf we are interested in retrieving only some values of the tuple, the expression *_ can be used to discard the other values. Let’s say we are interested in retrieving only the first and the last two values of the tuple:\n\nx,*_,y,z  = (4.5, \"this is a string\", ((\"Nested tuple\",5)),\"99\",99)\n\n\nx\n\n4.5\n\n\n\ny\n\n'99'\n\n\n\nz\n\n99\n\n\n\n\n2.1.4 Tuple methods\nA couple of useful tuple methods are count, which counts the occurrences of an element in the tuple and index, which returns the position of the first occurrence of an element in the tuple:\n\ntuple_example = (2,5,64,7,2,2)\n\n\ntuple_example.count(2)\n\n3\n\n\n\ntuple_example.index(2)\n\n0\n\n\nNow that we have an idea about tuple, let us try to think where it can be used."
  },
  {
    "objectID": "data_structures.html#list",
    "href": "data_structures.html#list",
    "title": "2  Data structures",
    "section": "2.2 List",
    "text": "2.2 List\nList is a sequence of python objects, with two key characeterisics that differentiates it from tuple: (1) the number of objects are variable, i.e., objects can be added or removed from a list, and (2) the objects are mutable, i.e., they can be changed.\nList can be defined as a sequence of python objects separated by commas, and enclosed in square brackets []. For example, below is a list consisting of three integers.\n\nlist_example = [2,7,4]\n\nList indexing works the same way as tuple indexing.\n\n2.2.1 Slicing a list\nList slicing is a technique in Python that allows you to extract a portion of a list by specifying a range of indices. It creates a new list containing the elements from the original list within that specified range. List slicing uses the colon : operator to indicate the start, stop, and step values for the slice. The general syntax is:  new_list = original_list[start:stop:step]\nHere’s what each part of the slice means: * start: The index at which the slice begins (inclusive). If omitted, it starts from the beginning (index 0). * stop: The index at which the slice ends (exclusive). If omitted, it goes until the end of the list. * step: The interval between elements in the slice. If omitted, it defaults to 1.\n\nlist_example6 = [4,7,3,5,7,1,5,87,5]\n\nLet us extract a slice containing all the elements from the the 3rd position to the 7th position.\n\nlist_example6[2:7]\n\n[3, 5, 7, 1, 5]\n\n\nNote that while the element at the start index is included, the element with the stop index is excluded in the above slice.\nIf either the start or stop index is not mentioned, the slicing will be done from the beginning or until the end of the list, respectively.\n\nlist_example6[:7]\n\n[4, 7, 3, 5, 7, 1, 5]\n\n\n\nlist_example6[2:]\n\n[3, 5, 7, 1, 5, 87, 5]\n\n\nTo slice the list relative to the end, we can use negative indices:\n\nlist_example6[-4:]\n\n[1, 5, 87, 5]\n\n\n\nlist_example6[-4:-2:]\n\n[1, 5]\n\n\nAn extra colon (‘:’) can be used to slice every \\(n\\)th element of a list.\n\n#Selecting every 3rd element of a list\nlist_example6[::3]\n\n[4, 5, 5]\n\n\n\n#Selecting every 3rd element of a list from the end\nlist_example6[::-3]\n\n[5, 1, 3]\n\n\n\n#Selecting every element of a list from the end or reversing a list \nlist_example6[::-1]\n\n[5, 87, 5, 1, 7, 5, 3, 7, 4]\n\n\n\n\n2.2.2 Adding and removing elements in a list\nWe can add elements at the end of the list using the append method. For example, we append the string ‘red’ to the list list_example below.\n\nlist_example.append('red')\n\n\nlist_example\n\n[2, 7, 4, 'red']\n\n\nNote that the objects of a list or a tuple can be of different datatypes.\nAn element can be added at a specific location of the list using the insert method. For example, if we wish to insert the number 2.32 as the second element of the list list_example, we can do it as follows:\n\nlist_example.insert(1,2.32)\n\n\nlist_example\n\n[2, 2.32, 7, 4, 'red']\n\n\nFor removing an element from the list, the pop and remove methods may be used. The pop method removes an element at a particular index, while the remove method removes the element’s first occurence in the list by its value. See the examples below.\nLet us say, we need to remove the third element of the list.\n\nlist_example.pop(2)\n\n7\n\n\n\nlist_example\n\n[2, 2.32, 4, 'red']\n\n\nLet us say, we need to remove the element ‘red’.\n\nlist_example.remove('red')\n\n\nlist_example\n\n[2, 2.32, 4]\n\n\n\n#If there are multiple occurrences of an element in the list, the first occurence will be removed\nlist_example2 = [2,3,2,4,4]\nlist_example2.remove(2)\nlist_example2\n\n[3, 2, 4, 4]\n\n\nFor removing multiple elements in a list, either pop or remove can be used in a for loop, or a for loop can be used with a condition. See the examples below.\nLet’s say we need to remove intergers less than 100 from the following list.\n\nlist_example3 = list(range(95,106))\nlist_example3\n\n[95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105]\n\n\n\n#Method 1: For loop with remove, iterating over the elements of the original list, \n#but updating a copy of the original list\nlist_example3_filtered = list(list_example3) #\nfor element in list_example3:\n    if element&lt;100:\n        list_example3_filtered.remove(element)\nprint(list_example3_filtered)\n\n[100, 101, 102, 103, 104, 105]\n\n\n\\(\\color{red}{\\text{Q1}}\\): What’s the need to define a new variable list_example3_filtered in the above code?\n\\(\\color{blue}{\\text{A1}}\\): Replace list_example3_filtered with list_example3 and identify the issue. After an element is removed from the list, all the elements that come afterward have their index/position reduced by one. After the elment 95 is removed, 96 is at index 0, but the for loop will now look at the element at index 1, which is now 97. So, iterating over the same list that is being updated in the loop will keep 96 and 98. Using a new list gets rid of the issue by keeping the original list unchanged, so the for-loop iterates over all elements of the original list.\nAnother method could have been to interate over a copy of the original list and update the original list as shown below.\n\n#Method 2: For loop with remove, iterating over the elements of a copy of the original list, \n#but updating the original list\nfor element in list_example3[:]: #Slicing a list creates a new list, thus the loop is iterating over elements of a copy of the original list as all the elements are selected in the slicing\n    if element&lt;100:\n        list_example3.remove(element)\nprint(list_example3)\n\n[100, 101, 102, 103, 104, 105]\n\n\nBelow is another method that uses a shorthand notation - list comprehension (explained in the next section).\n\n#Method 3: For loop with condition in list comprehension\nlist_example3 = list(range(95,106))\n[element for element in list_example3 if element&gt;=100]\n\n[100, 101, 102, 103, 104, 105]\n\n\n\n\n2.2.3 List comprehensions\nList comprehensions provide a concise and readable way to create new lists by applying an expression to each item in an iterable (e.g., a list, tuple, or range) and optionally filtering the items based on a condition. They are a powerful and efficient way to generate lists without the need for explicit loops. The basic syntax of a list comprehension is as follows:\nnew_list = [expression for item in iterable if condition]\n\nexpression: This is the expression that is applied to each item in the iterable. It defines what will be included in the new list.\nitem: This is a variable that represents each element in the iterable as the comprehension iterates through it.\niterable: This is the source from which the elements are taken. It can be any iterable, such as a list, tuple, range, or other iterable objects.\ncondition (optional): This is an optional filter that can be applied to control which items from the iterable are included in the new list. If omitted, all items from the iterable are included.\n\nExample: Create a list that has squares of natural numbers from 5 to 15.\n\nsqrt_natural_no_5_15 = [(x**2) for x in range(5,16)]\nprint(sqrt_natural_no_5_15)\n\n[25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225]\n\n\nExample: Create a list of tuples, where each tuple consists of a natural number and its square, for natural numbers ranging from 5 to 15.\n\nsqrt_natural_no_5_15 = [(x,x**2) for x in range(5,16)]\nprint(sqrt_natural_no_5_15)\n\n[(5, 25), (6, 36), (7, 49), (8, 64), (9, 81), (10, 100), (11, 121), (12, 144), (13, 169), (14, 196), (15, 225)]\n\n\nExample: Creating a list of words that start with the letter ‘a’ in a given list of words.\n\nwords = ['apple', 'banana', 'avocado', 'grape', 'apricot']\na_words = [word for word in words if word.startswith('a')]\nprint(a_words)\n\n['apple', 'avocado', 'apricot']\n\n\nExample: Create a list of even numbers from 1 to 20.\n\neven_numbers = [x for x in range(1, 21) if x % 2 == 0]\nprint(even_numbers)\n\n[2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n\n\nList comprehensions are not only concise but also considered more Pythonic and often more efficient than using explicit loops for simple operations. They can make your code cleaner and easier to read, especially for operations that transform or filter data in a list.\n\n\n2.2.4 Practice exercise 1\nBelow is a list consisting of responses to the question: “At what age do you think you will marry?” from students of the STAT303-1 Fall 2022 class.\n\nexp_marriage_age=['24','30','28','29','30','27','26','28','30+','26','28','30','30','30','probably never','30','25','25','30','28','30+ ','30','25','28','28','25','25','27','28','30','30','35','26','28','27','27','30','25','30','26','32','27','26','27','26','28','37','28','28','28','35','28','27','28','26','28','26','30','27','30','28','25','26','28','35','29','27','27','30','24','25','29','27','33','30','30','25','26','30','32','26','30','30','I wont','25','27','27','25','27','27','32','26','25','never','28','33','28','35','25','30','29','30','31','28','28','30','40','30','28','30','27','by 30','28','27','28','30-35','35','30','30','never','30','35','28','31','30','27','33','32','27','27','26','N/A','25','26','29','28','34','26','24','28','30','120','25','33','27','28','32','30','26','30','30','28','27','27','27','27','27','27','28','30','30','30','28','30','28','30','30','28','28','30','27','30','28','25','never','69','28','28','33','30','28','28','26','30','26','27','30','25','Never','27','27','25']\n\nUse list comprehension to:\n\n2.2.4.1 \nRemove the elements that are not integers - such as ‘probably never’, ‘30+’, etc. What is the length of the new list?\nHint: The built-in python function of the str class - isdigit() may be useful to check if the string contains only digits.\nSolution:\n\nexp_marriage_age_num = [x for x in exp_marriage_age if x.isdigit()==True]\nprint(\"Length of the new list = \",len(exp_marriage_age_num))\n\nLength of the new list =  181\n\n\n\n\n2.2.4.2 \nCap the values greater than 80 to 80, in the clean list obtained in (1). What is the mean age when people expect to marry in the new list?\n\nexp_marriage_age_capped = [min(int(x),80) for x in exp_marriage_age_num]\nprint(\"Mean age when people expect to marry = \", sum(exp_marriage_age_capped)/len(exp_marriage_age_capped))\n\nMean age when people expect to marry =  28.955801104972377\n\n\n\n\n2.2.4.3 \nDetermine the percentage of people who expect to marry at an age of 30 or more.\n\nprint(\"Percentage of people who expect to marry at an age of 30 or more =\", str(100*sum([1 for x in exp_marriage_age_capped if x&gt;=30])/len(exp_marriage_age_capped)),\"%\")\n\nPercentage of people who expect to marry at an age of 30 or more = 37.01657458563536 %\n\n\n\n\n2.2.4.4 \nRedo Q2.2.4.2 using the if-else statement within list comprehension.\n\n\n\n2.2.5 Practice exercise 2\nBelow is a list consisting of responses to the question: “What do you expect your starting salary to be after graduation, to the nearest thousand dollars? (ex: 47000)” from students of the STAT303-1 Fall 2023. class.\n\nexpected_salary = ['90000', '110000', '100000', '90k', '80000', '47000', '100000', '70000', '95000', '150000', '50000', '110000', '100000', '60000', '50000', '100000', '80000', '100000', '70000', '60000', '100k', '70000', '0', '60000', '50000', '150000', '90000', '80000', '110000', '85000', '90000', '50000', '60000', '150000', '100000', '100000', '125000', '30000', '100000', '110000', '90000', '600000', '80000', '100000', '100000', '70000', '60000', '0', '70000', '90000', '100000', '60000', '80000', '70000', '100000', '57000', '70000', '60000', '65000', '70000', '100000', '200000', '60000', '90000', '80000', '200000', '90000', '80000', '60000', '70000', '90000', '80000', '90000', '120000', '60000', '40000', '80000', '100000', '75000', '80000', '70000', '90000', '80000', '80000', '70000', '0', '50000', '65000', 'n/a', '100000', '60000', '65000', '100000', '100000', '65000', '90000', '50000', '80000', '90000', '100000', '100000', '100000', '100000', '80000', '60000', '100000', '80000', '55000', '80000', '100000', '60000', '130000', '35000', '70000', '50000', '120000', '110000', '110000', '80000', '70000', '90000', '100000', '90000', '100000', '70000', '110000', '300000', '90000', '45000', '90000', '60000', '44000', '1000000', '65000', '40000', '60000', '100000', '80000', '90000', '45000', '86000', '100000', '100,000+', '50000', '0']\n\nClean expected_salary using list comprehensions only, and find the mean expected salary.\n\n\n2.2.6 Concatenating lists\nAs in tuples, lists can be concatenated using the + operator:\n\nimport time as tm\n\n\nlist_example4 = [5,'hi',4] \nlist_example4 = list_example4 + [None,'7',9]\nlist_example4\n\n[5, 'hi', 4, None, '7', 9]\n\n\nFor adding elements to a list, the extend method is preferred over the + operator. This is because the + operator creates a new list, while the extend method adds elements to an existing list. Thus, the extend operator is more memory efficient.\n\nlist_example4 = [5,'hi',4]\nlist_example4.extend([None, '7', 9])\nlist_example4\n\n[5, 'hi', 4, None, '7', 9]\n\n\n\n\n2.2.7 Sorting a list\nA list can be sorted using the sort method:\n\nlist_example5 = [6,78,9]\nlist_example5.sort(reverse=True) #the reverse argument is used to specify if the sorting is in ascending or descending order\nlist_example5\n\n[78, 9, 6]\n\n\n\n\n2.2.8 Practice exercise 3\nStart with the list [8,9,10]. Do the following:\n\n2.2.8.1 \nSet the second entry (index 1) to 17\n\nL = [8,9,10]\nL[1]=17\n\n\n\n2.2.8.2 \nAdd 4, 5, and 6 to the end of the list\n\nL = L+[4,5,6]\n\n\n\n2.2.8.3 \nRemove the first entry from the list\n\nL.pop(0)\n\n8\n\n\n\n\n2.2.8.4 \nSort the list\n\nL.sort()\n\n\n\n2.2.8.5 \nDouble the list (concatenate the list to itself)\n\nL=L+L\n\n\n\n2.2.8.6 \nInsert 25 at index 3\nThe final list should equal [4,5,6,25,10,17,4,5,6,10,17]\n\nL.insert(3,25)\nL\n\n[4, 5, 6, 25, 10, 17, 4, 5, 6, 10, 17]\n\n\nNow that we have an idea about lists, let us try to think where it can be used.\n\n\n\n\n\n \n        \n\n\n\n\n\n2.2.9 Other list operations\nYou can test whether a list contains a value using the in operator.\n\nlist_example6\n\n[4, 7, 3, 5, 7, 1, 5, 87, 5]\n\n\n\n6 in list_example6\n\nFalse\n\n\n\n7 in list_example6\n\nTrue\n\n\n\n\n2.2.10 Lists: methods\nJust like strings, there are several in-built methods to manipulate a list. However, unlike strings, most list methods modify the original list rather than returning a new one. Here are some common list operations: \n\n\n\n2.2.11 Lists vs tuples\nNow that we have learned about lists and tuples, let us compare them.\n\\(\\color{red}{\\text{Q2}}\\): A list seems to be much more flexible than tuple, and can replace a tuple almost everywhere. Then why use tuple at all?\n\\(\\color{blue}{\\text{A2}}\\): The additional flexibility of a list comes at the cost of efficiency. Some of the advantages of a tuple over a list are as follows:\n\nSince a list can be extended, space is over-allocated when creating a list. A tuple takes less storage space as compared to a list of the same length.\nTuples are not copied. If a tuple is assigned to another tuple, both tuples point to the same memory location. However, if a list is assigned to another list, a new list is created consuming the same memory space as the original list.\nTuples refer to their element directly, while in a list, there is an extra layer of pointers that refers to their elements. Thus it is faster to retrieve elements from a tuple.\n\nThe examples below illustrate the above advantages of a tuple.\n\n#Example showing tuples take less storage space than lists for the same elements\ntuple_ex = (1, 2, 'Obama')\nlist_ex = [1, 2, 'Obama']\nprint(\"Space taken by tuple =\",tuple_ex.__sizeof__(),\" bytes\")\nprint(\"Space taken by list =\",list_ex.__sizeof__(),\" bytes\")\n\nSpace taken by tuple = 48  bytes\nSpace taken by list = 64  bytes\n\n\n\n#Examples showing that a tuples are not copied, while lists can be copied\ntuple_copy = tuple(tuple_ex)\nprint(\"Is tuple_copy same as tuple_ex?\", tuple_ex is tuple_copy)\nlist_copy = list(list_ex)\nprint(\"Is list_copy same as list_ex?\",list_ex is list_copy)\n\nIs tuple_copy same as tuple_ex? True\nIs list_copy same as list_ex? False\n\n\n\n#Examples showing tuples takes lesser time to retrieve elements\nimport time as tm\ntt = tm.time()\nlist_ex = list(range(1000000)) #List containinig whole numbers upto 1 million\na=(list_ex[::-2])\nprint(\"Time take to retrieve every 2nd element from a list = \", tm.time()-tt)\n\ntt = tm.time()\ntuple_ex = tuple(range(1000000)) #tuple containinig whole numbers upto 1 million\na=(tuple_ex[::-2])\nprint(\"Time take to retrieve every 2nd element from a tuple = \", tm.time()-tt)\n\nTime take to retrieve every 2nd element from a list =  0.03579902648925781\nTime take to retrieve every 2nd element from a tuple =  0.02684164047241211"
  },
  {
    "objectID": "data_structures.html#dictionary",
    "href": "data_structures.html#dictionary",
    "title": "2  Data structures",
    "section": "2.3 Dictionary",
    "text": "2.3 Dictionary\nUnlike lists and tuples, a dictionary is an unordered collection of items. Each item stored in a dictionary has a key and value. You can use a key to retrieve the corresponding value from the dictionary. Dictionaries have the type dict.\nDictionaries are often used to store many pieces of information e.g. details about a person, in a single variable. Dictionaries are created by enclosing key-value pairs within braces or curly brackets { and }, colons to separate keys and values, and commas to separate elements of a dictionary.\nThe dictionary keys and values are python objects. While values can be any python object, keys need to be immutable python objects, like strings, integers, tuples, etc. Thus, a list can be a value, but not a key, as elements of list can be changed.\n\ndict_example = {'USA':'Joe Biden', 'India':'Narendra Modi', 'China':'Xi Jinping'}\n\nElements of a dictionary can be retrieved by using the corresponding key.\n\ndict_example['India']\n\n'Narendra Modi'\n\n\n\n2.3.1 Viewing keys and values\n\ndict_example.keys()\n\ndict_keys(['USA', 'India', 'China'])\n\n\n\ndict_example.values()\n\ndict_values(['Joe Biden', 'Narendra Modi', 'Xi Jinping'])\n\n\n\ndict_example.items()\n\ndict_items([('USA', 'Joe Biden'), ('India', 'Narendra Modi'), ('China', 'Xi Jinping')])\n\n\nThe results of keys, values, and items look like lists. However, they don’t support the indexing operator [] for retrieving elements.\n\ndict_example.items()[1]\n\nTypeError: 'dict_items' object is not subscriptable\n\n\n\n\n2.3.2 Adding and removing elements in a dictionary\nNew elements can be added to a dictionary by defining a key in square brackets and assiging it to a value:\n\ndict_example['Japan'] = 'Fumio Kishida'\ndict_example['Countries'] = 4\ndict_example\n\n{'USA': 'Joe Biden',\n 'India': 'Narendra Modi',\n 'China': 'Xi Jinping',\n 'Japan': 'Fumio Kishida',\n 'Countries': 4}\n\n\nElements can be removed from the dictionary using the del method or the pop method:\n\n#Removing the element having key as 'Countries'\ndel dict_example['Countries']\n\n\ndict_example\n\n{'USA': 'Joe Biden',\n 'India': 'Narendra Modi',\n 'China': 'Xi Jinping',\n 'Japan': 'Fumio Kishida'}\n\n\n\n#Removing the element having key as 'USA'\ndict_example.pop('USA')\n\n'Joe Biden'\n\n\n\ndict_example\n\n{'India': 'Narendra Modi', 'China': 'Xi Jinping', 'Japan': 'Fumio Kishida'}\n\n\nNew elements can be added, and values of exisiting keys can be changed using the update method:\n\ndict_example = {'USA':'Joe Biden', 'India':'Narendra Modi', 'China':'Xi Jinping','Countries':3}\ndict_example\n\n{'USA': 'Joe Biden',\n 'India': 'Narendra Modi',\n 'China': 'Xi Jinping',\n 'Countries': 3}\n\n\n\ndict_example.update({'Countries':4, 'Japan':'Fumio Kishida'})\n\n\ndict_example\n\n{'USA': 'Joe Biden',\n 'India': 'Narendra Modi',\n 'China': 'Xi Jinping',\n 'Countries': 4,\n 'Japan': 'Fumio Kishida'}\n\n\n\n\n2.3.3 Iterating over elements of a dictionary\nThe items() attribute of a dictionary can be used to iterate over elements of a dictionary.\n\nfor key,value in dict_example.items():\n    print(\"The Head of State of\",key,\"is\",value)\n\nThe Head of State of USA is Joe Biden\nThe Head of State of India is Narendra Modi\nThe Head of State of China is Xi Jinping\nThe Head of State of Countries is 4\nThe Head of State of Japan is Fumio Kishida\n\n\n\n\n2.3.4 Practice exercise 4\nThe GDP per capita of USA for most years from 1960 to 2021 is given by the dictionary D given in the code cell below.\nFind:\n\nThe GDP per capita in 2015\nThe GDP per capita of 2014 is missing. Update the dictionary to include the GDP per capita of 2014 as the average of the GDP per capita of 2013 and 2015.\nImpute the GDP per capita of other missing years in the same manner as in (2), i.e., as the average GDP per capita of the previous year and the next year. Note that the GDP per capita is not missing for any two consecutive years.\nPrint the years and the imputed GDP per capita for the years having a missing value of GDP per capita in (3).\n\n\nD = {'1960':3007,'1961':3067,'1962':3244,'1963':3375,'1964':3574,'1965':3828,'1966':4146,'1967':4336,'1968':4696,'1970':5234,'1971':5609,'1972':6094,'1973':6726,'1974':7226,'1975':7801,'1976':8592,'1978':10565,'1979':11674, '1980':12575,'1981':13976,'1982':14434,'1983':15544,'1984':17121,'1985':18237,  '1986':19071,'1987':20039,'1988':21417,'1989':22857,'1990':23889,'1991':24342,  '1992':25419,'1993':26387,'1994':27695,'1995':28691,'1996':29968,'1997':31459,  '1998':32854,'2000':36330,'2001':37134,'2002':37998,'2003':39490,'2004':41725,  '2005':44123,'2006':46302,'2007':48050,'2008':48570,'2009':47195,'2010':48651,  '2011':50066,'2012':51784,'2013':53291,'2015':56763,'2016':57867,'2017':59915,'2018':62805, '2019':65095,'2020':63028,'2021':69288}\n\nSolution:\n\nprint(\"GDP per capita in 2015 =\", D['2015'])\nD['2014'] = (D['2013']+D['2015'])/2\nfor i in range(1960,2021):\n    if str(i) not in D.keys():    \n        D[str(i)] = (D[str(i-1)]+D[str(i+1)])/2\n        print(\"Imputed GDP per capita for the year\",i,\"is $\",D[str(i)])\n\nGDP per capita in 2015 = 56763\nImputed GDP per capita for the year 1969 is $ 4965.0\nImputed GDP per capita for the year 1977 is $ 9578.5\nImputed GDP per capita for the year 1999 is $ 34592.0"
  },
  {
    "objectID": "data_structures.html#functions",
    "href": "data_structures.html#functions",
    "title": "2  Data structures",
    "section": "2.4 Functions",
    "text": "2.4 Functions\nIf an algorithm or block of code is being used several times in a code, then it can be separately defined as a function. This makes the code more organized and readable. For example, let us define a function that prints prime numbers between a and b, and returns the number of prime numbers found.\n\n#Function definition\ndef prime_numbers (a,b=100):\n    num_prime_nos = 0\n    \n    #Iterating over all numbers between a and b\n    for i in range(a,b):\n        num_divisors=0\n        \n        #Checking if the ith number has any factors\n        for j in range(2, i):\n            if i%j == 0:\n                num_divisors=1;break;\n                \n        #If there are no factors, then printing and counting the number as prime        \n        if num_divisors==0:\n            print(i)\n            num_prime_nos = num_prime_nos+1\n            \n    #Return count of the number of prime numbers\n    return num_prime_nos\n\nIn the above function, the keyword def is used to define the function, prime_numbers is the name of the function, a and b are the arguments that the function uses to compute the output.\nLet us use the defined function to print and count the prime numbers between 40 and 60.\n\n#Printing prime numbers between 40 and 60\nnum_prime_nos_found = prime_numbers(40,60)\n\n41\n43\n47\n53\n59\n\n\n\nnum_prime_nos_found\n\n5\n\n\nIf the user calls the function without specifying the value of the argument b, then it will take the default value of 100, as mentioned in the function definition. However, for the argument a, the user will need to specify a value, as there is no value defined as a default value in the function definition.\n\n2.4.1 Global and local variables with respect to a function\nA variable defined within a function is local to that function, while a variable defined outside the function is global to that function. In case a variable with the same name is defined both outside and inside a function, it will refer to its global value outside the function and local value within the function.\nThe example below shows a variable with the name var referring to its local value when called within the function, and global value when called outside the function.\n\nvar = 5\ndef sample_function(var):    \n    print(\"Local value of 'var' within 'sample_function()'= \",var)\n\nsample_function(4)\nprint(\"Global value of 'var' outside 'sample_function()' = \",var)\n\nLocal value of 'var' within 'sample_function()'=  4\nGlobal value of 'var' outside 'sample_function()' =  5\n\n\n\n\n2.4.2 Practice exercise 5\nThe object deck defined below corresponds to a deck of cards. Estimate the probablity that a five card hand will be a flush, as follows:\n\nWrite a function that accepts a hand of 5 cards as argument, and returns whether the hand is a flush or not.\nRandomly pull a hand of 5 cards from the deck. Call the function developed in (1) to determine if the hand is a flush.\nRepeat (2) 10,000 times.\nEstimate the probability of the hand being a flush from the results of the 10,000 simulations.\n\nYou may use the function shuffle() from the random library to shuffle the deck everytime before pulling a hand of 5 cards.\n\ndeck = [{'value':i, 'suit':c}\nfor c in ['spades', 'clubs', 'hearts', 'diamonds']\nfor i in range(2,15)]\n\nSolution:\n\nimport random as rm\n\n#Function to check if a 5-card hand is a flush\ndef chck_flush(hands):  \n    \n    #Assuming that the hand is a flush, before checking the cards\n    yes_flush =1\n    \n    #Storing the suit of the first card in 'first_suit'\n    first_suit = hands[0]['suit']\n    \n    #Iterating over the remaining 4 cards of the hand\n    for j in range(1,len(hands)):\n        \n        #If the suit of any of the cards does not match the suit of the first card, the hand is not a flush\n        if first_suit!=hands[j]['suit']:\n            yes_flush = 0; \n            \n            #As soon as a card with a different suit is found, the hand is not a flush and there is no need to check other cards. So, we 'break' out of the loop\n            break;\n    return yes_flush\n\nflush=0\nfor i in range(10000):\n    \n    #Shuffling the deck\n    rm.shuffle(deck)\n    \n    #Picking out the first 5 cards of the deck as a hand and checking if they are a flush\n    #If the hand is a flush it is counted\n    flush=flush+chck_flush(deck[0:5])\n    \nprint(\"Probability of obtaining a flush=\", 100*(flush/10000),\"%\")\n\nProbability of obtaining a flush= 0.18 %"
  },
  {
    "objectID": "data_structures.html#practice-exercise-6",
    "href": "data_structures.html#practice-exercise-6",
    "title": "2  Data structures",
    "section": "2.5 Practice exercise 6",
    "text": "2.5 Practice exercise 6\nThe code cell below defines an object having the nutrition information of drinks in starbucks. Assume that the manner in which the information is structured is consistent throughout the object.\n\nstarbucks_drinks_nutrition={'Cool Lime Starbucks Refreshers™ Beverage': [{'Nutrition_type': 'Calories', 'value': 45}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 11}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Strawberry Acai Starbucks Refreshers™ Beverage': [{'Nutrition_type': 'Calories', 'value': 80}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 18}, {'Nutrition_type': 'Fiber', 'value': 1}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Very Berry Hibiscus Starbucks Refreshers™ Beverage': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 14}, {'Nutrition_type': 'Fiber', 'value': 1}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Evolution Fresh™ Organic Ginger Limeade': [{'Nutrition_type': 'Calories', 'value': 110}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 28}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Iced Coffee': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Iced Espresso Classics - Vanilla Latte': [{'Nutrition_type': 'Calories', 'value': 130}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 21}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 5}, {'Nutrition_type': 'Sodium', 'value': 65}], 'Iced Espresso Classics - Caffe Mocha': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 23}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 5}, {'Nutrition_type': 'Sodium', 'value': 90}], 'Iced Espresso Classics - Caramel Macchiato': [{'Nutrition_type': 'Calories', 'value': 130}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 21}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 5}, {'Nutrition_type': 'Sodium', 'value': 65}], 'Shaken Sweet Tea': [{'Nutrition_type': 'Calories', 'value': 80}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 19}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Berry Blossom White': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 15}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Black Mango': [{'Nutrition_type': 'Calories', 'value': 150}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 38}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Tazo® Bottled Black with Lemon': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Brambleberry': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Tazo® Bottled Giant Peach': [{'Nutrition_type': 'Calories', 'value': 150}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 37}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Tazo® Bottled Iced Passion': [{'Nutrition_type': 'Calories', 'value': 70}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 17}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Lemon Ginger': [{'Nutrition_type': 'Calories', 'value': 120}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 31}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Organic Black Lemonade': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Organic Iced Black Tea': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 15}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Organic Iced Green Tea': [{'Nutrition_type': 'Calories', 'value': 120}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 31}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Plum Pomegranate': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Tazoberry': [{'Nutrition_type': 'Calories', 'value': 150}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 38}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Tazo® Bottled White Cranberry': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Teavana® Shaken Iced Black Tea': [{'Nutrition_type': 'Calories', 'value': 30}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 8}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Teavana® Shaken Iced Black Tea Lemonade': [{'Nutrition_type': 'Calories', 'value': 70}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 17}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Teavana® Shaken Iced Green Tea': [{'Nutrition_type': 'Calories', 'value': 30}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 8}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Teavana® Shaken Iced Green Tea Lemonade': [{'Nutrition_type': 'Calories', 'value': 70}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 17}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Teavana® Shaken Iced Passion Tango™ Tea': [{'Nutrition_type': 'Calories', 'value': 30}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 8}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Teavana® Shaken Iced Passion Tango™ Tea Lemonade': [{'Nutrition_type': 'Calories', 'value': 90}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 24}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Teavana® Shaken Iced Peach Green Tea': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 15}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks Refreshers™ Raspberry Pomegranate': [{'Nutrition_type': 'Calories', 'value': 90}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 27}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks Refreshers™ Strawberry Lemonade': [{'Nutrition_type': 'Calories', 'value': 90}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 27}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks® Doubleshot Protein Dark Chocolate': [{'Nutrition_type': 'Calories', 'value': 210}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 33}, {'Nutrition_type': 'Fiber', 'value': 2}, {'Nutrition_type': 'Protein', 'value': 20}, {'Nutrition_type': 'Sodium', 'value': 115}], 'Starbucks® Doubleshot Protein Vanilla': [{'Nutrition_type': 'Calories', 'value': 200}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 34}, {'Nutrition_type': 'Fiber', 'value': 2}, {'Nutrition_type': 'Protein', 'value': 20}, {'Nutrition_type': 'Sodium', 'value': 120}], 'Starbucks® Iced Coffee Caramel': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 13}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks® Iced Coffee Light Sweetened': [{'Nutrition_type': 'Calories', 'value': 50}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 11}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks® Iced Coffee Unsweetened': [{'Nutrition_type': 'Calories', 'value': 10}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 2}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Blonde Roast': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Clover® Brewed Coffee': [{'Nutrition_type': 'Calories', 'value': 10}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Decaf Pike Place® Roast': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Featured Dark Roast': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Nariño 70 Cold Brew': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Nariño 70 Cold Brew with Milk': [{'Nutrition_type': 'Calories', 'value': 0}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Nitro Cold Brew': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Nitro Cold Brew with Sweet Cream': [{'Nutrition_type': 'Calories', 'value': 70}, {'Nutrition_type': 'Fat', 'value': 5.0}, {'Nutrition_type': 'Carb', 'value': 5}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 20}], 'Pike Place® Roast': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Vanilla Sweet Cream Cold Brew': [{'Nutrition_type': 'Calories', 'value': 110}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 14}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 25}], 'Hot Chocolate': [{'Nutrition_type': 'Calories', 'value': 320}, {'Nutrition_type': 'Fat', 'value': 9.0}, {'Nutrition_type': 'Carb', 'value': 47}, {'Nutrition_type': 'Fiber', 'value': 4}, {'Nutrition_type': 'Protein', 'value': 14}, {'Nutrition_type': 'Sodium', 'value': 160}], 'Starbucks® Signature Hot Chocolate': [{'Nutrition_type': 'Calories', 'value': 430}, {'Nutrition_type': 'Fat', 'value': 26.0}, {'Nutrition_type': 'Carb', 'value': 45}, {'Nutrition_type': 'Fiber', 'value': 5}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 115}], 'Caffè Latte': [{'Nutrition_type': 'Calories', 'value': 190}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 19}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 13}, {'Nutrition_type': 'Sodium', 'value': 170}], 'Caffè Mocha': [{'Nutrition_type': 'Calories', 'value': 290}, {'Nutrition_type': 'Fat', 'value': 8.0}, {'Nutrition_type': 'Carb', 'value': 42}, {'Nutrition_type': 'Fiber', 'value': 4}, {'Nutrition_type': 'Protein', 'value': 13}, {'Nutrition_type': 'Sodium', 'value': 140}], 'Cappuccino': [{'Nutrition_type': 'Calories', 'value': 120}, {'Nutrition_type': 'Fat', 'value': 4.0}, {'Nutrition_type': 'Carb', 'value': 12}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 8}, {'Nutrition_type': 'Sodium', 'value': 100}], 'Caramel Macchiato': [{'Nutrition_type': 'Calories', 'value': 250}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 150}], 'Cinnamon Dolce Latte': [{'Nutrition_type': 'Calories', 'value': 260}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 40}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 11}, {'Nutrition_type': 'Sodium', 'value': 150}], 'Coconutmilk Mocha Macchiato': [{'Nutrition_type': 'Calories', 'value': 250}, {'Nutrition_type': 'Fat', 'value': 9.0}, {'Nutrition_type': 'Carb', 'value': 32}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 180}], 'Flat White': [{'Nutrition_type': 'Calories', 'value': 180}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 18}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 160}], 'Iced Caffè Latte': [{'Nutrition_type': 'Calories', 'value': 130}, {'Nutrition_type': 'Fat', 'value': 4.5}, {'Nutrition_type': 'Carb', 'value': 13}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 8}, {'Nutrition_type': 'Sodium', 'value': 115}], 'Iced Caffè Mocha': [{'Nutrition_type': 'Calories', 'value': 230}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 36}, {'Nutrition_type': 'Fiber', 'value': 4}, {'Nutrition_type': 'Protein', 'value': 9}, {'Nutrition_type': 'Sodium', 'value': 90}], 'Iced Caramel Macchiato': [{'Nutrition_type': 'Calories', 'value': 250}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 37}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 150}], 'Iced Cinnamon Dolce Latte': [{'Nutrition_type': 'Calories', 'value': 200}, {'Nutrition_type': 'Fat', 'value': 4.0}, {'Nutrition_type': 'Carb', 'value': 34}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 7}, {'Nutrition_type': 'Sodium', 'value': 95}], 'Iced Coconutmilk Mocha Macchiato': [{'Nutrition_type': 'Calories', 'value': 260}, {'Nutrition_type': 'Fat', 'value': 9.0}, {'Nutrition_type': 'Carb', 'value': 34}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 11}, {'Nutrition_type': 'Sodium', 'value': 180}], 'Iced Vanilla Latte': [{'Nutrition_type': 'Calories', 'value': 190}, {'Nutrition_type': 'Fat', 'value': 4.0}, {'Nutrition_type': 'Carb', 'value': 30}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 7}, {'Nutrition_type': 'Sodium', 'value': 100}], 'Iced White Chocolate Mocha': [{'Nutrition_type': 'Calories', 'value': 300}, {'Nutrition_type': 'Fat', 'value': 8.0}, {'Nutrition_type': 'Carb', 'value': 47}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 190}], 'Latte Macchiato': [{'Nutrition_type': 'Calories', 'value': 190}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 19}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 160}], 'Starbucks Doubleshot® on Ice Beverage': [{'Nutrition_type': 'Calories', 'value': 45}, {'Nutrition_type': 'Fat', 'value': 1.0}, {'Nutrition_type': 'Carb', 'value': 5}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 3}, {'Nutrition_type': 'Sodium', 'value': 40}], 'Vanilla Latte': [{'Nutrition_type': 'Calories', 'value': 250}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 37}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 150}], 'White Chocolate Mocha': [{'Nutrition_type': 'Calories', 'value': 360}, {'Nutrition_type': 'Fat', 'value': 11.0}, {'Nutrition_type': 'Carb', 'value': 53}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 14}, {'Nutrition_type': 'Sodium', 'value': 240}], 'Cinnamon Dolce Frappuccino® Blended Coffee': [{'Nutrition_type': 'Calories', 'value': 350}, {'Nutrition_type': 'Fat', 'value': 4.5}, {'Nutrition_type': 'Carb', 'value': 64}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 15}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Coffee Light Frappuccino® Blended Coffee': [{'Nutrition_type': 'Calories', 'value': 110}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 24}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 3}, {'Nutrition_type': 'Sodium', 'value': 200}], 'Mocha Frappuccino® Blended Coffee': [{'Nutrition_type': 'Calories', 'value': 280}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 60}, {'Nutrition_type': 'Fiber', 'value': 2}, {'Nutrition_type': 'Protein', 'value': 4}, {'Nutrition_type': 'Sodium', 'value': 220}], 'Mocha Light Frappuccino® Blended Coffee': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.5}, {'Nutrition_type': 'Carb', 'value': 28}, {'Nutrition_type': 'Fiber', 'value': 1}, {'Nutrition_type': 'Protein', 'value': 4}, {'Nutrition_type': 'Sodium', 'value': 180}], 'Cinnamon Dolce Crème': [{'Nutrition_type': 'Calories', 'value': 200}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 28}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 135}], 'Vanilla Crème': [{'Nutrition_type': 'Calories', 'value': 200}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 28}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 135}], 'Chocolate Smoothie': [{'Nutrition_type': 'Calories', 'value': 320}, {'Nutrition_type': 'Fat', 'value': 5.0}, {'Nutrition_type': 'Carb', 'value': 53}, {'Nutrition_type': 'Fiber', 'value': 8}, {'Nutrition_type': 'Protein', 'value': 20}, {'Nutrition_type': 'Sodium', 'value': 170}], 'Strawberry Smoothie': [{'Nutrition_type': 'Calories', 'value': 300}, {'Nutrition_type': 'Fat', 'value': 2.0}, {'Nutrition_type': 'Carb', 'value': 60}, {'Nutrition_type': 'Fiber', 'value': 7}, {'Nutrition_type': 'Protein', 'value': 16}, {'Nutrition_type': 'Sodium', 'value': 130}]}\n\nUse the object above to answer the following questions:\n\n2.5.1 \nWhat is the datatype of the object?\n\nprint(\"Datatype=\",type(starbucks_drinks_nutrition)) \n\nDatatype= &lt;class 'dict'&gt;\n\n\n\n2.5.1.1 \nIf the object in (1) is a dictonary, what is the datatype of the values of the dictionary?\n\nprint(\"Datatype=\",type(starbucks_drinks_nutrition[list(starbucks_drinks_nutrition.keys())[0]]))\n\nDatatype= &lt;class 'list'&gt;\n\n\n\n\n2.5.1.2 \nIf the object in (1) is a dictonary, what is the datatype of the elements within the values of the dictionary?\n\nprint(\"Datatype=\",type(starbucks_drinks_nutrition[list(starbucks_drinks_nutrition.keys())[0]][0]))\n\nDatatype= &lt;class 'dict'&gt;\n\n\n\n\n2.5.1.3 \nHow many calories are there in Iced Coffee?\n\nprint(\"Calories = \",starbucks_drinks_nutrition['Iced Coffee'][0]['value'])\n\nCalories =  5\n\n\n\n\n2.5.1.4 \nWhich drink(s) have the highest amount of protein in them, and what is that protein amount?\n\n#Defining an empty dictionary that will be used to store the protein of each drink\nprotein={}\n\nfor key,value in starbucks_drinks_nutrition.items():\n    for nutrition in value:        \n        if nutrition['Nutrition_type']=='Protein':\n            protein[key]=(nutrition['value'])\n\n#Using dictionary comprehension to find the key-value pair having the maximum value in the dictionary\n{key:value for key, value in protein.items() if value == max(protein.values())}\n\n{'Starbucks® Doubleshot Protein Dark Chocolate': 20,\n 'Starbucks® Doubleshot Protein Vanilla': 20,\n 'Chocolate Smoothie': 20}\n\n\n\n\n2.5.1.5 \nWhich drink(s) have a fat content of more than 10g, and what is their fat content?\n\n#Defining an empty dictionary that will be used to store the fat of each drink\nfat={}\nfor key,value in starbucks_drinks_nutrition.items():\n    for nutrition in value:        \n        if nutrition['Nutrition_type']=='Fat':\n            fat[key]=(nutrition['value'])\n            \n#Using dictionary comprehension to find the key-value pair having the value more than 10\n{key:value for key, value in fat.items() if value&gt;=10}\n\n{'Starbucks® Signature Hot Chocolate': 26.0, 'White Chocolate Mocha': 11.0}\n\n\n\n\n2.5.1.6 \nAnswer Q2.5.1.5 using only dictionary comprehension."
  },
  {
    "objectID": "Reading_data.html#types-of-data",
    "href": "Reading_data.html#types-of-data",
    "title": "3  Reading Data",
    "section": "3.1 3.1 Types of data",
    "text": "3.1 3.1 Types of data\n\nIn this course, we will focus on analyzing structured data."
  },
  {
    "objectID": "Reading_data.html#using-pandas-to-read-csvs",
    "href": "Reading_data.html#using-pandas-to-read-csvs",
    "title": "3  Reading Data",
    "section": "3.2 3.2 Using Pandas to Read CSVs",
    "text": "3.2 3.2 Using Pandas to Read CSVs\nPandas is a popular Python library used for working in tabular data (similar to the data stored in a spreadsheet). Pandas provides helper functions to read data from various file formats like CSV, Excel spreadsheets, HTML tables, JSON, SQL, and more.\nThe below format of storing data is known as comma-separated values or CSV. It contains day-wise Covid-19 data for Italy:\ndate,new_cases,new_deaths,new_tests\n2020-04-21,2256.0,454.0,28095.0\n2020-04-22,2729.0,534.0,44248.0\n2020-04-23,3370.0,437.0,37083.0\n2020-04-24,2646.0,464.0,95273.0\n2020-04-25,3021.0,420.0,38676.0\n2020-04-26,2357.0,415.0,24113.0\n2020-04-27,2324.0,260.0,26678.0\n2020-04-28,1739.0,333.0,37554.0\n...\n\nCSVs: A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. A CSV file typically stores tabular data (numbers and text) in plain text, in which case each line will have the same number of fields. (Wikipedia)\n\nFirst, let’s import the Pandas library. As a convention, it is imported with the alias pd.\n\n\nCode\nimport pandas as pd\nimport os\n\n\n\n3.2.1 3.2.1 Using the read_csv function\nThe pd.read_csv function can be used to read a CSV file into a pandas DataFrame: a spreadsheet-like object for analyzing and processing data.\n\n\nCode\nmovie_ratings = pd.read_csv('../data/movie_ratings.csv')\n\n\nThe built-in python function type can be used to check the dataype of an object:\n\n\nCode\ntype(movie_ratings)\n\n\npandas.core.frame.DataFrame\n\n\nWe’ll learn more about DataFrame in a future lesson.\nNote that I use the relative path to specify the file path for movie_ratings.csv, you may need to change it based on where you store the data file.\n\n\n3.2.2 3.2.2 Data Overview\nOnce the data has been read, we may want to see what the data looks like. We’ll use another Pandas function head() to view the first few rows of the data.\n\n\nCode\nmovie_ratings.head()\n\n\n\n\n\n\n\n\n\nTitle\nUS Gross\nWorldwide Gross\nProduction Budget\nRelease Date\nMPAA Rating\nSource\nMajor Genre\nCreative Type\nIMDB Rating\nIMDB Votes\n\n\n\n\n0\nOpal Dreams\n14443\n14443\n9000000\nNov 22 2006\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n6.5\n468\n\n\n1\nMajor Dundee\n14873\n14873\n3800000\nApr 07 1965\nPG/PG-13\nAdapted screenplay\nWestern/Musical\nFiction\n6.7\n2588\n\n\n2\nThe Informers\n315000\n315000\n18000000\nApr 24 2009\nR\nAdapted screenplay\nHorror/Thriller\nFiction\n5.2\n7595\n\n\n3\nBuffalo Soldiers\n353743\n353743\n15000000\nJul 25 2003\nR\nAdapted screenplay\nComedy\nFiction\n6.9\n13510\n\n\n4\nThe Last Sin Eater\n388390\n388390\n2200000\nFeb 09 2007\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n5.7\n1012\n\n\n\n\n\n\n\nRow Indices and column names (axis labels)\nBy default, when you create a pandas DataFrame (or Series) without specifying an index, pandas will automatically assign integer-based row indices starting from 0. These indices serve as the row labels and uniquely identify each row in the DataFrame. For example, the index 2 correponds to the row of the movie The Informers. By default, the indices are integers starting from 0. However, they can be changed (to even non-integer values) if desired by the user.\nThe bold text on top of the DataFrame refers to column names. For example, the column US Gross consists of the gross revenue of a movie in the US.\nCollectively, the indices and column names are referred as axis labels.\nBasic information We can view some basic information about the data frame using the .info method.\n\n\nCode\nmovie_ratings.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 2228 entries, 0 to 2227\nData columns (total 11 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Title              2228 non-null   object \n 1   US Gross           2228 non-null   int64  \n 2   Worldwide Gross    2228 non-null   int64  \n 3   Production Budget  2228 non-null   int64  \n 4   Release Date       2228 non-null   object \n 5   MPAA Rating        2228 non-null   object \n 6   Source             2228 non-null   object \n 7   Major Genre        2228 non-null   object \n 8   Creative Type      2228 non-null   object \n 9   IMDB Rating        2228 non-null   float64\n 10  IMDB Votes         2228 non-null   int64  \ndtypes: float64(1), int64(4), object(6)\nmemory usage: 191.6+ KB\n\n\nThe shape property of a pandas DataFrame provides a tuple that represents the dimensions of the DataFrame:\n\nThe first value in the tuple is the number of rows.\nThe second value in the tuple is the number of columns.\n\n\n\nCode\nmovie_ratings.shape\n\n\n(2228, 11)\n\n\nThe columns property contains the list of columns within the data frame.\n\n\nCode\nmovie_ratings.columns\n\n\nIndex(['Title', 'US Gross', 'Worldwide Gross', 'Production Budget',\n       'Release Date', 'MPAA Rating', 'Source', 'Major Genre', 'Creative Type',\n       'IMDB Rating', 'IMDB Votes'],\n      dtype='object')\n\n\nYou can view statistical information for numerical columns (mean, standard deviation, minimum/maximum values, and the number of non-empty values) using the .describe method.\n\n\nCode\nmovie_ratings.describe()\n\n\n\n\n\n\n\n\n\nUS Gross\nWorldwide Gross\nProduction Budget\nIMDB Rating\nIMDB Votes\n\n\n\n\ncount\n2.228000e+03\n2.228000e+03\n2.228000e+03\n2228.000000\n2228.000000\n\n\nmean\n5.076370e+07\n1.019370e+08\n3.816055e+07\n6.239004\n33585.154847\n\n\nstd\n6.643081e+07\n1.648589e+08\n3.782604e+07\n1.243285\n47325.651561\n\n\nmin\n0.000000e+00\n8.840000e+02\n2.180000e+02\n1.400000\n18.000000\n\n\n25%\n9.646188e+06\n1.320737e+07\n1.200000e+07\n5.500000\n6659.250000\n\n\n50%\n2.838649e+07\n4.266892e+07\n2.600000e+07\n6.400000\n18169.000000\n\n\n75%\n6.453140e+07\n1.200000e+08\n5.300000e+07\n7.100000\n40092.750000\n\n\nmax\n7.601676e+08\n2.767891e+09\n3.000000e+08\n9.200000\n519541.000000\n\n\n\n\n\n\n\nFunctions & Methods we’ve looked so far\n\npd.read_csv - Read data from a CSV file into a Pandas DataFrame object\n.info() - View basic infomation about rows, columns & data types\n.shape - Get the number of rows & columns as a tuple\n.columns - Get the list of column names\n.describe() - View statistical information about numeric columns"
  },
  {
    "objectID": "Reading_data.html#data-selection-and-filtering",
    "href": "Reading_data.html#data-selection-and-filtering",
    "title": "3  Reading Data",
    "section": "3.3 3.3 Data Selection and Filtering",
    "text": "3.3 3.3 Data Selection and Filtering\n\n3.3.1 3.3.1 Extracting Column(s) from pandas\nThe first step when working with a DataFrame is often to extract one or more columns. To do this effectively, it’s helpful to understand the internal structure of a DataFrame. Conceptually, you can think of a DataFrame as a dictionary of lists, where the keys are column names, and the values are lists or arrays containing data for the respective columns.\n\n\nCode\n# Pandas format is simliar to this\nmovie_ratings_dict = {\n    'Title':  ['Opal Dreams', 'Major Dundee', 'The Informers', 'Buffalo Soldiers', 'The Last Sin Eater'],\n    'US Gross':  [14443, 14873, 315000, 353743, 388390],\n    'Worldwide Gross': [14443, 14873, 315000, 353743, 388390],\n    'Production Budget': [9000000, 3800000, 18000000, 15000000, 2200000]\n}\n\n\nFor dictionary, we use key to retrive its values\n\n\nCode\nmovie_ratings_dict['Title']\n\n\n['Opal Dreams',\n 'Major Dundee',\n 'The Informers',\n 'Buffalo Soldiers',\n 'The Last Sin Eater']\n\n\nSimilar like dictionary, we can extract a column by its column name\n\n\nCode\nmovie_ratings['Title']\n\n\n0                         Opal Dreams\n1                        Major Dundee\n2                       The Informers\n3                    Buffalo Soldiers\n4                  The Last Sin Eater\n                    ...              \n2223                      King Arthur\n2224                            Mulan\n2225                       Robin Hood\n2226    Robin Hood: Prince of Thieves\n2227                       Spiceworld\nName: Title, Length: 2228, dtype: object\n\n\nEach column is a feature of the dataframe, we can also use. operator to extract a single column\n\n\nCode\nmovie_ratings.Title\n\n\n0                         Opal Dreams\n1                        Major Dundee\n2                       The Informers\n3                    Buffalo Soldiers\n4                  The Last Sin Eater\n                    ...              \n2223                      King Arthur\n2224                            Mulan\n2225                       Robin Hood\n2226    Robin Hood: Prince of Thieves\n2227                       Spiceworld\nName: Title, Length: 2228, dtype: object\n\n\nWhen extracting multiple columns, you need to place the column names inside a list.\n\n\nCode\nmovie_ratings[['Title', 'US Gross', 'Worldwide Gross' ]]\n\n\n\n\n\n\n\n\n\nTitle\nUS Gross\nWorldwide Gross\n\n\n\n\n0\nOpal Dreams\n14443\n14443\n\n\n1\nMajor Dundee\n14873\n14873\n\n\n2\nThe Informers\n315000\n315000\n\n\n3\nBuffalo Soldiers\n353743\n353743\n\n\n4\nThe Last Sin Eater\n388390\n388390\n\n\n...\n...\n...\n...\n\n\n2223\nKing Arthur\n51877963\n203877963\n\n\n2224\nMulan\n120620254\n303500000\n\n\n2225\nRobin Hood\n105269730\n310885538\n\n\n2226\nRobin Hood: Prince of Thieves\n165493908\n390500000\n\n\n2227\nSpiceworld\n29342592\n56042592\n\n\n\n\n2228 rows × 3 columns\n\n\n\n\n\n3.3.2 3.3.2 Creating new columns from existing columns\nNew variables (or columns) can be created based on existing variables, or with external data (we’ll see adding external data later). For example, let us create a new variable ratio_wgross_by_budget, which is the ratio of Worldwide Gross and Production Budget for each movie:\n\n\nCode\nmovie_ratings['ratio_wgross_by_budget'] = movie_ratings['Worldwide Gross']/movie_ratings['Production Budget']\nmovie_ratings.head()\n\n\n\n\n\n\n\n\n\nTitle\nUS Gross\nWorldwide Gross\nProduction Budget\nRelease Date\nMPAA Rating\nSource\nMajor Genre\nCreative Type\nIMDB Rating\nIMDB Votes\nratio_wgross_by_budget\n\n\n\n\n0\nOpal Dreams\n14443\n14443\n9000000\nNov 22 2006\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n6.5\n468\n0.001605\n\n\n1\nMajor Dundee\n14873\n14873\n3800000\nApr 07 1965\nPG/PG-13\nAdapted screenplay\nWestern/Musical\nFiction\n6.7\n2588\n0.003914\n\n\n2\nThe Informers\n315000\n315000\n18000000\nApr 24 2009\nR\nAdapted screenplay\nHorror/Thriller\nFiction\n5.2\n7595\n0.017500\n\n\n3\nBuffalo Soldiers\n353743\n353743\n15000000\nJul 25 2003\nR\nAdapted screenplay\nComedy\nFiction\n6.9\n13510\n0.023583\n\n\n4\nThe Last Sin Eater\n388390\n388390\n2200000\nFeb 09 2007\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n5.7\n1012\n0.176541\n\n\n\n\n\n\n\n\n\n3.3.3 3.3.3 Extracting a sub-set of data: loc and iloc\nSometimes we may be interested in working with a subset of rows and columns of the data, instead of working with the entire dataset. The indexing operators loc and iloc provide a convenient way of selecting a subset of desired rows and columns.\nLet us first sort the movie_ratings data frame by IMDB Rating.\n\n\nCode\nmovie_ratings_sorted = movie_ratings.sort_values(by = 'IMDB Rating', ascending = False)\nmovie_ratings_sorted.head()\n\n\n\n\n\n\n\n\n\nTitle\nUS Gross\nWorldwide Gross\nProduction Budget\nRelease Date\nMPAA Rating\nSource\nMajor Genre\nCreative Type\nIMDB Rating\nIMDB Votes\nratio_wgross_by_budget\n\n\n\n\n182\nThe Shawshank Redemption\n28241469\n28241469\n25000000\nSep 23 1994\nR\nAdapted screenplay\nDrama\nFiction\n9.2\n519541\n1.129659\n\n\n2084\nInception\n285630280\n753830280\n160000000\nJul 16 2010\nPG/PG-13\nOriginal Screenplay\nHorror/Thriller\nFiction\n9.1\n188247\n4.711439\n\n\n2092\nToy Story 3\n410640665\n1046340665\n200000000\nJun 18 2010\nG\nOriginal Screenplay\nAction/Adventure\nFiction\n8.9\n67380\n5.231703\n\n\n1962\nPulp Fiction\n107928762\n212928762\n8000000\nOct 14 1994\nR\nOriginal Screenplay\nDrama\nFiction\n8.9\n417703\n26.616095\n\n\n790\nSchindler's List\n96067179\n321200000\n25000000\nDec 15 1993\nR\nAdapted screenplay\nDrama\nNon-Fiction\n8.9\n276283\n12.848000\n\n\n\n\n\n\n\n\n3.3.3.1 3.3.3.1 Subsetting the DataFrame by loc\nThe operator loc uses axis labels (row indices and column names) to subset the data.\nLet’s subset the title, worldwide gross, production budget, and IMDB raring of top 3 movies.\n\n\nCode\n# Subsetting the DataFrame by loc - using axis labels\nmovies_subset = movie_ratings_sorted.loc[[182,2084, 2092],[ 'Title', 'IMDB Rating', 'US Gross', 'Worldwide Gross', 'Production Budget']]\nmovies_subset\n\n\n\n\n\n\n\n\n\nTitle\nIMDB Rating\nUS Gross\nWorldwide Gross\nProduction Budget\n\n\n\n\n182\nThe Shawshank Redemption\n9.2\n28241469\n28241469\n25000000\n\n\n2084\nInception\n9.1\n285630280\n753830280\n160000000\n\n\n2092\nToy Story 3\n8.9\n410640665\n1046340665\n200000000\n\n\n\n\n\n\n\nThe : symbol in .loc and .iloc is a slicing operator that represents a range or all elements in the specified dimension (rows or columns). Use : alone to select all rows/columns, or with start/end points to slice specific parts of the DataFrame.\n\n\nCode\n# Subsetting the DataFrame by loc - using axis labels. the colon is used to select all rows\nmovies_subset = movie_ratings_sorted.loc[:,['Title','Worldwide Gross','Production Budget','IMDB Rating']]\nmovies_subset\n\n\n\n\n\n\n\n\n\nTitle\nWorldwide Gross\nProduction Budget\nIMDB Rating\n\n\n\n\n182\nThe Shawshank Redemption\n28241469\n25000000\n9.2\n\n\n2084\nInception\n753830280\n160000000\n9.1\n\n\n2092\nToy Story 3\n1046340665\n200000000\n8.9\n\n\n1962\nPulp Fiction\n212928762\n8000000\n8.9\n\n\n790\nSchindler's List\n321200000\n25000000\n8.9\n\n\n...\n...\n...\n...\n...\n\n\n516\nSon of the Mask\n59918422\n100000000\n2.0\n\n\n1495\nDisaster Movie\n34690901\n20000000\n1.7\n\n\n1116\nCrossover\n7009668\n5600000\n1.7\n\n\n805\nFrom Justin to Kelly\n4922166\n12000000\n1.6\n\n\n1147\nSuper Babies: Baby Geniuses 2\n9109322\n20000000\n1.4\n\n\n\n\n2228 rows × 4 columns\n\n\n\n\n\nCode\n# Subsetting the DataFrame by loc - using axis labels. the colon is used to select a range of rows\nmovies_subset = movie_ratings_sorted.loc[182:561,['Title','Worldwide Gross','Production Budget','IMDB Rating']]\nmovies_subset\n\n\n\n\n\n\n\n\n\nTitle\nWorldwide Gross\nProduction Budget\nIMDB Rating\n\n\n\n\n182\nThe Shawshank Redemption\n28241469\n25000000\n9.2\n\n\n2084\nInception\n753830280\n160000000\n9.1\n\n\n2092\nToy Story 3\n1046340665\n200000000\n8.9\n\n\n1962\nPulp Fiction\n212928762\n8000000\n8.9\n\n\n790\nSchindler's List\n321200000\n25000000\n8.9\n\n\n561\nThe Dark Knight\n1022345358\n185000000\n8.9\n\n\n\n\n\n\n\n\n\n3.3.3.2 3.3.3.2 Subsetting the DataFrame by iloc\nwhile iloc uses the position of rows or columns, where position has values 0,1,2,3,…and so on, for rows from top to bottom and columns from left to right. In other words, the first row has position 0, the second row has position 1, the third row has position 2, and so on. Similarly, the first column from left has position 0, the second column from left has position 1, the third column from left has position 2, and so on.\n\n\nCode\nmovie_ratings_sorted.head()\n\n\n\n\n\n\n\n\n\nTitle\nUS Gross\nWorldwide Gross\nProduction Budget\nRelease Date\nMPAA Rating\nSource\nMajor Genre\nCreative Type\nIMDB Rating\nIMDB Votes\n\n\n\n\n182\nThe Shawshank Redemption\n28241469\n28241469\n25000000\nSep 23 1994\nR\nAdapted screenplay\nDrama\nFiction\n9.2\n519541\n\n\n2084\nInception\n285630280\n753830280\n160000000\nJul 16 2010\nPG/PG-13\nOriginal Screenplay\nHorror/Thriller\nFiction\n9.1\n188247\n\n\n2092\nToy Story 3\n410640665\n1046340665\n200000000\nJun 18 2010\nG\nOriginal Screenplay\nAction/Adventure\nFiction\n8.9\n67380\n\n\n1962\nPulp Fiction\n107928762\n212928762\n8000000\nOct 14 1994\nR\nOriginal Screenplay\nDrama\nFiction\n8.9\n417703\n\n\n790\nSchindler's List\n96067179\n321200000\n25000000\nDec 15 1993\nR\nAdapted screenplay\nDrama\nNon-Fiction\n8.9\n276283\n\n\n\n\n\n\n\n\n\nCode\nmovie_ratings_sorted.iloc[0:3,[0,2,3,9]]\n\n\n\n\n\n\n\n\n\nTitle\nWorldwide Gross\nProduction Budget\nIMDB Rating\n\n\n\n\n182\nThe Shawshank Redemption\n28241469\n25000000\n9.2\n\n\n2084\nInception\n753830280\n160000000\n9.1\n\n\n2092\nToy Story 3\n1046340665\n200000000\n8.9\n\n\n\n\n\n\n\n\n\nCode\n# Subsetting the DataFrame by iloc - using index of the position of rows and columns\nmovies_iloc_subset = movie_ratings_sorted.iloc[182:561,[0,2,3,9]]\nmovies_iloc_subset\n\n\n\n\n\n\n\n\n\nTitle\nWorldwide Gross\nProduction Budget\nIMDB Rating\n\n\n\n\n227\nThe Boy in the Striped Pyjamas\n39830581\n12500000\n7.8\n\n\n1463\nLage Raho Munnabhai\n31517561\n2700000\n7.8\n\n\n363\nCoraline\n124062750\n60000000\n7.8\n\n\n1628\nLucky Number Slevin\n55495466\n27000000\n7.8\n\n\n1418\nDark City\n27257061\n27000000\n7.8\n\n\n...\n...\n...\n...\n...\n\n\n1720\nCoach Carter\n76669806\n45000000\n7.1\n\n\n249\nLittle Women\n50003303\n15000000\n7.1\n\n\n1752\nDrag Me To Hell\n85724728\n30000000\n7.1\n\n\n1150\nBlack Snake Moan\n9396870\n15000000\n7.1\n\n\n665\nFind Me Guilty\n1788077\n13000000\n7.1\n\n\n\n\n379 rows × 4 columns\n\n\n\nWhy iloc returns different rows?\n\n\nCode\n# Subsetting the DataFrame by iloc - using index of the position of rows and columns\nmovies_iloc_subset1 = movie_ratings_sorted.iloc[0:10,[0,2,3,9]]\nmovies_iloc_subset1\n\n\n\n\n\n\n\n\n\nTitle\nWorldwide Gross\nProduction Budget\nIMDB Rating\n\n\n\n\n182\nThe Shawshank Redemption\n28241469\n25000000\n9.2\n\n\n2084\nInception\n753830280\n160000000\n9.1\n\n\n2092\nToy Story 3\n1046340665\n200000000\n8.9\n\n\n1962\nPulp Fiction\n212928762\n8000000\n8.9\n\n\n790\nSchindler's List\n321200000\n25000000\n8.9\n\n\n561\nThe Dark Knight\n1022345358\n185000000\n8.9\n\n\n184\nCidade de Deus\n28763397\n3300000\n8.8\n\n\n487\nThe Lord of the Rings: The Fellowship of the Ring\n868621686\n109000000\n8.8\n\n\n497\nThe Lord of the Rings: The Return of the King\n1133027325\n94000000\n8.8\n\n\n1081\nC'era una volta il West\n5321508\n5000000\n8.8\n\n\n\n\n\n\n\n\n\n3.3.3.3 3.3.3.3 Key differences betweenloc and iloc in pandas\n\nIndexing Type:\n\nloc uses labels (names) for indexing.\niloc uses integer positions for indexing.\n\nInclusion of Endpoints:\n\nIn a loc slice, both endpoints are included.\nIn an iloc slice, the endpoint is excluded.\n\n\nExample:\n\n\nCode\n# Assuming you have a DataFrame like this:\nimport pandas as pd\n\ndata = {'A': [1, 2, 3, 4, 5],\n        'B': [10, 20, 30, 40, 50],\n        'C': [100, 200, 300, 400, 500]}\n\ndf = pd.DataFrame(data, index=['row1', 'row2', 'row3', 'row4', 'row5'])\ndf\n\n\n\n\n\n\n\n\n\nA\nB\nC\n\n\n\n\nrow1\n1\n10\n100\n\n\nrow2\n2\n20\n200\n\n\nrow3\n3\n30\n300\n\n\nrow4\n4\n40\n400\n\n\nrow5\n5\n50\n500\n\n\n\n\n\n\n\n\n\nCode\n# using 'loc'\ndf.loc['row2':'row4', 'B']\n\n\nrow2    20\nrow3    30\nrow4    40\nName: B, dtype: int64\n\n\n\n\nCode\n\n# using 'iloc'\ndf.iloc[1:4, 1]\n\n\nrow2    20\nrow3    30\nrow4    40\nName: B, dtype: int64\n\n\nNote that in the loc example, both ‘row2’ and ‘row4’ are included in the result, whereas in the iloc example, the row at position 4 is excluded.\n\n\n\n3.3.4 3.3.4 Extracting rows based on a Single Condition or Multiple Conditions\nIn many cases, we need to filter data based on specific conditions or a combination of multiple conditions. Next, let’s explore how to use these conditions effectively to extract rows that meet our criteria, whether it’s a single condition or multiple conditions combined\n\n\nCode\n# extracting the rows that have IMDB Rating greater than 8\nmovie_ratings[movie_ratings['IMDB Rating'] &gt; 8]\n\n\n\n\n\n\n\n\n\nTitle\nUS Gross\nWorldwide Gross\nProduction Budget\nRelease Date\nMPAA Rating\nSource\nMajor Genre\nCreative Type\nIMDB Rating\nIMDB Votes\nratio_wgross_by_budget\n\n\n\n\n21\nGandhi, My Father\n240425\n1375194\n5000000\nAug 03 2007\nOther\nAdapted screenplay\nDrama\nNon-Fiction\n8.1\n50881\n0.275039\n\n\n56\nEd Wood\n5828466\n5828466\n18000000\nSep 30 1994\nR\nAdapted screenplay\nComedy\nNon-Fiction\n8.1\n74171\n0.323804\n\n\n67\nRequiem for a Dream\n3635482\n7390108\n4500000\nOct 06 2000\nOther\nAdapted screenplay\nDrama\nFiction\n8.5\n185226\n1.642246\n\n\n164\nTrainspotting\n16501785\n24000785\n3100000\nJul 19 1996\nR\nAdapted screenplay\nDrama\nFiction\n8.2\n150483\n7.742189\n\n\n181\nThe Wizard of Oz\n28202232\n28202232\n2777000\nAug 25 2039\nG\nAdapted screenplay\nWestern/Musical\nFiction\n8.3\n102795\n10.155647\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n2090\nFinding Nemo\n339714978\n867894287\n94000000\nMay 30 2003\nG\nOriginal Screenplay\nAction/Adventure\nFiction\n8.2\n165006\n9.232918\n\n\n2092\nToy Story 3\n410640665\n1046340665\n200000000\nJun 18 2010\nG\nOriginal Screenplay\nAction/Adventure\nFiction\n8.9\n67380\n5.231703\n\n\n2094\nAvatar\n760167650\n2767891499\n237000000\nDec 18 2009\nPG/PG-13\nOriginal Screenplay\nAction/Adventure\nFiction\n8.3\n261439\n11.678867\n\n\n2130\nScarface\n44942821\n44942821\n25000000\nDec 09 1983\nOther\nAdapted screenplay\nDrama\nFiction\n8.2\n152262\n1.797713\n\n\n2194\nThe Departed\n133311000\n290539042\n90000000\nOct 06 2006\nR\nAdapted screenplay\nDrama\nFiction\n8.5\n264148\n3.228212\n\n\n\n\n97 rows × 12 columns\n\n\n\nTo combine multiple conditions in pandas, you need to use the & (AND) and | (OR) operators. Make sure to enclose each condition in parentheses () for clarity and to ensure proper evaluation order.\n\n\nCode\n# extracting the rows that have IMDB Rating greater than 8 and US Gross less than 1000000\nmovie_ratings[(movie_ratings['IMDB Rating'] &gt; 8) & (movie_ratings['US Gross'] &lt; 1000000)]\n\n\n\n\n\n\n\n\n\nTitle\nUS Gross\nWorldwide Gross\nProduction Budget\nRelease Date\nMPAA Rating\nSource\nMajor Genre\nCreative Type\nIMDB Rating\nIMDB Votes\nratio_wgross_by_budget\n\n\n\n\n21\nGandhi, My Father\n240425\n1375194\n5000000\nAug 03 2007\nOther\nAdapted screenplay\nDrama\nNon-Fiction\n8.1\n50881\n0.275039\n\n\n636\nLake of Fire\n25317\n25317\n6000000\nOct 03 2007\nOther\nAdapted screenplay\nDocumentary\nNon-Fiction\n8.4\n1027\n0.004220\n\n\n\n\n\n\n\nCombining .loc with condition(s) to extract specific rows and columns based on criteria\n\n\nCode\n# extracting the rows that have IMDB Rating greater than 8 or US Gross less than 1000000, only extract the Title and IMDB Rating columns\nmovie_ratings[(movie_ratings['IMDB Rating'] &gt; 8) & (movie_ratings['US Gross'] &lt; 1000000)][['Title','IMDB Rating']]\n\n#using loc to extract the rows that have IMDB Rating greater than 8 or US Gross less than 1000000, only extract the Title and IMDB Rating columns\nmovie_ratings.loc[(movie_ratings['IMDB Rating'] &gt; 8) & (movie_ratings['US Gross'] &lt; 1000000),['Title','IMDB Rating']]\n\n\n\n\n\n\n\n\n\nTitle\nIMDB Rating\n\n\n\n\n21\nGandhi, My Father\n8.1\n\n\n636\nLake of Fire\n8.4\n\n\n\n\n\n\n\nCan you use .iloc for conditional filtering, why or why not?\n\n\n3.3.5 3.3.5 Finding minimum/maximum of a column\nWhen working with pandas, there are two main options for locating the minimum or maximum values in a DataFrame column:\n\nidxmin() and idxmax(): return the index label of the first occurrence of the maximum or minimum value in a specified column.\n\n\n\nCode\n# movie_ratings_sorted.iloc[position_max_wgross,:]\nmax_index = movie_ratings_sorted['Worldwide Gross'].idxmax()\nmin_index = movie_ratings_sorted['Worldwide Gross'].idxmin()\nprint(\"Max index: \", max_index)\nprint(\"Min index: \", min_index)\n\n\nMax index:  2094\nMin index:  896\n\n\nidxmin() and idxmax() return the index label of the minimum or maximum value in a column. You can use these returned index labels with .loc to extract the corresponding row.\n\n\nCode\nprint(movie_ratings_sorted.loc[max_index,'Worldwide Gross'])\nprint(movie_ratings_sorted.loc[min_index,'Worldwide Gross'])\n\n\n2767891499\n884\n\n\n\nargmax() and argmin(): Return the integer position of the first occurrence of the maximum or minimum value in a column. You can use these integer positions with .iloc to extract the corresponding row\n\n\n\nCode\n# using argmax and argmin, which return the index of the maximum and minimum values\nmax_position = movie_ratings_sorted['Worldwide Gross'].argmax()\nmin_position = movie_ratings_sorted['Worldwide Gross'].argmin()\nprint(\"max position:\", max_position)\nprint(\"min position:\", min_position)\n\n# using iloc to get the row with the maximum and minimum values\nprint(movie_ratings_sorted.iloc[max_position, 2])\nprint(movie_ratings_sorted.iloc[min_position, 2])\n\n\nmax position: 43\nmin position: 2146\n2767891499\n884\n\n\nAdditional Tips: * If you are dealing with non-unique or non-default indices, prefer using idxmax()/idxmin() to get the index labels, as argmax() might be less intuitive in such cases. * For DataFrames, consider using .idxmax(axis=1) or .idxmin(axis=1) to find the max/min index labels along rows instead of columns."
  },
  {
    "objectID": "Reading_data.html#datatype-and-datatype-conversion",
    "href": "Reading_data.html#datatype-and-datatype-conversion",
    "title": "3  Reading Data",
    "section": "3.4 3.4 DataType and DataType Conversion",
    "text": "3.4 3.4 DataType and DataType Conversion\n\n\nCode\nmovie_ratings.dtypes\n\n\nTitle                 object\nUS Gross               int64\nWorldwide Gross        int64\nProduction Budget      int64\nRelease Date          object\nMPAA Rating           object\nSource                object\nMajor Genre           object\nCreative Type         object\nIMDB Rating          float64\nIMDB Votes             int64\ndtype: object\n\n\nThe dtypes property is used to find the dtypes in the DataFrame.\nThis returns a Series with the data type of each column.\n\nWhile it’s common for columns containing strings to have the object data type, it can also include other types such as lists, dictionaries, or even mixed types within the same column. The object data type is a catch-all for columns that contain mixed types or types that aren’t easily categorized.\n\n3.4.1 3.4.1 Available Data Types and Associated Built-in Functions\nIn a DataFrame, columns can have different data types. Here are the common data types you’ll encounter and some built-in functions associated with each type:\n\nNumerical Data (int, float)\n\nBuilt-in functions: mean(), sum(), min(), max(), std(), median(), quantile(), etc.\n\nObject Data (str or mixed types)\n\nBuilt-in functions: str.contains(), str.startswith(), str.endswith(), str.lower(), str.upper(), str.replace(), etc.\n\nDatetime Data (datetime64)\n\nBuilt-in functions: dt.year, dt.month, dt.day, dt.strftime(), dt.weekday(), dt.hour, etc.\n\n\nThese functions help in exploring and transforming the data effectively depending on the type of data in each column.\n\n\n3.4.2 3.4.2 Data Type Conversion\nWhen you work on a specific column, being mindful of which data type it is, the data type depends on its built in function.\nOften, we need to convert the datatypes of some of the columns to make them suitable for analysis. For example, the datatype of Release Date in the DataFrame movie_ratings is object. To perform datetime related computations on this variable, we’ll need to convert it to a datatime format. We’ll use the Pandas function to_datatime() to covert it to a datatime format. Similar functions such as to_numeric(), to_string() etc., can be used for other conversions.\n\n\nCode\nmovie_ratings['Release Date']\n\n\n0       Nov 22 2006\n1       Apr 07 1965\n2       Apr 24 2009\n3       Jul 25 2003\n4       Feb 09 2007\n           ...     \n2223    Jul 07 2004\n2224    Jun 19 1998\n2225    May 14 2010\n2226    Jun 14 1991\n2227    Jan 23 1998\nName: Release Date, Length: 2228, dtype: object\n\n\n\n\nCode\n# check the datatype of release data column \nmovie_ratings['Release Date'].dtypes\n\n\ndtype('O')\n\n\nWe can see above that the function to_datetime() converts Release Date to a datetime format.\nNext, we’ll update the variable Release Date in the DataFrame to be in the datetime format:\n\n\nCode\nmovie_ratings['Release Date'] = pd.to_datetime(movie_ratings['Release Date'])\n\n\n\n\nCode\n# Let's check the datatype of release data column again\nmovie_ratings['Release Date'].dtypes\n\n\ndtype('&lt;M8[ns]')\n\n\ndtype('&lt;M8[ns]') means a 64-bit datetime object with nanosecond precision stored in little-endian format. This data type is commonly used to represent timestamps in high-resolution time series data.\nNext, we can use the built-in datetime functions to extract the year from this variable and create the ‘release year’ column.\n\n\nCode\n# Extracting the year from the release date\nmovie_ratings['Release Year'] = movie_ratings['Release Date'].dt.year\nmovie_ratings.head()\n\n\n\n\n\n\n\n\n\nTitle\nUS Gross\nWorldwide Gross\nProduction Budget\nRelease Date\nMPAA Rating\nSource\nMajor Genre\nCreative Type\nIMDB Rating\nIMDB Votes\nRelease Year\nratio_wgross_by_budget\n\n\n\n\n0\nOpal Dreams\n14443\n14443\n9000000\n2006-11-22\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n6.5\n468\n2006\n0.001605\n\n\n1\nMajor Dundee\n14873\n14873\n3800000\n1965-04-07\nPG/PG-13\nAdapted screenplay\nWestern/Musical\nFiction\n6.7\n2588\n1965\n0.003914\n\n\n2\nThe Informers\n315000\n315000\n18000000\n2009-04-24\nR\nAdapted screenplay\nHorror/Thriller\nFiction\n5.2\n7595\n2009\n0.017500\n\n\n3\nBuffalo Soldiers\n353743\n353743\n15000000\n2003-07-25\nR\nAdapted screenplay\nComedy\nFiction\n6.9\n13510\n2003\n0.023583\n\n\n4\nThe Last Sin Eater\n388390\n388390\n2200000\n2007-02-09\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n5.7\n1012\n2007\n0.176541\n\n\n\n\n\n\n\nIn Pandas, the errors='coerce' parameter is often used in the context of data conversion, specifically when using the pd.to_numeric function. This argument tells Pandas to convert values that it can and set the ones it cannot convert to NaN. It’s a way of gracefully handling errors without raising an exception. Read the textbook for an example\n\n\n3.4.3 3.4.3 Data Type Filtering\nWe can filter the columns based on its data types\n\n\nCode\n\n# select just object columns\nmovie_ratings.select_dtypes(include='object').head()\n\n\n\n\n\n\n\n\n\nTitle\nMPAA Rating\nSource\nMajor Genre\nCreative Type\n\n\n\n\n0\nOpal Dreams\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n\n\n1\nMajor Dundee\nPG/PG-13\nAdapted screenplay\nWestern/Musical\nFiction\n\n\n2\nThe Informers\nR\nAdapted screenplay\nHorror/Thriller\nFiction\n\n\n3\nBuffalo Soldiers\nR\nAdapted screenplay\nComedy\nFiction\n\n\n4\nThe Last Sin Eater\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n\n\n\n\n\n\n\n\n\nCode\n# select the numeric columns\nmovie_ratings.select_dtypes(include='number').head()\n\n\n\n\n\n\n\n\n\nUS Gross\nWorldwide Gross\nProduction Budget\nIMDB Rating\nIMDB Votes\nRelease Year\nratio_wgross_by_budget\n\n\n\n\n0\n14443\n14443\n9000000\n6.5\n468\n2006\n0.001605\n\n\n1\n14873\n14873\n3800000\n6.7\n2588\n1965\n0.003914\n\n\n2\n315000\n315000\n18000000\n5.2\n7595\n2009\n0.017500\n\n\n3\n353743\n353743\n15000000\n6.9\n13510\n2003\n0.023583\n\n\n4\n388390\n388390\n2200000\n5.7\n1012\n2007\n0.176541\n\n\n\n\n\n\n\n\n\n3.4.4 3.4.4 Summary statistics across rows/columns in Pandas: Numeric Columns\nThe Pandas DataFrame class has functions such as sum() and mean() to compute sum over rows or columns of a DataFrame.\nBy default, functions like mean() and sum() compute the statistics for each column (i.e., all rows are aggregated) in the DataFrame. Let us compute the mean of all the numeric columns of the data:\n\n\nCode\nmovie_ratings.describe()\n\n\n\n\n\n\n\n\n\nUS Gross\nWorldwide Gross\nProduction Budget\nIMDB Rating\nIMDB Votes\n\n\n\n\ncount\n2.228000e+03\n2.228000e+03\n2.228000e+03\n2228.000000\n2228.000000\n\n\nmean\n5.076370e+07\n1.019370e+08\n3.816055e+07\n6.239004\n33585.154847\n\n\nstd\n6.643081e+07\n1.648589e+08\n3.782604e+07\n1.243285\n47325.651561\n\n\nmin\n0.000000e+00\n8.840000e+02\n2.180000e+02\n1.400000\n18.000000\n\n\n25%\n9.646188e+06\n1.320737e+07\n1.200000e+07\n5.500000\n6659.250000\n\n\n50%\n2.838649e+07\n4.266892e+07\n2.600000e+07\n6.400000\n18169.000000\n\n\n75%\n6.453140e+07\n1.200000e+08\n5.300000e+07\n7.100000\n40092.750000\n\n\nmax\n7.601676e+08\n2.767891e+09\n3.000000e+08\n9.200000\n519541.000000\n\n\n\n\n\n\n\n\n\nCode\n# select the numeric columns\nmovie_ratings.mean(numeric_only=True)\n\n\nUS Gross                  5.076370e+07\nWorldwide Gross           1.019370e+08\nProduction Budget         3.816055e+07\nIMDB Rating               6.239004e+00\nIMDB Votes                3.358515e+04\nRelease Year              2.002005e+03\nratio_wgross_by_budget    1.259483e+01\ndtype: float64\n\n\nUsing the axis parameter:\nThe axis parameter controls whether to compute the statistic across rows or columns: * The argument axis=0(deafult) denotes that the mean is taken over all the rows of the DataFrame. * For computing a statistic across column the argument axis=1 will be used.\nIf mean over a subset of columns is desired, then those column names can be subset from the data.\nFor example, let us compute the mean IMDB rating, and mean IMDB votes of all the movies:\n\n\nCode\nmovie_ratings[['IMDB Rating','IMDB Votes']].mean(axis = 0)\n\n\nIMDB Rating        6.239004\nIMDB Votes     33585.154847\ndtype: float64\n\n\nPandas sum function\n\n\nCode\ndata = [[10, 18, 11], [13, 15, 8], [9, 20, 3]]\ndf = pd.DataFrame(data )\ndf\n\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n10\n18\n11\n\n\n1\n13\n15\n8\n\n\n2\n9\n20\n3\n\n\n\n\n\n\n\n\n\nCode\n# By default, the sum method adds values accross rows and returns the sum for each column\ndf.sum()\n\n\n0    32\n1    53\n2    22\ndtype: int64\n\n\n\n\nCode\n# By specifying the column axis (axis='columns'), the sum() method add values accross columns and returns the sum of each row.\ndf.sum(axis = 'columns')\n\n\n0    39\n1    36\n2    32\ndtype: int64\n\n\n\n\nCode\n# in python, axis=1 stands for column, while axis=0 stands for rows\ndf.sum(axis = 1)\n\n\n0    39\n1    36\n2    32\ndtype: int64"
  },
  {
    "objectID": "Reading_data.html#writing-data-to-a-.csv-file",
    "href": "Reading_data.html#writing-data-to-a-.csv-file",
    "title": "3  Reading Data",
    "section": "3.5 3.5 Writing data to a .csv file",
    "text": "3.5 3.5 Writing data to a .csv file\nThe Pandas function to_csv can be used to write (or export) data to a csv. Below is an example.\n\n\nCode\n#Exporting the data of the top 250 movies to a csv file\nmovie_ratings.to_csv('../data/movie_rating_exported.csv')\n\n\n\n\nCode\n# check if the file has been exported\nos.listdir('../data')\n\n\n['bestseller_books.txt',\n 'country-capital-lat-long-population.csv',\n 'covid.csv',\n 'fifa_data.csv',\n 'food_quantity.csv',\n 'gas_prices.csv',\n 'gdp_lifeExpectancy.csv',\n 'LOTR 2.csv',\n 'LOTR.csv',\n 'movies.csv',\n 'movies_cleaned.csv',\n 'movie_ratings.csv',\n 'movie_ratings.txt',\n 'movie_rating_exported.csv',\n 'party_nyc.csv',\n 'price.csv',\n 'question_json_data.json',\n 'spotify_data.csv',\n 'stocks.csv']"
  },
  {
    "objectID": "Reading_data.html#reading-other-data-formats---txt-html-json",
    "href": "Reading_data.html#reading-other-data-formats---txt-html-json",
    "title": "3  Reading Data",
    "section": "3.6 3.6 Reading other data formats - txt, html, json",
    "text": "3.6 3.6 Reading other data formats - txt, html, json\nAlthough .csv is a very popular format for structured data, data is found in several other formats as well. Some of the other data formats are .txt, .html and .json.\n\n3.6.1 3.6.1 Reading .txt files\nThe txt format offers some additional flexibility as compared to the csv format. In the csv format, the delimiter is a comma (or the column values are separated by a comma). However, in a txt file, the delimiter can be anything as desired by the user. Let us read the file movie_ratings.txt, where the variable values are separated by a tab character.\n\n\nCode\nmovie_ratings_txt = pd.read_csv('../data/movie_ratings.txt',sep='\\t')\nmovie_ratings_txt.head()\n\n\n\n\n\n\n\n\n\nUnnamed: 0\nTitle\nUS Gross\nWorldwide Gross\nProduction Budget\nRelease Date\nMPAA Rating\nSource\nMajor Genre\nCreative Type\nIMDB Rating\nIMDB Votes\n\n\n\n\n0\n0\nOpal Dreams\n14443\n14443\n9000000\nNov 22 2006\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n6.5\n468\n\n\n1\n1\nMajor Dundee\n14873\n14873\n3800000\nApr 07 1965\nPG/PG-13\nAdapted screenplay\nWestern/Musical\nFiction\n6.7\n2588\n\n\n2\n2\nThe Informers\n315000\n315000\n18000000\nApr 24 2009\nR\nAdapted screenplay\nHorror/Thriller\nFiction\n5.2\n7595\n\n\n3\n3\nBuffalo Soldiers\n353743\n353743\n15000000\nJul 25 2003\nR\nAdapted screenplay\nComedy\nFiction\n6.9\n13510\n\n\n4\n4\nThe Last Sin Eater\n388390\n388390\n2200000\nFeb 09 2007\nPG/PG-13\nAdapted screenplay\nDrama\nFiction\n5.7\n1012\n\n\n\n\n\n\n\nWe use the function read_csv to read a txt file. However, we mention the tab character (r”) as a separator of variable values.\nNote that there is no need to remember the argument name - sep for specifying the delimiter. You can always refer to the read_csv() documentation to find the relevant argument.\n\n\n3.6.2 Practice exercise 4\nRead the file bestseller_books.txt. It contains top 50 best-selling books on amazon from 2009 to 2019. Identify the delimiter without opening the file with Notepad or a text-editing software. How many rows and columns are there in the dataset?\nSolution:\n\n\nCode\n#The delimiter seems to be ';' based on the output of the above code\nbestseller_books = pd.read_csv('../Data/bestseller_books.txt',sep=';')\nbestseller_books.head()\n\n\n\n\n\n\n\n\n\nUnnamed: 0.1\nUnnamed: 0\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n0\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n1\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n2\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n3\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n4\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n\n\n\n\n\n\n\nCode\n#The file read with ';' as the delimited is correct\nprint(\"The file has\",bestseller_books.shape[0],\"rows and\",bestseller_books.shape[1],\"columns\")\n\n\nThe file has 550 rows and 9 columns\n\n\nAlternatively, you can use the argument sep = None, and engine = 'python'. The default engine is C. However, the ‘python’ engine has a ‘sniffer’ tool which may identify the delimiter automatically.\n\n\nCode\nbestseller_books = pd.read_csv('../data/bestseller_books.txt',sep=None, engine = 'python')\nbestseller_books.head()\n\n\n\n\n\n\n\n\n\nUnnamed: 0.1\nUnnamed: 0\nName\nAuthor\nUser Rating\nReviews\nPrice\nYear\nGenre\n\n\n\n\n0\n0\n0\n10-Day Green Smoothie Cleanse\nJJ Smith\n4.7\n17350\n8\n2016\nNon Fiction\n\n\n1\n1\n1\n11/22/63: A Novel\nStephen King\n4.6\n2052\n22\n2011\nFiction\n\n\n2\n2\n2\n12 Rules for Life: An Antidote to Chaos\nJordan B. Peterson\n4.7\n18979\n15\n2018\nNon Fiction\n\n\n3\n3\n3\n1984 (Signet Classics)\nGeorge Orwell\n4.7\n21424\n6\n2017\nFiction\n\n\n4\n4\n4\n5,000 Awesome Facts (About Everything!) (Natio...\nNational Geographic Kids\n4.8\n7665\n12\n2019\nNon Fiction\n\n\n\n\n\n\n\n\n\n3.6.3 3.6.2 Reading HTML data\nThe Pandas function read_html searches for tabular data, i.e., data contained within the &lt;table&gt; tags of an html file. Let us read the tables in the GDP per capita page on Wikipedia.\n\n\nCode\n#Reading all the tables from the Wikipedia page on GDP per capita\ntables = pd.read_html('https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)_per_capita')\n\n\nAll the tables will be read and stored in the variable named as tables. Let us find the datatype of the variable tables.\n\n\nCode\n#Finidng datatype of the variable - tables\ntype(tables)\n\n\nlist\n\n\nThe variable - tables is a list of all the tables read from the HTML data.\n\n\nCode\n#Number of tables read from the page\nlen(tables)\n\n\n6\n\n\nThe in-built function len can be used to find the length of the list - tables or the number of tables read from the Wikipedia page. Let us check out the first table.\n\n\nCode\n#Checking out the first table. Note that the index of the first table will be 0.\ntables[0]\n\n\n\n\n\n\n\n\n\n0\n1\n2\n\n\n\n\n0\n&gt;$60,000 $50,000–$60,000 $40,000–$50,000 $30,0...\n$20,000–$30,000 $10,000–$20,000 $5,000–$10,000...\n$1,000–$2,500 $500–$1,000 &lt;$500 No data\n\n\n\n\n\n\n\nThe above table doesn’t seem to be useful. Let us check out the second table.\n\n\nCode\n#Checking out the second table. Note that the index of the first table will be 1.\ntables[1]\n\n\n\n\n\n\n\n\n\nCountry/Territory\nIMF[4][5]\nWorld Bank[6]\nUnited Nations[7]\n\n\n\nCountry/Territory\nEstimate\nYear\nEstimate\nYear\nEstimate\nYear\n\n\n\n\n0\nMonaco\n—\n—\n240862\n2022\n234317\n2021\n\n\n1\nLiechtenstein\n—\n—\n187267\n2022\n169260\n2021\n\n\n2\nLuxembourg\n131384\n2024\n128259\n2023\n133745\n2021\n\n\n3\nBermuda\n—\n—\n123091\n2022\n112653\n2021\n\n\n4\nIreland\n106059\n2024\n103685\n2023\n101109\n2021\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n218\nMalawi\n481\n2024\n673\n2023\n613\n2021\n\n\n219\nSouth Sudan\n422\n2024\n1072\n2015\n400\n2021\n\n\n220\nAfghanistan\n422\n2022\n353\n2022\n373\n2021\n\n\n221\nSyria\n—\n—\n421\n2021\n925\n2021\n\n\n222\nBurundi\n230\n2024\n200\n2023\n311\n2021\n\n\n\n\n223 rows × 7 columns\n\n\n\nThe above table contains the estimated GDP per capita of all countries. This is the table that is likely to be relevant to a user interested in analyzing GDP per capita of countries. Instead of reading all tables of an HTML file, we can focus the search to tables containing certain relevant keywords. Let us try searching all table containing the word ‘Country’.\n\n\nCode\n#Reading all the tables from the Wikipedia page on GDP per capita, containing the word 'Country'\ntables = pd.read_html('https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)_per_capita', match = 'Country')\n\n\nThe match argument can be used to specify the keywords to be present in the table to be read.\n\n\nCode\nlen(tables)\n\n\n1\n\n\nOnly one table contains the keyword - ‘Country’. Let us check out the table obtained.\n\n\nCode\n#Table having the keyword - 'Country' from the HTML page\ntables[0]\n\n\n\n\n\n\n\n\n\nCountry/Territory\nIMF[4][5]\nWorld Bank[6]\nUnited Nations[7]\n\n\n\nCountry/Territory\nEstimate\nYear\nEstimate\nYear\nEstimate\nYear\n\n\n\n\n0\nMonaco\n—\n—\n240862\n2022\n234317\n2021\n\n\n1\nLiechtenstein\n—\n—\n187267\n2022\n169260\n2021\n\n\n2\nLuxembourg\n131384\n2024\n128259\n2023\n133745\n2021\n\n\n3\nBermuda\n—\n—\n123091\n2022\n112653\n2021\n\n\n4\nIreland\n106059\n2024\n103685\n2023\n101109\n2021\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n218\nMalawi\n481\n2024\n673\n2023\n613\n2021\n\n\n219\nSouth Sudan\n422\n2024\n1072\n2015\n400\n2021\n\n\n220\nAfghanistan\n422\n2022\n353\n2022\n373\n2021\n\n\n221\nSyria\n—\n—\n421\n2021\n925\n2021\n\n\n222\nBurundi\n230\n2024\n200\n2023\n311\n2021\n\n\n\n\n223 rows × 7 columns\n\n\n\nThe argument match helps with a more focussed search, and helps us discard irrelevant tables.\n\n\n3.6.4 Practice exercise 5\nRead the table(s) consisting of attendance of spectators in FIFA worlds cup from this page. Read only those table(s) that have the word ‘attendance’ in them. How many rows and columns are there in the table(s)?\n\n\nCode\ndfs = pd.read_html('https://en.wikipedia.org/wiki/FIFA_World_Cup',\n                       match='reaching')\nprint(len(dfs))\ndata = dfs[0]\nprint(\"Number of rows =\",data.shape[0], \"and number of columns=\",data.shape[1])\ndata.head()\n\n\n1\nNumber of rows = 25 and number of columns= 6\n\n\n\n\n\n\n\n\n\nTeam\nTitles\nRunners-up\nThird place\nFourth place\nTop 4 total\n\n\n\n\n0\nBrazil\n5 (1958, 1962, 1970, 1994, 2002)\n2 (1950 *, 1998)\n2 (1938, 1978)\n2 (1974, 2014 *)\n11\n\n\n1\nGermany1\n4 (1954, 1974 *, 1990, 2014)\n4 (1966, 1982, 1986, 2002)\n4 (1934, 1970, 2006 *, 2010)\n1 (1958)\n13\n\n\n2\nItaly\n4 (1934 *, 1938, 1982, 2006)\n2 (1970, 1994)\n1 (1990 *)\n1 (1978)\n8\n\n\n3\nArgentina\n3 (1978 *, 1986, 2022)\n3 (1930, 1990, 2014)\nNaN\nNaN\n6\n\n\n4\nFrance\n2 (1998 *, 2018)\n2 (2006, 2022)\n2 (1958, 1986)\n1 (1982)\n7\n\n\n\n\n\n\n\n\n\n3.6.5 3.6.3 Reading JSON data\nJSON stands for JavaScript Object Notation, in which the data is stored and transmitted as plain text. A couple of benefits of the JSON format are:\n\nSince the format is text only, JSON data can easily be exchanged between web applications, and used by any programming language.\nUnlike the csv format, JSON supports a hierarchical data structure, and is easier to integrate with APIs.\n\nThe JSON format can support a hierachical data structure, as it is built on the following two data structures (Source: technical documentation):\n\nA collection of name/value pairs. In various languages, this is realized as an object, record, struct, dictionary, hash table, keyed list, or associative array.\nAn ordered list of values. In most languages, this is realized as an array, vector, list, or sequence.\n\nThese are universal data structures. Virtually all modern programming languages support them in one form or another. It makes sense that a data format that is interchangeable with programming languages also be based on these structures.\nThe Pandas function read_json converts a JSON string to a Pandas DataFrame. The function dumps() of the json library converts a Python object to a JSON string.\nLets read the JSON data on Ted Talks.\n\n\nCode\ntedtalks_data = pd.read_json('https://raw.githubusercontent.com/cwkenwaysun/TEDmap/master/data/TED_Talks.json')\n\n\n\n\nCode\ntedtalks_data.head()\n\n\n\n\n\n\n\n\n\nid\nspeaker\nheadline\nURL\ndescription\ntranscript_URL\nmonth_filmed\nyear_filmed\nevent\nduration\ndate_published\ntags\nnewURL\ndate\nviews\nrates\n\n\n\n\n0\n7\nDavid Pogue\nSimplicity sells\nhttp://www.ted.com/talks/view/id/7\nNew York Times columnist David Pogue takes aim...\nhttp://www.ted.com/talks/view/id/7/transcript?...\n2\n2006\nTED2006\n0:21:26\n6/27/06\nsimplicity,computers,software,interface design...\nhttps://www.ted.com/talks/david_pogue_says_sim...\n2006-06-27\n1646773\n[{'id': 7, 'name': 'Funny', 'count': 968}, {'i...\n\n\n1\n6\nCraig Venter\nSampling the ocean's DNA\nhttp://www.ted.com/talks/view/id/6\nGenomics pioneer Craig Venter takes a break fr...\nhttp://www.ted.com/talks/view/id/6/transcript?...\n7\n2005\nTEDGlobal 2005\n0:16:51\n2004/05/07\nbiotech,invention,oceans,genetics,DNA,biology,...\nhttps://www.ted.com/talks/craig_venter_on_dna_...\n2004-05-07\n562625\n[{'id': 3, 'name': 'Courageous', 'count': 21},...\n\n\n2\n4\nBurt Rutan\nThe real future of space exploration\nhttp://www.ted.com/talks/view/id/4\nIn this passionate talk, legendary spacecraft ...\nhttp://www.ted.com/talks/view/id/4/transcript?...\n2\n2006\nTED2006\n0:19:37\n10/25/06\naircraft,flight,industrial design,NASA,rocket ...\nhttps://www.ted.com/talks/burt_rutan_sees_the_...\n2006-10-25\n2046869\n[{'id': 3, 'name': 'Courageous', 'count': 169}...\n\n\n3\n3\nAshraf Ghani\nHow to rebuild a broken state\nhttp://www.ted.com/talks/view/id/3\nAshraf Ghani's passionate and powerful 10-minu...\nhttp://www.ted.com/talks/view/id/3/transcript?...\n7\n2005\nTEDGlobal 2005\n0:18:45\n10/18/06\ncorruption,poverty,economics,investment,milita...\nhttps://www.ted.com/talks/ashraf_ghani_on_rebu...\n2006-10-18\n814554\n[{'id': 3, 'name': 'Courageous', 'count': 140}...\n\n\n4\n5\nChris Bangle\nGreat cars are great art\nhttp://www.ted.com/talks/view/id/5\nAmerican designer Chris Bangle explains his ph...\nhttp://www.ted.com/talks/view/id/5/transcript?...\n2\n2002\nTED2002\n0:20:04\n2004/05/07\ncars,industrial design,transportation,inventio...\nhttps://www.ted.com/talks/chris_bangle_says_gr...\n2004-05-07\n870950\n[{'id': 1, 'name': 'Beautiful', 'count': 89}, ...\n\n\n\n\n\n\n\n\n\n[{'question': \"What is the data type of values in the last column (named 'rates') of the above dataset on ted talks\",\n  'type': 'multiple_choice',\n  'answers': [{'answer': 'list', 'correct': True, 'feedback': 'Correct!'},\n   {'answer': 'string',\n    'correct': False,\n    'feedback': 'Incorrect. Use the type function on the variable to find its datatype.'},\n   {'answer': 'numeric',\n    'correct': False,\n    'feedback': 'Incorrect. Use the type function on the variable to find its datatype.'},\n   {'answer': 'dictionary',\n    'correct': False,\n    'feedback': 'Incorrect. Use the type function on the variable to find its datatype.'}]}]\n\n\nThis JSON data contains nested structures, such as lists and dictionaries, which require a deeper understanding to effectively structure. We will address this in future lectures\n\n\n3.6.6 Practice exercise 6\nRead the movies dataset from here. How many rows and columns are there in the data?\n\n\nCode\nmovies_data = pd.read_json('https://raw.githubusercontent.com/vega/vega-datasets/master/data/movies.json')\nprint(\"Number of rows =\",movies_data.shape[0], \"and number of columns=\",movies_data.shape[1])\n\n\nNumber of rows = 3201 and number of columns= 16\n\n\n\n\n3.6.7 3.6.4 Reading data from a URL in Python\nThis process typically involves using the requests library, which allows you to send HTTP requests and handle responses easily.\nYou’ll need to install it using pip\nWe’ll use the CoinGecko API, which provides cryptocurrency market data. Here’s an example of how to retrieve current market data:\n\n\nCode\nimport requests\n\n# Define the URL of the API\nurl = 'https://api.coingecko.com/api/v3/coins/markets?vs_currency=usd'\n\n# Send a GET request to the URL\nresponse = requests.get(url)\n\n# Check if the request was successful\nif response.status_code == 200:\n    # Parse the JSON data\n    data = response.json()\n    print(data)\nelse:\n    print(f\"Failed to retrieve data: {response.status_code}\")\n\n\n[{'id': 'bitcoin', 'symbol': 'btc', 'name': 'Bitcoin', 'image': 'https://coin-images.coingecko.com/coins/images/1/large/bitcoin.png?1696501400', 'current_price': 62490, 'market_cap': 1235032675967, 'market_cap_rank': 1, 'fully_diluted_valuation': 1312231173412, 'total_volume': 34554624888, 'high_24h': 64500, 'low_24h': 62100, 'price_change_24h': -1170.466984852057, 'price_change_percentage_24h': -1.83862, 'market_cap_change_24h': -23150749922.800293, 'market_cap_change_percentage_24h': -1.84001, 'circulating_supply': 19764571.0, 'total_supply': 21000000.0, 'max_supply': 21000000.0, 'ath': 73738, 'ath_change_percentage': -15.21931, 'ath_date': '2024-03-14T07:10:36.635Z', 'atl': 67.81, 'atl_change_percentage': 92093.56211, 'atl_date': '2013-07-06T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.271Z'}, {'id': 'ethereum', 'symbol': 'eth', 'name': 'Ethereum', 'image': 'https://coin-images.coingecko.com/coins/images/279/large/ethereum.png?1696501628', 'current_price': 2434.1, 'market_cap': 293023922868, 'market_cap_rank': 2, 'fully_diluted_valuation': 293018397207, 'total_volume': 16968707061, 'high_24h': 2518.07, 'low_24h': 2405.58, 'price_change_24h': -53.64323369453086, 'price_change_percentage_24h': -2.1563, 'market_cap_change_24h': -6417354167.597656, 'market_cap_change_percentage_24h': -2.14311, 'circulating_supply': 120379113.24004, 'total_supply': 120376843.206498, 'max_supply': None, 'ath': 4878.26, 'ath_change_percentage': -50.02647, 'ath_date': '2021-11-10T14:24:19.604Z', 'atl': 0.432979, 'atl_change_percentage': 562938.84293, 'atl_date': '2015-10-20T00:00:00.000Z', 'roi': {'times': 51.08601756823208, 'currency': 'btc', 'percentage': 5108.601756823207}, 'last_updated': '2024-10-08T00:54:07.565Z'}, {'id': 'tether', 'symbol': 'usdt', 'name': 'Tether', 'image': 'https://coin-images.coingecko.com/coins/images/325/large/Tether.png?1696501661', 'current_price': 0.999711, 'market_cap': 119827577712, 'market_cap_rank': 3, 'fully_diluted_valuation': 119827577712, 'total_volume': 55698442555, 'high_24h': 1.004, 'low_24h': 0.99633, 'price_change_24h': -0.001198196616044811, 'price_change_percentage_24h': -0.11971, 'market_cap_change_24h': -23449752.259277344, 'market_cap_change_percentage_24h': -0.01957, 'circulating_supply': 119857245003.333, 'total_supply': 119857245003.333, 'max_supply': None, 'ath': 1.32, 'ath_change_percentage': -24.39102, 'ath_date': '2018-07-24T00:00:00.000Z', 'atl': 0.572521, 'atl_change_percentage': 74.73226, 'atl_date': '2015-03-02T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:12.212Z'}, {'id': 'binancecoin', 'symbol': 'bnb', 'name': 'BNB', 'image': 'https://coin-images.coingecko.com/coins/images/825/large/bnb-icon2_2x.png?1696501970', 'current_price': 568.59, 'market_cap': 82947258162, 'market_cap_rank': 4, 'fully_diluted_valuation': 82947258162, 'total_volume': 799134450, 'high_24h': 582.45, 'low_24h': 563.77, 'price_change_24h': -7.260884048894809, 'price_change_percentage_24h': -1.2609, 'market_cap_change_24h': -1068798750.590683, 'market_cap_change_percentage_24h': -1.27214, 'circulating_supply': 145887575.79, 'total_supply': 145887575.79, 'max_supply': 200000000.0, 'ath': 717.48, 'ath_change_percentage': -20.80519, 'ath_date': '2024-06-06T14:10:59.816Z', 'atl': 0.0398177, 'atl_change_percentage': 1426911.78115, 'atl_date': '2017-10-19T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:13.445Z'}, {'id': 'solana', 'symbol': 'sol', 'name': 'Solana', 'image': 'https://coin-images.coingecko.com/coins/images/4128/large/solana.png?1718769756', 'current_price': 144.62, 'market_cap': 67873121370, 'market_cap_rank': 5, 'fully_diluted_valuation': 84775812388, 'total_volume': 3237160849, 'high_24h': 151.52, 'low_24h': 143.59, 'price_change_24h': -4.597486919219733, 'price_change_percentage_24h': -3.081, 'market_cap_change_24h': -2171285003.411751, 'market_cap_change_percentage_24h': -3.09987, 'circulating_supply': 469265730.374483, 'total_supply': 586128687.109744, 'max_supply': None, 'ath': 259.96, 'ath_change_percentage': -44.35227, 'ath_date': '2021-11-06T21:54:35.825Z', 'atl': 0.500801, 'atl_change_percentage': 28785.99929, 'atl_date': '2020-05-11T19:35:23.449Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.774Z'}, {'id': 'usd-coin', 'symbol': 'usdc', 'name': 'USDC', 'image': 'https://coin-images.coingecko.com/coins/images/6319/large/usdc.png?1696506694', 'current_price': 0.99982, 'market_cap': 35336575331, 'market_cap_rank': 6, 'fully_diluted_valuation': 35336582362, 'total_volume': 7937781611, 'high_24h': 1.003, 'low_24h': 0.996693, 'price_change_24h': -0.000988042958259383, 'price_change_percentage_24h': -0.09872, 'market_cap_change_24h': -295654890.59819794, 'market_cap_change_percentage_24h': -0.82974, 'circulating_supply': 35344977832.893, 'total_supply': 35344984865.7762, 'max_supply': None, 'ath': 1.17, 'ath_change_percentage': -14.68676, 'ath_date': '2019-05-08T00:40:28.300Z', 'atl': 0.877647, 'atl_change_percentage': 13.99504, 'atl_date': '2023-03-11T08:02:13.981Z', 'roi': None, 'last_updated': '2024-10-08T00:54:12.579Z'}, {'id': 'ripple', 'symbol': 'xrp', 'name': 'XRP', 'image': 'https://coin-images.coingecko.com/coins/images/44/large/xrp-symbol-white-128.png?1696501442', 'current_price': 0.531761, 'market_cap': 30080966724, 'market_cap_rank': 7, 'fully_diluted_valuation': 53173544466, 'total_volume': 1488925609, 'high_24h': 0.54488, 'low_24h': 0.529092, 'price_change_24h': -0.006764730959881505, 'price_change_percentage_24h': -1.25616, 'market_cap_change_24h': -380244778.19135284, 'market_cap_change_percentage_24h': -1.24829, 'circulating_supply': 56564039920.0, 'total_supply': 99987161962.0, 'max_supply': 100000000000.0, 'ath': 3.4, 'ath_change_percentage': -84.34345, 'ath_date': '2018-01-07T00:00:00.000Z', 'atl': 0.00268621, 'atl_change_percentage': 19707.86295, 'atl_date': '2014-05-22T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.049Z'}, {'id': 'staked-ether', 'symbol': 'steth', 'name': 'Lido Staked Ether', 'image': 'https://coin-images.coingecko.com/coins/images/13442/large/steth_logo.png?1696513206', 'current_price': 2433.54, 'market_cap': 23774301241, 'market_cap_rank': 8, 'fully_diluted_valuation': 23774301241, 'total_volume': 55393440, 'high_24h': 2515.61, 'low_24h': 2405.33, 'price_change_24h': -52.13318341543163, 'price_change_percentage_24h': -2.09734, 'market_cap_change_24h': -622209584.8816986, 'market_cap_change_percentage_24h': -2.5504, 'circulating_supply': 9767026.36285491, 'total_supply': 9767026.36285491, 'max_supply': None, 'ath': 4829.57, 'ath_change_percentage': -49.57783, 'ath_date': '2021-11-10T14:40:47.256Z', 'atl': 482.9, 'atl_change_percentage': 404.28528, 'atl_date': '2020-12-22T04:08:21.854Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.810Z'}, {'id': 'dogecoin', 'symbol': 'doge', 'name': 'Dogecoin', 'image': 'https://coin-images.coingecko.com/coins/images/5/large/dogecoin.png?1696501409', 'current_price': 0.109138, 'market_cap': 15967242014, 'market_cap_rank': 9, 'fully_diluted_valuation': 15967846781, 'total_volume': 994792895, 'high_24h': 0.11513, 'low_24h': 0.108236, 'price_change_24h': -0.004391041308727209, 'price_change_percentage_24h': -3.86778, 'market_cap_change_24h': -629528269.0053463, 'market_cap_change_percentage_24h': -3.79308, 'circulating_supply': 146268586383.705, 'total_supply': 146274126383.705, 'max_supply': None, 'ath': 0.731578, 'ath_change_percentage': -85.08287, 'ath_date': '2021-05-08T05:08:23.458Z', 'atl': 8.69e-05, 'atl_change_percentage': 125476.21875, 'atl_date': '2015-05-06T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.023Z'}, {'id': 'tron', 'symbol': 'trx', 'name': 'TRON', 'image': 'https://coin-images.coingecko.com/coins/images/1094/large/tron-logo.png?1696502193', 'current_price': 0.156189, 'market_cap': 13526695367, 'market_cap_rank': 10, 'fully_diluted_valuation': 13526702713, 'total_volume': 382377142, 'high_24h': 0.156897, 'low_24h': 0.153597, 'price_change_24h': 0.00148677, 'price_change_percentage_24h': 0.96105, 'market_cap_change_24h': 119102470, 'market_cap_change_percentage_24h': 0.88832, 'circulating_supply': 86577032111.108, 'total_supply': 86577079124.0223, 'max_supply': None, 'ath': 0.231673, 'ath_change_percentage': -32.53334, 'ath_date': '2018-01-05T00:00:00.000Z', 'atl': 0.00180434, 'atl_change_percentage': 8562.54313, 'atl_date': '2017-11-12T00:00:00.000Z', 'roi': {'times': 81.20479655054011, 'currency': 'usd', 'percentage': 8120.47965505401}, 'last_updated': '2024-10-08T00:54:05.672Z'}, {'id': 'the-open-network', 'symbol': 'ton', 'name': 'Toncoin', 'image': 'https://coin-images.coingecko.com/coins/images/17980/large/photo_2024-09-10_17.09.00.jpeg?1725963446', 'current_price': 5.23, 'market_cap': 13266378590, 'market_cap_rank': 11, 'fully_diluted_valuation': 26745582651, 'total_volume': 289898643, 'high_24h': 5.38, 'low_24h': 5.19, 'price_change_24h': -0.11581596106146907, 'price_change_percentage_24h': -2.1656, 'market_cap_change_24h': -292964162.0925293, 'market_cap_change_percentage_24h': -2.16061, 'circulating_supply': 2536031815.95331, 'total_supply': 5112747844.44798, 'max_supply': None, 'ath': 8.25, 'ath_change_percentage': -36.61515, 'ath_date': '2024-06-15T00:36:51.509Z', 'atl': 0.519364, 'atl_change_percentage': 907.29703, 'atl_date': '2021-09-21T00:33:11.092Z', 'roi': None, 'last_updated': '2024-10-08T00:54:13.375Z'}, {'id': 'cardano', 'symbol': 'ada', 'name': 'Cardano', 'image': 'https://coin-images.coingecko.com/coins/images/975/large/cardano.png?1696502090', 'current_price': 0.35311, 'market_cap': 12609866405, 'market_cap_rank': 12, 'fully_diluted_valuation': 15891641222, 'total_volume': 323896654, 'high_24h': 0.36763, 'low_24h': 0.350159, 'price_change_24h': -0.007715970856781273, 'price_change_percentage_24h': -2.13842, 'market_cap_change_24h': -274870486.73763466, 'market_cap_change_percentage_24h': -2.1333, 'circulating_supply': 35707072684.8988, 'total_supply': 45000000000.0, 'max_supply': 45000000000.0, 'ath': 3.09, 'ath_change_percentage': -88.54235, 'ath_date': '2021-09-02T06:00:10.474Z', 'atl': 0.01925275, 'atl_change_percentage': 1737.07582, 'atl_date': '2020-03-13T02:22:55.044Z', 'roi': None, 'last_updated': '2024-10-08T00:54:06.319Z'}, {'id': 'avalanche-2', 'symbol': 'avax', 'name': 'Avalanche', 'image': 'https://coin-images.coingecko.com/coins/images/12559/large/Avalanche_Circle_RedWhite_Trans.png?1696512369', 'current_price': 26.86, 'market_cap': 10918471696, 'market_cap_rank': 13, 'fully_diluted_valuation': 11993041109, 'total_volume': 383447410, 'high_24h': 27.69, 'low_24h': 26.52, 'price_change_24h': -0.30149710548148434, 'price_change_percentage_24h': -1.10995, 'market_cap_change_24h': -122018390.50128365, 'market_cap_change_percentage_24h': -1.10519, 'circulating_supply': 406462834.22799, 'total_supply': 446465917.213367, 'max_supply': 720000000.0, 'ath': 144.96, 'ath_change_percentage': -81.48341, 'ath_date': '2021-11-21T14:18:56.538Z', 'atl': 2.8, 'atl_change_percentage': 858.27418, 'atl_date': '2020-12-31T13:15:21.540Z', 'roi': None, 'last_updated': '2024-10-08T00:54:04.331Z'}, {'id': 'shiba-inu', 'symbol': 'shib', 'name': 'Shiba Inu', 'image': 'https://coin-images.coingecko.com/coins/images/11939/large/shiba.png?1696511800', 'current_price': 1.759e-05, 'market_cap': 10365613559, 'market_cap_rank': 14, 'fully_diluted_valuation': 17590632069, 'total_volume': 791497323, 'high_24h': 1.873e-05, 'low_24h': 1.746e-05, 'price_change_24h': -9.50643038621e-07, 'price_change_percentage_24h': -5.12756, 'market_cap_change_24h': -564457717.0176163, 'market_cap_change_percentage_24h': -5.16426, 'circulating_supply': 589258560734548.0, 'total_supply': 999982343215162.0, 'max_supply': None, 'ath': 8.616e-05, 'ath_change_percentage': -79.56469, 'ath_date': '2021-10-28T03:54:55.568Z', 'atl': 5.6366e-11, 'atl_change_percentage': 31236278.95797, 'atl_date': '2020-11-28T11:26:25.838Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.049Z'}, {'id': 'wrapped-steth', 'symbol': 'wsteth', 'name': 'Wrapped stETH', 'image': 'https://coin-images.coingecko.com/coins/images/18834/large/wstETH.png?1696518295', 'current_price': 2870.49, 'market_cap': 10083391703, 'market_cap_rank': 15, 'fully_diluted_valuation': 10083391703, 'total_volume': 57354973, 'high_24h': 2967.08, 'low_24h': 2856.16, 'price_change_24h': -65.57570573917383, 'price_change_percentage_24h': -2.23345, 'market_cap_change_24h': -183962777.72447205, 'market_cap_change_percentage_24h': -1.79173, 'circulating_supply': 3515218.76797872, 'total_supply': 3515218.76797872, 'max_supply': None, 'ath': 7256.02, 'ath_change_percentage': -60.4339, 'ath_date': '2022-05-13T15:09:54.509Z', 'atl': 558.54, 'atl_change_percentage': 414.00503, 'atl_date': '2022-05-13T01:36:45.053Z', 'roi': None, 'last_updated': '2024-10-08T00:54:12.928Z'}, {'id': 'wrapped-bitcoin', 'symbol': 'wbtc', 'name': 'Wrapped Bitcoin', 'image': 'https://coin-images.coingecko.com/coins/images/7598/large/wrapped_bitcoin_wbtc.png?1696507857', 'current_price': 62339, 'market_cap': 9370148390, 'market_cap_rank': 16, 'fully_diluted_valuation': 9370148390, 'total_volume': 173837802, 'high_24h': 64104, 'low_24h': 62051, 'price_change_24h': -1114.1613043298566, 'price_change_percentage_24h': -1.75588, 'market_cap_change_24h': -212142102.48479843, 'market_cap_change_percentage_24h': -2.2139, 'circulating_supply': 150281.33314858, 'total_supply': 150281.33314858, 'max_supply': 150281.33314858, 'ath': 73505, 'ath_change_percentage': -15.19126, 'ath_date': '2024-03-14T07:10:23.403Z', 'atl': 3139.17, 'atl_change_percentage': 1885.84407, 'atl_date': '2019-04-02T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:12.624Z'}, {'id': 'weth', 'symbol': 'weth', 'name': 'WETH', 'image': 'https://coin-images.coingecko.com/coins/images/2518/large/weth.png?1696503332', 'current_price': 2434.35, 'market_cap': 7231757765, 'market_cap_rank': 17, 'fully_diluted_valuation': 7231757765, 'total_volume': 421839130, 'high_24h': 2514.46, 'low_24h': 2412.75, 'price_change_24h': -52.1605917937668, 'price_change_percentage_24h': -2.09774, 'market_cap_change_24h': -167754303.50990772, 'market_cap_change_percentage_24h': -2.2671, 'circulating_supply': 2973433.46470016, 'total_supply': 2973433.46470016, 'max_supply': None, 'ath': 4799.89, 'ath_change_percentage': -49.27022, 'ath_date': '2021-11-09T00:00:00.000Z', 'atl': 82.1, 'atl_change_percentage': 2865.74184, 'atl_date': '2018-12-15T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:04.743Z'}, {'id': 'chainlink', 'symbol': 'link', 'name': 'Chainlink', 'image': 'https://coin-images.coingecko.com/coins/images/877/large/chainlink-new-logo.png?1696502009', 'current_price': 11.22, 'market_cap': 7034017951, 'market_cap_rank': 18, 'fully_diluted_valuation': 11221214442, 'total_volume': 429742466, 'high_24h': 11.74, 'low_24h': 11.11, 'price_change_24h': -0.20415057957979954, 'price_change_percentage_24h': -1.78697, 'market_cap_change_24h': -127373629.90058899, 'market_cap_change_percentage_24h': -1.77862, 'circulating_supply': 626849971.3083414, 'total_supply': 1000000000.0, 'max_supply': 1000000000.0, 'ath': 52.7, 'ath_change_percentage': -78.69639, 'ath_date': '2021-05-10T00:13:57.214Z', 'atl': 0.148183, 'atl_change_percentage': 7475.94449, 'atl_date': '2017-11-29T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:05.960Z'}, {'id': 'bitcoin-cash', 'symbol': 'bch', 'name': 'Bitcoin Cash', 'image': 'https://coin-images.coingecko.com/coins/images/780/large/bitcoin-cash-circle.png?1696501932', 'current_price': 325.66, 'market_cap': 6438369641, 'market_cap_rank': 19, 'fully_diluted_valuation': 6838542455, 'total_volume': 245664732, 'high_24h': 332.33, 'low_24h': 321.68, 'price_change_24h': -2.1671119914790893, 'price_change_percentage_24h': -0.66106, 'market_cap_change_24h': -44835556.588739395, 'market_cap_change_percentage_24h': -0.69156, 'circulating_supply': 19771137.3966508, 'total_supply': 21000000.0, 'max_supply': 21000000.0, 'ath': 3785.82, 'ath_change_percentage': -91.40438, 'ath_date': '2017-12-20T00:00:00.000Z', 'atl': 76.93, 'atl_change_percentage': 322.97489, 'atl_date': '2018-12-16T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.631Z'}, {'id': 'polkadot', 'symbol': 'dot', 'name': 'Polkadot', 'image': 'https://coin-images.coingecko.com/coins/images/12171/large/polkadot.png?1696512008', 'current_price': 4.15, 'market_cap': 5904726419, 'market_cap_rank': 20, 'fully_diluted_valuation': 6240862690, 'total_volume': 179496820, 'high_24h': 4.27, 'low_24h': 4.13, 'price_change_24h': -0.061744048750748355, 'price_change_percentage_24h': -1.46434, 'market_cap_change_24h': -89644363.9776411, 'market_cap_change_percentage_24h': -1.49548, 'circulating_supply': 1421990197.81355, 'total_supply': 1502939330.71355, 'max_supply': None, 'ath': 54.98, 'ath_change_percentage': -92.44717, 'ath_date': '2021-11-04T14:10:09.301Z', 'atl': 2.7, 'atl_change_percentage': 53.94571, 'atl_date': '2020-08-20T05:48:11.359Z', 'roi': None, 'last_updated': '2024-10-08T00:54:04.800Z'}, {'id': 'dai', 'symbol': 'dai', 'name': 'Dai', 'image': 'https://coin-images.coingecko.com/coins/images/9956/large/Badge_Dai.png?1696509996', 'current_price': 0.999811, 'market_cap': 5881292215, 'market_cap_rank': 21, 'fully_diluted_valuation': 5881798975, 'total_volume': 63258183, 'high_24h': 1.003, 'low_24h': 0.994743, 'price_change_24h': -0.000764124895492824, 'price_change_percentage_24h': -0.07637, 'market_cap_change_24h': 3577027, 'market_cap_change_percentage_24h': 0.06086, 'circulating_supply': 5882619286.90039, 'total_supply': 5883126161.262, 'max_supply': None, 'ath': 1.22, 'ath_change_percentage': -17.94271, 'ath_date': '2020-03-13T03:02:50.373Z', 'atl': 0.88196, 'atl_change_percentage': 13.40894, 'atl_date': '2023-03-11T07:50:50.514Z', 'roi': None, 'last_updated': '2024-10-08T00:54:06.710Z'}, {'id': 'sui', 'symbol': 'sui', 'name': 'Sui', 'image': 'https://coin-images.coingecko.com/coins/images/26375/large/sui-ocean-square.png?1727791290', 'current_price': 2.06, 'market_cap': 5685791571, 'market_cap_rank': 22, 'fully_diluted_valuation': 20572061868, 'total_volume': 2077001293, 'high_24h': 2.14, 'low_24h': 1.87, 'price_change_24h': 0.154302, 'price_change_percentage_24h': 8.10887, 'market_cap_change_24h': 415591222, 'market_cap_change_percentage_24h': 7.88568, 'circulating_supply': 2763841372.60889, 'total_supply': 10000000000.0, 'max_supply': 10000000000.0, 'ath': 2.17, 'ath_change_percentage': -5.01098, 'ath_date': '2024-03-27T17:46:02.608Z', 'atl': 0.364846, 'atl_change_percentage': 465.24479, 'atl_date': '2023-10-19T10:40:30.078Z', 'roi': None, 'last_updated': '2024-10-08T00:54:04.265Z'}, {'id': 'near', 'symbol': 'near', 'name': 'NEAR Protocol', 'image': 'https://coin-images.coingecko.com/coins/images/10365/large/near.jpg?1696510367', 'current_price': 5.11, 'market_cap': 5660830269, 'market_cap_rank': 23, 'fully_diluted_valuation': 6049736931, 'total_volume': 576314968, 'high_24h': 5.31, 'low_24h': 5.01, 'price_change_24h': 0.095049, 'price_change_percentage_24h': 1.89681, 'market_cap_change_24h': 113909251, 'market_cap_change_percentage_24h': 2.05356, 'circulating_supply': 1107181322.94878, 'total_supply': 1183246170.6779, 'max_supply': None, 'ath': 20.44, 'ath_change_percentage': -75.01369, 'ath_date': '2022-01-16T22:09:45.873Z', 'atl': 0.526762, 'atl_change_percentage': 869.45631, 'atl_date': '2020-11-04T16:09:15.137Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.280Z'}, {'id': 'leo-token', 'symbol': 'leo', 'name': 'LEO Token', 'image': 'https://coin-images.coingecko.com/coins/images/8418/large/leo-token.png?1696508607', 'current_price': 6.01, 'market_cap': 5560203959, 'market_cap_rank': 24, 'fully_diluted_valuation': 5920434513, 'total_volume': 801407, 'high_24h': 6.05, 'low_24h': 5.93, 'price_change_24h': -0.027411011021039933, 'price_change_percentage_24h': -0.45384, 'market_cap_change_24h': -24784317.658293724, 'market_cap_change_percentage_24h': -0.44377, 'circulating_supply': 925292320.9, 'total_supply': 985239504.0, 'max_supply': None, 'ath': 8.14, 'ath_change_percentage': -25.84331, 'ath_date': '2022-02-08T17:40:10.285Z', 'atl': 0.799859, 'atl_change_percentage': 654.24544, 'atl_date': '2019-12-24T15:14:35.376Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.729Z'}, {'id': 'uniswap', 'symbol': 'uni', 'name': 'Uniswap', 'image': 'https://coin-images.coingecko.com/coins/images/12504/large/uniswap-logo.png?1720676669', 'current_price': 7.24, 'market_cap': 5464326017, 'market_cap_rank': 25, 'fully_diluted_valuation': 7249360122, 'total_volume': 231484762, 'high_24h': 7.46, 'low_24h': 7.17, 'price_change_24h': 0.0370806, 'price_change_percentage_24h': 0.5151, 'market_cap_change_24h': 40188389, 'market_cap_change_percentage_24h': 0.74092, 'circulating_supply': 753766667.0, 'total_supply': 1000000000.0, 'max_supply': 1000000000.0, 'ath': 44.92, 'ath_change_percentage': -83.84698, 'ath_date': '2021-05-03T05:25:04.822Z', 'atl': 1.03, 'atl_change_percentage': 604.31268, 'atl_date': '2020-09-17T01:20:38.214Z', 'roi': None, 'last_updated': '2024-10-08T00:54:12.072Z'}, {'id': 'litecoin', 'symbol': 'ltc', 'name': 'Litecoin', 'image': 'https://coin-images.coingecko.com/coins/images/2/large/litecoin.png?1696501400', 'current_price': 65.04, 'market_cap': 4881816975, 'market_cap_rank': 26, 'fully_diluted_valuation': 5463392544, 'total_volume': 332840383, 'high_24h': 67.87, 'low_24h': 64.44, 'price_change_24h': -2.5680815804710733, 'price_change_percentage_24h': -3.79825, 'market_cap_change_24h': -192122729.2591772, 'market_cap_change_percentage_24h': -3.78646, 'circulating_supply': 75058239.4834713, 'total_supply': 84000000.0, 'max_supply': 84000000.0, 'ath': 410.26, 'ath_change_percentage': -84.11656, 'ath_date': '2021-05-10T03:13:07.904Z', 'atl': 1.15, 'atl_change_percentage': 5572.09067, 'atl_date': '2015-01-14T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:09.994Z'}, {'id': 'bittensor', 'symbol': 'tao', 'name': 'Bittensor', 'image': 'https://coin-images.coingecko.com/coins/images/28452/large/ARUsPeNQ_400x400.jpeg?1696527447', 'current_price': 617.07, 'market_cap': 4554478084, 'market_cap_rank': 27, 'fully_diluted_valuation': 12958100764, 'total_volume': 305713998, 'high_24h': 671.85, 'low_24h': 601.5, 'price_change_24h': -54.06723446710225, 'price_change_percentage_24h': -8.05608, 'market_cap_change_24h': -334381577.4141588, 'market_cap_change_percentage_24h': -6.83966, 'circulating_supply': 7381023.0, 'total_supply': 21000000.0, 'max_supply': 21000000.0, 'ath': 757.6, 'ath_change_percentage': -18.06424, 'ath_date': '2024-03-07T18:45:36.466Z', 'atl': 30.83, 'atl_change_percentage': 1913.46097, 'atl_date': '2023-05-14T08:57:53.732Z', 'roi': None, 'last_updated': '2024-10-08T00:54:05.434Z'}, {'id': 'aptos', 'symbol': 'apt', 'name': 'Aptos', 'image': 'https://coin-images.coingecko.com/coins/images/26455/large/aptos_round.png?1696525528', 'current_price': 8.91, 'market_cap': 4482021558, 'market_cap_rank': 28, 'fully_diluted_valuation': 9975514711, 'total_volume': 559303098, 'high_24h': 9.29, 'low_24h': 8.46, 'price_change_24h': -0.05442955762588575, 'price_change_percentage_24h': -0.6072, 'market_cap_change_24h': -22231350.747354507, 'market_cap_change_percentage_24h': -0.49356, 'circulating_supply': 503104224.342875, 'total_supply': 1119745526.9904, 'max_supply': None, 'ath': 19.92, 'ath_change_percentage': -55.28954, 'ath_date': '2023-01-26T14:25:17.390Z', 'atl': 3.08, 'atl_change_percentage': 189.19136, 'atl_date': '2022-12-29T21:35:14.796Z', 'roi': None, 'last_updated': '2024-10-08T00:54:04.642Z'}, {'id': 'pepe', 'symbol': 'pepe', 'name': 'Pepe', 'image': 'https://coin-images.coingecko.com/coins/images/29850/large/pepe-token.jpeg?1696528776', 'current_price': 9.89e-06, 'market_cap': 4160848085, 'market_cap_rank': 29, 'fully_diluted_valuation': 4160848085, 'total_volume': 2685682892, 'high_24h': 1.075e-05, 'low_24h': 9.79e-06, 'price_change_24h': -5.62021500895e-07, 'price_change_percentage_24h': -5.37525, 'market_cap_change_24h': -237379054.54402733, 'market_cap_change_percentage_24h': -5.39715, 'circulating_supply': 420690000000000.0, 'total_supply': 420690000000000.0, 'max_supply': 420690000000000.0, 'ath': 1.717e-05, 'ath_change_percentage': -42.2268, 'ath_date': '2024-05-27T08:30:07.709Z', 'atl': 5.5142e-08, 'atl_change_percentage': 17885.15417, 'atl_date': '2023-04-18T02:14:41.591Z', 'roi': None, 'last_updated': '2024-10-08T00:54:02.340Z'}, {'id': 'wrapped-eeth', 'symbol': 'weeth', 'name': 'Wrapped eETH', 'image': 'https://coin-images.coingecko.com/coins/images/33033/large/weETH.png?1701438396', 'current_price': 2554.88, 'market_cap': 4038780433, 'market_cap_rank': 30, 'fully_diluted_valuation': 4038780433, 'total_volume': 30073791, 'high_24h': 2635.83, 'low_24h': 2524.51, 'price_change_24h': -56.44659523926384, 'price_change_percentage_24h': -2.16161, 'market_cap_change_24h': -54462725.86518383, 'market_cap_change_percentage_24h': -1.33055, 'circulating_supply': 1580768.11822637, 'total_supply': 1580768.11822637, 'max_supply': None, 'ath': 4196.87, 'ath_change_percentage': -39.06049, 'ath_date': '2024-03-13T08:29:59.938Z', 'atl': 2231.18, 'atl_change_percentage': 14.62807, 'atl_date': '2024-01-08T03:35:28.624Z', 'roi': None, 'last_updated': '2024-10-08T00:54:12.420Z'}, {'id': 'fetch-ai', 'symbol': 'fet', 'name': 'Artificial Superintelligence Alliance', 'image': 'https://coin-images.coingecko.com/coins/images/5681/large/ASI.png?1719827289', 'current_price': 1.49, 'market_cap': 3876658812, 'market_cap_rank': 31, 'fully_diluted_valuation': 4039354437, 'total_volume': 571576675, 'high_24h': 1.55, 'low_24h': 1.46, 'price_change_24h': -0.02254401432244868, 'price_change_percentage_24h': -1.49514, 'market_cap_change_24h': -57053180.25035906, 'market_cap_change_percentage_24h': -1.45036, 'circulating_supply': 2609959126.672, 'total_supply': 2719493896.672, 'max_supply': 2719493896.672, 'ath': 3.45, 'ath_change_percentage': -57.02791, 'ath_date': '2024-03-28T17:21:18.050Z', 'atl': 0.00816959, 'atl_change_percentage': 18068.83315, 'atl_date': '2020-03-13T02:24:18.347Z', 'roi': {'times': 16.131207571263495, 'currency': 'usd', 'percentage': 1613.1207571263494}, 'last_updated': '2024-10-08T00:54:07.419Z'}, {'id': 'internet-computer', 'symbol': 'icp', 'name': 'Internet Computer', 'image': 'https://coin-images.coingecko.com/coins/images/14495/large/Internet_Computer_logo.png?1696514180', 'current_price': 8.13, 'market_cap': 3837481675, 'market_cap_rank': 32, 'fully_diluted_valuation': 4261162155, 'total_volume': 149290724, 'high_24h': 8.64, 'low_24h': 8.04, 'price_change_24h': -0.4425720487875928, 'price_change_percentage_24h': -5.16321, 'market_cap_change_24h': -205014513.86187172, 'market_cap_change_percentage_24h': -5.07148, 'circulating_supply': 471937376.870267, 'total_supply': 524042030.677131, 'max_supply': None, 'ath': 700.65, 'ath_change_percentage': -98.84109, 'ath_date': '2021-05-10T16:05:53.653Z', 'atl': 2.87, 'atl_change_percentage': 183.414, 'atl_date': '2023-09-22T00:29:57.369Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.888Z'}, {'id': 'kaspa', 'symbol': 'kas', 'name': 'Kaspa', 'image': 'https://coin-images.coingecko.com/coins/images/25751/large/kaspa-icon-exchanges.png?1696524837', 'current_price': 0.137693, 'market_cap': 3422402884, 'market_cap_rank': 33, 'fully_diluted_valuation': 3422566689, 'total_volume': 49406266, 'high_24h': 0.147201, 'low_24h': 0.135657, 'price_change_24h': -0.006053383405024011, 'price_change_percentage_24h': -4.21116, 'market_cap_change_24h': -175264701.85171556, 'market_cap_change_percentage_24h': -4.87162, 'circulating_supply': 24864690527.4324, 'total_supply': 24865880619.228, 'max_supply': 28704026601.0, 'ath': 0.207411, 'ath_change_percentage': -33.49467, 'ath_date': '2024-08-01T00:40:47.164Z', 'atl': 0.00017105, 'atl_change_percentage': 80542.92002, 'atl_date': '2022-05-26T14:42:59.316Z', 'roi': None, 'last_updated': '2024-10-08T00:54:09.197Z'}, {'id': 'polygon-ecosystem-token', 'symbol': 'pol', 'name': 'POL (ex-MATIC)', 'image': 'https://coin-images.coingecko.com/coins/images/32440/large/polygon.png?1698233684', 'current_price': 0.376926, 'market_cap': 2844275996, 'market_cap_rank': 34, 'fully_diluted_valuation': 3876780009, 'total_volume': 59628192, 'high_24h': 0.389753, 'low_24h': 0.373173, 'price_change_24h': -0.01072502812598436, 'price_change_percentage_24h': -2.76667, 'market_cap_change_24h': -89083731.41555977, 'market_cap_change_percentage_24h': -3.03692, 'circulating_supply': 7536487650.506331, 'total_supply': 10272317000.3188, 'max_supply': None, 'ath': 1.29, 'ath_change_percentage': -70.69669, 'ath_date': '2024-03-13T18:55:06.692Z', 'atl': 0.344976, 'atl_change_percentage': 9.36936, 'atl_date': '2024-08-05T06:45:46.141Z', 'roi': None, 'last_updated': '2024-10-08T00:53:49.166Z'}, {'id': 'ethereum-classic', 'symbol': 'etc', 'name': 'Ethereum Classic', 'image': 'https://coin-images.coingecko.com/coins/images/453/large/ethereum-classic-logo.png?1696501717', 'current_price': 18.7, 'market_cap': 2787253411, 'market_cap_rank': 35, 'fully_diluted_valuation': 3940186706, 'total_volume': 115562256, 'high_24h': 19.1, 'low_24h': 18.54, 'price_change_24h': -0.2404127891239547, 'price_change_percentage_24h': -1.26933, 'market_cap_change_24h': -34460136.58007479, 'market_cap_change_percentage_24h': -1.22125, 'circulating_supply': 149047326.285244, 'total_supply': 210700000.0, 'max_supply': 210700000.0, 'ath': 167.09, 'ath_change_percentage': -88.80786, 'ath_date': '2021-05-06T18:34:22.133Z', 'atl': 0.615038, 'atl_change_percentage': 2940.53103, 'atl_date': '2016-07-25T00:00:00.000Z', 'roi': {'times': 40.55485369483518, 'currency': 'usd', 'percentage': 4055.485369483518}, 'last_updated': '2024-10-08T00:54:08.346Z'}, {'id': 'stellar', 'symbol': 'xlm', 'name': 'Stellar', 'image': 'https://coin-images.coingecko.com/coins/images/100/large/Stellar_symbol_black_RGB.png?1696501482', 'current_price': 0.091505, 'market_cap': 2718689271, 'market_cap_rank': 36, 'fully_diluted_valuation': 4575830767, 'total_volume': 55794210, 'high_24h': 0.093297, 'low_24h': 0.090686, 'price_change_24h': -0.001792341838620773, 'price_change_percentage_24h': -1.92111, 'market_cap_change_24h': -51736126.038962364, 'market_cap_change_percentage_24h': -1.86744, 'circulating_supply': 29708118282.3443, 'total_supply': 50001786931.8027, 'max_supply': 50001786931.8027, 'ath': 0.875563, 'ath_change_percentage': -89.54997, 'ath_date': '2018-01-03T00:00:00.000Z', 'atl': 0.00047612, 'atl_change_percentage': 19116.98588, 'atl_date': '2015-03-05T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.358Z'}, {'id': 'monero', 'symbol': 'xmr', 'name': 'Monero', 'image': 'https://coin-images.coingecko.com/coins/images/69/large/monero_logo.png?1696501460', 'current_price': 144.06, 'market_cap': 2658495109, 'market_cap_rank': 37, 'fully_diluted_valuation': 2658495109, 'total_volume': 49881391, 'high_24h': 148.72, 'low_24h': 143.98, 'price_change_24h': -4.402376663747191, 'price_change_percentage_24h': -2.96526, 'market_cap_change_24h': -79142990.84689522, 'market_cap_change_percentage_24h': -2.89092, 'circulating_supply': 18446744.0737096, 'total_supply': 18446744.0737096, 'max_supply': None, 'ath': 542.33, 'ath_change_percentage': -73.40115, 'ath_date': '2018-01-09T00:00:00.000Z', 'atl': 0.216177, 'atl_change_percentage': 66628.90964, 'atl_date': '2015-01-14T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:12.179Z'}, {'id': 'blockstack', 'symbol': 'stx', 'name': 'Stacks', 'image': 'https://coin-images.coingecko.com/coins/images/2069/large/Stacks_Logo_png.png?1709979332', 'current_price': 1.77, 'market_cap': 2636405645, 'market_cap_rank': 38, 'fully_diluted_valuation': 2636405645, 'total_volume': 148650701, 'high_24h': 1.88, 'low_24h': 1.76, 'price_change_24h': -0.10597245605099315, 'price_change_percentage_24h': -5.65908, 'market_cap_change_24h': -157654404.66367483, 'market_cap_change_percentage_24h': -5.64248, 'circulating_supply': 1492329684.93845, 'total_supply': 1492329684.93845, 'max_supply': 1818000000.0, 'ath': 3.86, 'ath_change_percentage': -54.22821, 'ath_date': '2024-04-01T12:34:58.342Z', 'atl': 0.04559639, 'atl_change_percentage': 3779.18767, 'atl_date': '2020-03-13T02:29:26.415Z', 'roi': {'times': 13.721979508556592, 'currency': 'usd', 'percentage': 1372.1979508556592}, 'last_updated': '2024-10-08T00:54:05.953Z'}, {'id': 'first-digital-usd', 'symbol': 'fdusd', 'name': 'First Digital USD', 'image': 'https://coin-images.coingecko.com/coins/images/31079/large/firstfigital.jpeg?1696529912', 'current_price': 0.999501, 'market_cap': 2614879689, 'market_cap_rank': 39, 'fully_diluted_valuation': 2614879689, 'total_volume': 5277645305, 'high_24h': 1.009, 'low_24h': 0.989271, 'price_change_24h': -0.002162259148526635, 'price_change_percentage_24h': -0.21587, 'market_cap_change_24h': -2509489.620900631, 'market_cap_change_percentage_24h': -0.09588, 'circulating_supply': 2616235583.37, 'total_supply': 2616235583.37, 'max_supply': None, 'ath': 1.089, 'ath_change_percentage': -8.09515, 'ath_date': '2024-05-20T19:42:15.377Z', 'atl': 0.942129, 'atl_change_percentage': 6.18864, 'atl_date': '2023-08-17T21:55:41.478Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.584Z'}, {'id': 'dogwifcoin', 'symbol': 'wif', 'name': 'dogwifhat', 'image': 'https://coin-images.coingecko.com/coins/images/33566/large/dogwifhat.jpg?1702499428', 'current_price': 2.56, 'market_cap': 2553931562, 'market_cap_rank': 40, 'fully_diluted_valuation': 2553931562, 'total_volume': 1577781813, 'high_24h': 2.77, 'low_24h': 2.52, 'price_change_24h': -0.07085253704175454, 'price_change_percentage_24h': -2.69691, 'market_cap_change_24h': -69753420.44635868, 'market_cap_change_percentage_24h': -2.65861, 'circulating_supply': 998926392.0, 'total_supply': 998926392.0, 'max_supply': 998926392.0, 'ath': 4.83, 'ath_change_percentage': -47.0231, 'ath_date': '2024-03-31T09:34:58.366Z', 'atl': 0.00155464, 'atl_change_percentage': 164335.54227, 'atl_date': '2023-12-13T07:13:50.873Z', 'roi': None, 'last_updated': '2024-10-08T00:54:06.464Z'}, {'id': 'okb', 'symbol': 'okb', 'name': 'OKB', 'image': 'https://coin-images.coingecko.com/coins/images/4463/large/WeChat_Image_20220118095654.png?1696505053', 'current_price': 41.75, 'market_cap': 2504875206, 'market_cap_rank': 41, 'fully_diluted_valuation': 9850742591, 'total_volume': 3021964, 'high_24h': 42.23, 'low_24h': 41.49, 'price_change_24h': 0.133862, 'price_change_percentage_24h': 0.32167, 'market_cap_change_24h': 9021972, 'market_cap_change_percentage_24h': 0.36148, 'circulating_supply': 60000000.0, 'total_supply': 235957685.3, 'max_supply': 300000000.0, 'ath': 73.8, 'ath_change_percentage': -43.40078, 'ath_date': '2024-03-14T00:30:12.502Z', 'atl': 0.580608, 'atl_change_percentage': 7094.54711, 'atl_date': '2019-01-14T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.193Z'}, {'id': 'ethena-usde', 'symbol': 'usde', 'name': 'Ethena USDe', 'image': 'https://coin-images.coingecko.com/coins/images/33613/large/USDE.png?1716355685', 'current_price': 0.998868, 'market_cap': 2475501311, 'market_cap_rank': 42, 'fully_diluted_valuation': 2475501311, 'total_volume': 42239822, 'high_24h': 1.001, 'low_24h': 0.99399, 'price_change_24h': -0.000324026932799759, 'price_change_percentage_24h': -0.03243, 'market_cap_change_24h': -735411.9714083672, 'market_cap_change_percentage_24h': -0.0297, 'circulating_supply': 2478118745.28326, 'total_supply': 2478118745.28326, 'max_supply': None, 'ath': 1.032, 'ath_change_percentage': -3.18123, 'ath_date': '2023-12-20T15:38:34.596Z', 'atl': 0.929486, 'atl_change_percentage': 7.50557, 'atl_date': '2024-10-04T07:57:15.809Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.938Z'}, {'id': 'immutable-x', 'symbol': 'imx', 'name': 'Immutable', 'image': 'https://coin-images.coingecko.com/coins/images/17233/large/immutableX-symbol-BLK-RGB.png?1696516787', 'current_price': 1.49, 'market_cap': 2399110937, 'market_cap_rank': 43, 'fully_diluted_valuation': 2988988709, 'total_volume': 98646439, 'high_24h': 1.58, 'low_24h': 1.48, 'price_change_24h': -0.04880323823546994, 'price_change_percentage_24h': -3.16226, 'market_cap_change_24h': -77613561.05947065, 'market_cap_change_percentage_24h': -3.13372, 'circulating_supply': 1605299431.3898141, 'total_supply': 2000000000.0, 'max_supply': 2000000000.0, 'ath': 9.52, 'ath_change_percentage': -84.26299, 'ath_date': '2021-11-26T01:03:01.536Z', 'atl': 0.378055, 'atl_change_percentage': 296.27954, 'atl_date': '2022-12-31T07:36:37.649Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.984Z'}, {'id': 'filecoin', 'symbol': 'fil', 'name': 'Filecoin', 'image': 'https://coin-images.coingecko.com/coins/images/12817/large/filecoin.png?1696512609', 'current_price': 3.74, 'market_cap': 2212048994, 'market_cap_rank': 44, 'fully_diluted_valuation': 7333073696, 'total_volume': 220501731, 'high_24h': 3.81, 'low_24h': 3.69, 'price_change_24h': 0.00388424, 'price_change_percentage_24h': 0.10391, 'market_cap_change_24h': 3262126, 'market_cap_change_percentage_24h': 0.14769, 'circulating_supply': 591219863.0, 'total_supply': 1959928934.0, 'max_supply': 1959928934.0, 'ath': 236.84, 'ath_change_percentage': -98.42174, 'ath_date': '2021-04-01T13:29:41.564Z', 'atl': 2.64, 'atl_change_percentage': 41.53757, 'atl_date': '2022-12-16T22:45:28.552Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.874Z'}, {'id': 'aave', 'symbol': 'aave', 'name': 'Aave', 'image': 'https://coin-images.coingecko.com/coins/images/12645/large/aave-token-round.png?1720472354', 'current_price': 146.68, 'market_cap': 2192912572, 'market_cap_rank': 45, 'fully_diluted_valuation': 2346687419, 'total_volume': 317227189, 'high_24h': 154.37, 'low_24h': 145.63, 'price_change_24h': -5.858279094344567, 'price_change_percentage_24h': -3.84065, 'market_cap_change_24h': -87181126.71949911, 'market_cap_change_percentage_24h': -3.82358, 'circulating_supply': 14951544.4115039, 'total_supply': 16000000.0, 'max_supply': 16000000.0, 'ath': 661.69, 'ath_change_percentage': -77.76392, 'ath_date': '2021-05-18T21:19:59.514Z', 'atl': 26.02, 'atl_change_percentage': 465.39646, 'atl_date': '2020-11-05T09:20:11.928Z', 'roi': None, 'last_updated': '2024-10-08T00:54:13.358Z'}, {'id': 'crypto-com-chain', 'symbol': 'cro', 'name': 'Cronos', 'image': 'https://coin-images.coingecko.com/coins/images/7310/large/cro_token_logo.png?1696507599', 'current_price': 0.078844, 'market_cap': 2129405535, 'market_cap_rank': 46, 'fully_diluted_valuation': 2364898273, 'total_volume': 5713307, 'high_24h': 0.081471, 'low_24h': 0.078325, 'price_change_24h': -0.002135162614234229, 'price_change_percentage_24h': -2.63669, 'market_cap_change_24h': -60340163.39772034, 'market_cap_change_percentage_24h': -2.75558, 'circulating_supply': 27012648607.4253, 'total_supply': 30000000000.0, 'max_supply': None, 'ath': 0.965407, 'ath_change_percentage': -91.82827, 'ath_date': '2021-11-24T15:53:54.855Z', 'atl': 0.0121196, 'atl_change_percentage': 550.93336, 'atl_date': '2019-02-08T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.102Z'}, {'id': 'optimism', 'symbol': 'op', 'name': 'Optimism', 'image': 'https://coin-images.coingecko.com/coins/images/25244/large/Optimism.png?1696524385', 'current_price': 1.67, 'market_cap': 2101136824, 'market_cap_rank': 47, 'fully_diluted_valuation': 7190284537, 'total_volume': 218428886, 'high_24h': 1.73, 'low_24h': 1.64, 'price_change_24h': -0.03476149712388876, 'price_change_percentage_24h': -2.03669, 'market_cap_change_24h': -39040505.690792084, 'market_cap_change_percentage_24h': -1.82417, 'circulating_supply': 1255070491.0, 'total_supply': 4294967296.0, 'max_supply': 4294967296.0, 'ath': 4.84, 'ath_change_percentage': -65.39861, 'ath_date': '2024-03-06T08:35:50.817Z', 'atl': 0.402159, 'atl_change_percentage': 316.79983, 'atl_date': '2022-06-18T20:54:52.178Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.229Z'}, {'id': 'render-token', 'symbol': 'render', 'name': 'Render', 'image': 'https://coin-images.coingecko.com/coins/images/11636/large/rndr.png?1696511529', 'current_price': 5.32, 'market_cap': 2086965284, 'market_cap_rank': 48, 'fully_diluted_valuation': 2830162803, 'total_volume': 189902209, 'high_24h': 5.66, 'low_24h': 5.25, 'price_change_24h': -0.23595866218748007, 'price_change_percentage_24h': -4.24782, 'market_cap_change_24h': -90450600.43532825, 'market_cap_change_percentage_24h': -4.15403, 'circulating_supply': 392459381.455492, 'total_supply': 532219654.735492, 'max_supply': None, 'ath': 13.53, 'ath_change_percentage': -60.69465, 'ath_date': '2024-03-17T16:30:24.636Z', 'atl': 0.03665669, 'atl_change_percentage': 14412.65249, 'atl_date': '2020-06-16T13:22:25.900Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.739Z'}, {'id': 'injective-protocol', 'symbol': 'inj', 'name': 'Injective', 'image': 'https://coin-images.coingecko.com/coins/images/12882/large/Secondary_Symbol.png?1696512670', 'current_price': 20.63, 'market_cap': 2020107435, 'market_cap_rank': 49, 'fully_diluted_valuation': 2067087743, 'total_volume': 162234744, 'high_24h': 21.68, 'low_24h': 20.41, 'price_change_24h': -0.5420461942348993, 'price_change_percentage_24h': -2.56032, 'market_cap_change_24h': -38736183.09372449, 'market_cap_change_percentage_24h': -1.88145, 'circulating_supply': 97727222.33, 'total_supply': 100000000.0, 'max_supply': None, 'ath': 52.62, 'ath_change_percentage': -60.76848, 'ath_date': '2024-03-14T15:06:22.124Z', 'atl': 0.657401, 'atl_change_percentage': 3040.22836, 'atl_date': '2020-11-03T16:19:30.576Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.301Z'}, {'id': 'arbitrum', 'symbol': 'arb', 'name': 'Arbitrum', 'image': 'https://coin-images.coingecko.com/coins/images/16547/large/arb.jpg?1721358242', 'current_price': 0.55172, 'market_cap': 1995610038, 'market_cap_rank': 50, 'fully_diluted_valuation': 5517172560, 'total_volume': 305793045, 'high_24h': 0.574299, 'low_24h': 0.549433, 'price_change_24h': -0.01640000679415732, 'price_change_percentage_24h': -2.88672, 'market_cap_change_24h': -58973496.59108758, 'market_cap_change_percentage_24h': -2.87034, 'circulating_supply': 3617088312.0, 'total_supply': 10000000000.0, 'max_supply': 10000000000.0, 'ath': 2.39, 'ath_change_percentage': -76.88637, 'ath_date': '2024-01-12T12:29:59.231Z', 'atl': 0.431578, 'atl_change_percentage': 28.01435, 'atl_date': '2024-08-05T11:35:54.024Z', 'roi': None, 'last_updated': '2024-10-08T00:54:12.965Z'}, {'id': 'hedera-hashgraph', 'symbol': 'hbar', 'name': 'Hedera', 'image': 'https://coin-images.coingecko.com/coins/images/3688/large/hbar.png?1696504364', 'current_price': 0.052714, 'market_cap': 1984767944, 'market_cap_rank': 51, 'fully_diluted_valuation': 2635626384, 'total_volume': 58643085, 'high_24h': 0.055465, 'low_24h': 0.052442, 'price_change_24h': -0.002289720403595014, 'price_change_percentage_24h': -4.16286, 'market_cap_change_24h': -87166884.84962511, 'market_cap_change_percentage_24h': -4.20703, 'circulating_supply': 37652680130.7546, 'total_supply': 50000000000.0, 'max_supply': 50000000000.0, 'ath': 0.569229, 'ath_change_percentage': -90.73263, 'ath_date': '2021-09-15T10:40:28.318Z', 'atl': 0.00986111, 'atl_change_percentage': 434.95523, 'atl_date': '2020-01-02T17:30:24.852Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.816Z'}, {'id': 'mantle', 'symbol': 'mnt', 'name': 'Mantle', 'image': 'https://coin-images.coingecko.com/coins/images/30980/large/token-logo.png?1696529819', 'current_price': 0.594723, 'market_cap': 1942595143, 'market_cap_rank': 52, 'fully_diluted_valuation': 3698255282, 'total_volume': 83557233, 'high_24h': 0.617403, 'low_24h': 0.590237, 'price_change_24h': -0.020384026293793656, 'price_change_percentage_24h': -3.3139, 'market_cap_change_24h': -65637588.91737676, 'market_cap_change_percentage_24h': -3.26843, 'circulating_supply': 3266841707.83684, 'total_supply': 6219316794.99, 'max_supply': 6219316794.99, 'ath': 1.54, 'ath_change_percentage': -61.31909, 'ath_date': '2024-04-08T09:45:25.482Z', 'atl': 0.307978, 'atl_change_percentage': 93.25706, 'atl_date': '2023-10-18T02:50:46.942Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.666Z'}, {'id': 'fantom', 'symbol': 'ftm', 'name': 'Fantom', 'image': 'https://coin-images.coingecko.com/coins/images/4001/large/Fantom_round.png?1696504642', 'current_price': 0.680296, 'market_cap': 1904364725, 'market_cap_rank': 53, 'fully_diluted_valuation': 2156613951, 'total_volume': 442766255, 'high_24h': 0.692213, 'low_24h': 0.643663, 'price_change_24h': 0.02108022, 'price_change_percentage_24h': 3.19777, 'market_cap_change_24h': 51058008, 'market_cap_change_percentage_24h': 2.75497, 'circulating_supply': 2803634835.52659, 'total_supply': 3175000000.0, 'max_supply': 3175000000.0, 'ath': 3.46, 'ath_change_percentage': -80.42443, 'ath_date': '2021-10-28T05:19:39.845Z', 'atl': 0.00190227, 'atl_change_percentage': 35490.93498, 'atl_date': '2020-03-13T02:25:38.280Z', 'roi': {'times': 21.676526443109893, 'currency': 'usd', 'percentage': 2167.652644310989}, 'last_updated': '2024-10-08T00:54:08.083Z'}, {'id': 'vechain', 'symbol': 'vet', 'name': 'VeChain', 'image': 'https://coin-images.coingecko.com/coins/images/1167/large/VET_Token_Icon.png?1710013505', 'current_price': 0.02305745, 'market_cap': 1866097633, 'market_cap_rank': 54, 'fully_diluted_valuation': 1981310122, 'total_volume': 33029041, 'high_24h': 0.02413624, 'low_24h': 0.02287468, 'price_change_24h': -0.000579121553516551, 'price_change_percentage_24h': -2.45011, 'market_cap_change_24h': -48530189.73806381, 'market_cap_change_percentage_24h': -2.53471, 'circulating_supply': 80985041177.0, 'total_supply': 85985041177.0, 'max_supply': 86712634466.0, 'ath': 0.280991, 'ath_change_percentage': -91.78701, 'ath_date': '2021-04-19T01:08:21.675Z', 'atl': 0.00191713, 'atl_change_percentage': 1103.76506, 'atl_date': '2020-03-13T02:29:59.652Z', 'roi': {'times': 2.315297764204298, 'currency': 'eth', 'percentage': 231.52977642042976}, 'last_updated': '2024-10-08T00:54:04.449Z'}, {'id': 'cosmos', 'symbol': 'atom', 'name': 'Cosmos Hub', 'image': 'https://coin-images.coingecko.com/coins/images/1481/large/cosmos_hub.png?1696502525', 'current_price': 4.44, 'market_cap': 1735226482, 'market_cap_rank': 55, 'fully_diluted_valuation': 1736299828, 'total_volume': 157094956, 'high_24h': 4.78, 'low_24h': 4.42, 'price_change_24h': -0.2745205030004252, 'price_change_percentage_24h': -5.82303, 'market_cap_change_24h': -106653058.32591224, 'market_cap_change_percentage_24h': -5.79045, 'circulating_supply': 390688369.813272, 'total_supply': 390930035.085365, 'max_supply': None, 'ath': 44.45, 'ath_change_percentage': -90.00078, 'ath_date': '2022-01-17T00:34:41.497Z', 'atl': 1.16, 'atl_change_percentage': 283.12318, 'atl_date': '2020-03-13T02:27:44.591Z', 'roi': {'times': 43.39870942426602, 'currency': 'usd', 'percentage': 4339.870942426602}, 'last_updated': '2024-10-08T00:54:06.660Z'}, {'id': 'thorchain', 'symbol': 'rune', 'name': 'THORChain', 'image': 'https://coin-images.coingecko.com/coins/images/6595/large/Rune200x200.png?1696506946', 'current_price': 5.09, 'market_cap': 1713439020, 'market_cap_rank': 56, 'fully_diluted_valuation': 2107376729, 'total_volume': 436029070, 'high_24h': 5.32, 'low_24h': 4.99, 'price_change_24h': 0.092116, 'price_change_percentage_24h': 1.8445, 'market_cap_change_24h': 30384714, 'market_cap_change_percentage_24h': 1.80533, 'circulating_supply': 336760873.0, 'total_supply': 414185751.0, 'max_supply': 500000000.0, 'ath': 20.87, 'ath_change_percentage': -75.60622, 'ath_date': '2021-05-19T00:30:09.436Z', 'atl': 0.00851264, 'atl_change_percentage': 59698.01566, 'atl_date': '2019-09-28T00:00:00.000Z', 'roi': {'times': 132.84719235436123, 'currency': 'usd', 'percentage': 13284.719235436123}, 'last_updated': '2024-10-08T00:54:11.506Z'}, {'id': 'whitebit', 'symbol': 'wbt', 'name': 'WhiteBIT Coin', 'image': 'https://coin-images.coingecko.com/coins/images/27045/large/wbt_token.png?1696526096', 'current_price': 11.61, 'market_cap': 1672767757, 'market_cap_rank': 57, 'fully_diluted_valuation': 3986192957, 'total_volume': 5269580, 'high_24h': 11.74, 'low_24h': 11.45, 'price_change_24h': 0.054923, 'price_change_percentage_24h': 0.47536, 'market_cap_change_24h': 8356197, 'market_cap_change_percentage_24h': 0.50205, 'circulating_supply': 144118517.10815412, 'total_supply': 343433340.0, 'max_supply': 400000000.0, 'ath': 14.64, 'ath_change_percentage': -20.66611, 'ath_date': '2022-10-28T12:32:18.119Z', 'atl': 3.06, 'atl_change_percentage': 279.46514, 'atl_date': '2023-02-13T19:01:21.899Z', 'roi': None, 'last_updated': '2024-10-08T00:54:12.576Z'}, {'id': 'the-graph', 'symbol': 'grt', 'name': 'The Graph', 'image': 'https://coin-images.coingecko.com/coins/images/13397/large/Graph_Token.png?1696513159', 'current_price': 0.16643, 'market_cap': 1590930683, 'market_cap_rank': 58, 'fully_diluted_valuation': 1797445718, 'total_volume': 74994229, 'high_24h': 0.175174, 'low_24h': 0.164311, 'price_change_24h': -0.002237407739360153, 'price_change_percentage_24h': -1.32652, 'market_cap_change_24h': -19839233.915035248, 'market_cap_change_percentage_24h': -1.23166, 'circulating_supply': 9548531509.16547, 'total_supply': 10788004319.0, 'max_supply': 10788004319.0, 'ath': 2.84, 'ath_change_percentage': -94.13502, 'ath_date': '2021-02-12T07:28:45.775Z', 'atl': 0.052051, 'atl_change_percentage': 220.17379, 'atl_date': '2022-11-22T10:05:03.503Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.707Z'}, {'id': 'sei-network', 'symbol': 'sei', 'name': 'Sei', 'image': 'https://coin-images.coingecko.com/coins/images/28205/large/Sei_Logo_-_Transparent.png?1696527207', 'current_price': 0.436364, 'market_cap': 1537777839, 'market_cap_rank': 59, 'fully_diluted_valuation': 4362662218, 'total_volume': 385107557, 'high_24h': 0.45975, 'low_24h': 0.425647, 'price_change_24h': -0.012570966005509167, 'price_change_percentage_24h': -2.80018, 'market_cap_change_24h': -44875622.576061964, 'market_cap_change_percentage_24h': -2.83547, 'circulating_supply': 3524861111.0, 'total_supply': 10000000000.0, 'max_supply': None, 'ath': 1.14, 'ath_change_percentage': -61.71689, 'ath_date': '2024-03-16T02:30:23.904Z', 'atl': 0.095364, 'atl_change_percentage': 357.53176, 'atl_date': '2023-10-19T08:05:30.655Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.382Z'}, {'id': 'bitget-token', 'symbol': 'bgb', 'name': 'Bitget Token', 'image': 'https://coin-images.coingecko.com/coins/images/11610/large/icon_colour.png?1696511504', 'current_price': 1.075, 'market_cap': 1505112149, 'market_cap_rank': 60, 'fully_diluted_valuation': 2150158677, 'total_volume': 4809367, 'high_24h': 1.14, 'low_24h': 0.641602, 'price_change_24h': -0.029675512038628504, 'price_change_percentage_24h': -2.68607, 'market_cap_change_24h': -41599600.1858089, 'market_cap_change_percentage_24h': -2.68955, 'circulating_supply': 1400001000.0, 'total_supply': 2000000000.0, 'max_supply': 2000000000.0, 'ath': 1.48, 'ath_change_percentage': -27.18174, 'ath_date': '2024-06-01T03:50:55.951Z', 'atl': 0.0142795, 'atl_change_percentage': 7443.46905, 'atl_date': '2020-06-25T04:17:05.895Z', 'roi': None, 'last_updated': '2024-10-08T00:54:05.579Z'}, {'id': 'bonk', 'symbol': 'bonk', 'name': 'Bonk', 'image': 'https://coin-images.coingecko.com/coins/images/28600/large/bonk.jpg?1696527587', 'current_price': 2.134e-05, 'market_cap': 1482766707, 'market_cap_rank': 61, 'fully_diluted_valuation': 1996093347, 'total_volume': 418331264, 'high_24h': 2.327e-05, 'low_24h': 2.116e-05, 'price_change_24h': -1.444364956781e-06, 'price_change_percentage_24h': -6.33855, 'market_cap_change_24h': -100689387.01500964, 'market_cap_change_percentage_24h': -6.35884, 'circulating_supply': 69474461693558.484, 'total_supply': 93526183276778.0, 'max_supply': 93526183276778.0, 'ath': 4.547e-05, 'ath_change_percentage': -53.06035, 'ath_date': '2024-03-04T17:05:29.594Z', 'atl': 8.6142e-08, 'atl_change_percentage': 24677.40406, 'atl_date': '2022-12-29T22:48:46.755Z', 'roi': None, 'last_updated': '2024-10-08T00:54:06.906Z'}, {'id': 'binance-peg-weth', 'symbol': 'weth', 'name': 'Binance-Peg WETH', 'image': 'https://coin-images.coingecko.com/coins/images/39580/large/weth.png?1723006716', 'current_price': 2434.55, 'market_cap': 1472855920, 'market_cap_rank': 62, 'fully_diluted_valuation': 1472855920, 'total_volume': 52219432, 'high_24h': 2512.03, 'low_24h': 2423.7, 'price_change_24h': -52.02834219076749, 'price_change_percentage_24h': -2.09236, 'market_cap_change_24h': -32065616.701003075, 'market_cap_change_percentage_24h': -2.13072, 'circulating_supply': 604999.999959841, 'total_supply': 604999.999959841, 'max_supply': None, 'ath': 2808.56, 'ath_change_percentage': -13.40018, 'ath_date': '2024-08-24T16:52:46.091Z', 'atl': 2171.8, 'atl_change_percentage': 11.99047, 'atl_date': '2024-09-06T21:02:52.910Z', 'roi': None, 'last_updated': '2024-10-08T00:54:04.960Z'}, {'id': 'floki', 'symbol': 'floki', 'name': 'FLOKI', 'image': 'https://coin-images.coingecko.com/coins/images/16746/large/PNG_image.png?1696516318', 'current_price': 0.00013831, 'market_cap': 1340262428, 'market_cap_rank': 63, 'fully_diluted_valuation': 1383218927, 'total_volume': 371506712, 'high_24h': 0.00014615, 'low_24h': 0.00013686, 'price_change_24h': -5.493776205175e-06, 'price_change_percentage_24h': -3.82021, 'market_cap_change_24h': -53932127.53149462, 'market_cap_change_percentage_24h': -3.86834, 'circulating_supply': 9689445405951.0, 'total_supply': 10000000000000.0, 'max_supply': 10000000000000.0, 'ath': 0.00034495, 'ath_change_percentage': -59.87297, 'ath_date': '2024-06-05T07:25:59.137Z', 'atl': 8.428e-08, 'atl_change_percentage': 164136.20747, 'atl_date': '2021-07-06T01:11:20.438Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.994Z'}, {'id': 'rocket-pool-eth', 'symbol': 'reth', 'name': 'Rocket Pool ETH', 'image': 'https://coin-images.coingecko.com/coins/images/20764/large/reth.png?1696520159', 'current_price': 2719.44, 'market_cap': 1328506348, 'market_cap_rank': 64, 'fully_diluted_valuation': 1328506348, 'total_volume': 5214534, 'high_24h': 2808.84, 'low_24h': 2696.73, 'price_change_24h': -64.3257142784546, 'price_change_percentage_24h': -2.31075, 'market_cap_change_24h': -30626102.881741285, 'market_cap_change_percentage_24h': -2.25336, 'circulating_supply': 488193.944227492, 'total_supply': 488193.944227492, 'max_supply': None, 'ath': 4814.31, 'ath_change_percentage': -43.50101, 'ath_date': '2021-12-01T08:03:50.749Z', 'atl': 887.26, 'atl_change_percentage': 206.56468, 'atl_date': '2022-06-18T20:55:45.957Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.671Z'}, {'id': 'theta-token', 'symbol': 'theta', 'name': 'Theta Network', 'image': 'https://coin-images.coingecko.com/coins/images/2538/large/theta-token-logo.png?1696503349', 'current_price': 1.31, 'market_cap': 1305909326, 'market_cap_rank': 65, 'fully_diluted_valuation': 1305909326, 'total_volume': 19702810, 'high_24h': 1.37, 'low_24h': 1.3, 'price_change_24h': -0.05468473696731757, 'price_change_percentage_24h': -4.02037, 'market_cap_change_24h': -52673402.857219934, 'market_cap_change_percentage_24h': -3.87708, 'circulating_supply': 1000000000.0, 'total_supply': 1000000000.0, 'max_supply': 1000000000.0, 'ath': 15.72, 'ath_change_percentage': -91.68442, 'ath_date': '2021-04-16T13:15:11.190Z', 'atl': 0.04039979, 'atl_change_percentage': 3135.62621, 'atl_date': '2020-03-13T02:24:16.483Z', 'roi': {'times': 7.7033697367491865, 'currency': 'usd', 'percentage': 770.3369736749187}, 'last_updated': '2024-10-08T00:54:11.319Z'}, {'id': 'popcat', 'symbol': 'popcat', 'name': 'Popcat', 'image': 'https://coin-images.coingecko.com/coins/images/33760/large/image.jpg?1702964227', 'current_price': 1.28, 'market_cap': 1254180237, 'market_cap_rank': 66, 'fully_diluted_valuation': 1254180237, 'total_volume': 166807604, 'high_24h': 1.47, 'low_24h': 1.27, 'price_change_24h': -0.1536987502902194, 'price_change_percentage_24h': -10.72276, 'market_cap_change_24h': -149282754.86362696, 'market_cap_change_percentage_24h': -10.63674, 'circulating_supply': 979978669.96, 'total_supply': 979978669.96, 'max_supply': 979978694.0, 'ath': 1.47, 'ath_change_percentage': -13.18589, 'ath_date': '2024-10-07T08:39:47.267Z', 'atl': 0.00379728, 'atl_change_percentage': 33597.19423, 'atl_date': '2024-01-05T15:34:24.842Z', 'roi': None, 'last_updated': '2024-10-08T00:53:24.463Z'}, {'id': 'arweave', 'symbol': 'ar', 'name': 'Arweave', 'image': 'https://coin-images.coingecko.com/coins/images/4343/large/oRt6SiEN_400x400.jpg?1696504946', 'current_price': 19.03, 'market_cap': 1245444184, 'market_cap_rank': 67, 'fully_diluted_valuation': 1245444184, 'total_volume': 93459497, 'high_24h': 20.35, 'low_24h': 18.83, 'price_change_24h': -1.102395992722606, 'price_change_percentage_24h': -5.47499, 'market_cap_change_24h': -72086752.11991191, 'market_cap_change_percentage_24h': -5.47135, 'circulating_supply': 65454185.5381511, 'total_supply': 65454185.5381511, 'max_supply': 66000000.0, 'ath': 89.24, 'ath_change_percentage': -78.66006, 'ath_date': '2021-11-05T04:14:42.689Z', 'atl': 0.298788, 'atl_change_percentage': 6273.32719, 'atl_date': '2020-01-31T06:47:36.543Z', 'roi': {'times': 24.719889503069542, 'currency': 'usd', 'percentage': 2471.988950306954}, 'last_updated': '2024-10-08T00:54:04.701Z'}, {'id': 'maker', 'symbol': 'mkr', 'name': 'Maker', 'image': 'https://coin-images.coingecko.com/coins/images/1364/large/Mark_Maker.png?1696502423', 'current_price': 1406.89, 'market_cap': 1228618819, 'market_cap_rank': 68, 'fully_diluted_valuation': 1271387721, 'total_volume': 141868687, 'high_24h': 1484.9, 'low_24h': 1388.68, 'price_change_24h': -65.40749774075653, 'price_change_percentage_24h': -4.44254, 'market_cap_change_24h': -63091679.83813453, 'market_cap_change_percentage_24h': -4.88435, 'circulating_supply': 874256.939689837, 'total_supply': 904690.308012115, 'max_supply': 1005577.0, 'ath': 6292.31, 'ath_change_percentage': -77.6293, 'ath_date': '2021-05-03T21:54:29.333Z', 'atl': 168.36, 'atl_change_percentage': 736.09842, 'atl_date': '2020-03-16T20:52:36.527Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.987Z'}, {'id': 'mantle-staked-ether', 'symbol': 'meth', 'name': 'Mantle Staked Ether', 'image': 'https://coin-images.coingecko.com/coins/images/33345/large/symbol_transparent_bg.png?1701697066', 'current_price': 2540.6, 'market_cap': 1203906007, 'market_cap_rank': 69, 'fully_diluted_valuation': 1203906007, 'total_volume': 46913247, 'high_24h': 2625.66, 'low_24h': 2510.44, 'price_change_24h': -54.040076595622395, 'price_change_percentage_24h': -2.08276, 'market_cap_change_24h': -28273549.475244284, 'market_cap_change_percentage_24h': -2.2946, 'circulating_supply': 474094.100298458, 'total_supply': 474094.100298458, 'max_supply': None, 'ath': 4729.53, 'ath_change_percentage': -46.19013, 'ath_date': '2024-03-27T05:26:27.333Z', 'atl': 2142.02, 'atl_change_percentage': 18.81108, 'atl_date': '2023-12-18T10:41:32.686Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.632Z'}, {'id': 'mantra-dao', 'symbol': 'om', 'name': 'MANTRA', 'image': 'https://coin-images.coingecko.com/coins/images/12151/large/OM_Token.png?1696511991', 'current_price': 1.4, 'market_cap': 1192208346, 'market_cap_rank': 70, 'fully_diluted_valuation': 1246554201, 'total_volume': 55717062, 'high_24h': 1.47, 'low_24h': 1.38, 'price_change_24h': -0.008372729468661968, 'price_change_percentage_24h': -0.59314, 'market_cap_change_24h': 993214, 'market_cap_change_percentage_24h': 0.08338, 'circulating_supply': 850136119.15, 'total_supply': 888888888.0, 'max_supply': 888888888.0, 'ath': 1.47, 'ath_change_percentage': -4.68623, 'ath_date': '2024-10-07T01:10:47.695Z', 'atl': 0.01726188, 'atl_change_percentage': 8009.94779, 'atl_date': '2023-10-12T17:25:09.068Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.389Z'}, {'id': 'pyth-network', 'symbol': 'pyth', 'name': 'Pyth Network', 'image': 'https://coin-images.coingecko.com/coins/images/31924/large/pyth.png?1701245725', 'current_price': 0.327718, 'market_cap': 1187587206, 'market_cap_rank': 71, 'fully_diluted_valuation': 3276112770, 'total_volume': 71153373, 'high_24h': 0.347405, 'low_24h': 0.323434, 'price_change_24h': -0.014656647843092951, 'price_change_percentage_24h': -4.28087, 'market_cap_change_24h': -53646265.49825287, 'market_cap_change_percentage_24h': -4.32201, 'circulating_supply': 3624988786.43857, 'total_supply': 10000000000.0, 'max_supply': 10000000000.0, 'ath': 1.2, 'ath_change_percentage': -72.6067, 'ath_date': '2024-03-16T07:01:15.357Z', 'atl': 0.22352, 'atl_change_percentage': 46.61974, 'atl_date': '2024-08-05T11:30:50.894Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.687Z'}, {'id': 'helium', 'symbol': 'hnt', 'name': 'Helium', 'image': 'https://coin-images.coingecko.com/coins/images/4284/large/Helium_HNT.png?1696504894', 'current_price': 6.89, 'market_cap': 1175763601, 'market_cap_rank': 72, 'fully_diluted_valuation': 1535181838, 'total_volume': 21363150, 'high_24h': 7.5, 'low_24h': 6.8, 'price_change_24h': -0.5567727122519592, 'price_change_percentage_24h': -7.47186, 'market_cap_change_24h': -96629481.61365056, 'market_cap_change_percentage_24h': -7.59431, 'circulating_supply': 170791027.272522, 'total_supply': 223000000.0, 'max_supply': 223000000.0, 'ath': 54.88, 'ath_change_percentage': -87.4452, 'ath_date': '2021-11-12T23:08:25.301Z', 'atl': 0.113248, 'atl_change_percentage': 5983.74805, 'atl_date': '2020-04-18T00:19:10.902Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.888Z'}, {'id': 'solv-btc', 'symbol': 'solvbtc', 'name': 'Solv Protocol SolvBTC', 'image': 'https://coin-images.coingecko.com/coins/images/36800/large/solvBTC.png?1719810684', 'current_price': 62563, 'market_cap': 1166983495, 'market_cap_rank': 73, 'fully_diluted_valuation': 1166983495, 'total_volume': 4234286, 'high_24h': 64322, 'low_24h': 62260, 'price_change_24h': -972.2084470276677, 'price_change_percentage_24h': -1.5302, 'market_cap_change_24h': -18407428.421874046, 'market_cap_change_percentage_24h': -1.55286, 'circulating_supply': 18649.035274833, 'total_supply': 18649.035274833, 'max_supply': 21000000.0, 'ath': 70898, 'ath_change_percentage': -11.66845, 'ath_date': '2024-06-05T16:15:24.629Z', 'atl': 49058, 'atl_change_percentage': 27.6557, 'atl_date': '2024-08-05T06:28:45.311Z', 'roi': None, 'last_updated': '2024-10-08T00:53:36.145Z'}, {'id': 'celestia', 'symbol': 'tia', 'name': 'Celestia', 'image': 'https://coin-images.coingecko.com/coins/images/31967/large/tia.jpg?1696530772', 'current_price': 5.39, 'market_cap': 1160718301, 'market_cap_rank': 74, 'fully_diluted_valuation': 5799974465, 'total_volume': 223647640, 'high_24h': 5.72, 'low_24h': 5.33, 'price_change_24h': -0.03489822745982085, 'price_change_percentage_24h': -0.64286, 'market_cap_change_24h': -4896667.941010714, 'market_cap_change_percentage_24h': -0.42009, 'circulating_supply': 214906541.448367, 'total_supply': 1073863013.69837, 'max_supply': None, 'ath': 20.85, 'ath_change_percentage': -74.13297, 'ath_date': '2024-02-10T14:30:02.495Z', 'atl': 2.08, 'atl_change_percentage': 158.86734, 'atl_date': '2023-10-31T15:14:31.951Z', 'roi': None, 'last_updated': '2024-10-08T00:54:05.796Z'}, {'id': 'gatechain-token', 'symbol': 'gt', 'name': 'Gate', 'image': 'https://coin-images.coingecko.com/coins/images/8183/large/gate.png?1696508395', 'current_price': 8.86, 'market_cap': 1133702266, 'market_cap_rank': 75, 'fully_diluted_valuation': 2655869390, 'total_volume': 3255449, 'high_24h': 9.0, 'low_24h': 8.73, 'price_change_24h': 0.123653, 'price_change_percentage_24h': 1.4158, 'market_cap_change_24h': 15515512, 'market_cap_change_percentage_24h': 1.38756, 'circulating_supply': 128060017.17436442, 'total_supply': 300000000.0, 'max_supply': None, 'ath': 12.94, 'ath_change_percentage': -31.4915, 'ath_date': '2021-05-12T11:39:16.531Z', 'atl': 0.25754, 'atl_change_percentage': 3342.6755, 'atl_date': '2020-03-13T02:18:02.481Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.598Z'}, {'id': 'jupiter-exchange-solana', 'symbol': 'jup', 'name': 'Jupiter', 'image': 'https://coin-images.coingecko.com/coins/images/34188/large/jup.png?1704266489', 'current_price': 0.772541, 'market_cap': 1043006766, 'market_cap_rank': 76, 'fully_diluted_valuation': 7725976046, 'total_volume': 151655748, 'high_24h': 0.813931, 'low_24h': 0.767147, 'price_change_24h': -0.02900773798361378, 'price_change_percentage_24h': -3.61896, 'market_cap_change_24h': -38808691.17161238, 'market_cap_change_percentage_24h': -3.58737, 'circulating_supply': 1350000000.0, 'total_supply': 10000000000.0, 'max_supply': 10000000000.0, 'ath': 2.0, 'ath_change_percentage': -61.2806, 'ath_date': '2024-01-31T15:02:47.304Z', 'atl': 0.457464, 'atl_change_percentage': 69.27956, 'atl_date': '2024-02-21T18:31:05.083Z', 'roi': None, 'last_updated': '2024-10-08T00:54:09.568Z'}, {'id': 'algorand', 'symbol': 'algo', 'name': 'Algorand', 'image': 'https://coin-images.coingecko.com/coins/images/4380/large/download.png?1696504978', 'current_price': 0.125351, 'market_cap': 1039769409, 'market_cap_rank': 77, 'fully_diluted_valuation': 1039769414, 'total_volume': 57158385, 'high_24h': 0.129693, 'low_24h': 0.124391, 'price_change_24h': -0.002723524453178167, 'price_change_percentage_24h': -2.12651, 'market_cap_change_24h': -20685980.82075572, 'market_cap_change_percentage_24h': -1.95067, 'circulating_supply': 8292746539.53288, 'total_supply': 8292746578.70868, 'max_supply': 10000000000.0, 'ath': 3.56, 'ath_change_percentage': -96.48322, 'ath_date': '2019-06-20T14:51:19.480Z', 'atl': 0.087513, 'atl_change_percentage': 43.10684, 'atl_date': '2023-09-11T19:42:08.247Z', 'roi': {'times': -0.9477703186223201, 'currency': 'usd', 'percentage': -94.77703186223201}, 'last_updated': '2024-10-08T00:54:06.162Z'}, {'id': 'matic-network', 'symbol': 'matic', 'name': 'Polygon', 'image': 'https://coin-images.coingecko.com/coins/images/4713/large/polygon.png?1698233745', 'current_price': 0.377139, 'market_cap': 1031513152, 'market_cap_rank': 78, 'fully_diluted_valuation': 3770427519, 'total_volume': 10428459, 'high_24h': 0.389223, 'low_24h': 0.375421, 'price_change_24h': -0.005050292179460625, 'price_change_percentage_24h': -1.32141, 'market_cap_change_24h': -1119194.28873837, 'market_cap_change_percentage_24h': -0.10838, 'circulating_supply': 2735798915.4468446, 'total_supply': 10000000000.0, 'max_supply': 10000000000.0, 'ath': 2.92, 'ath_change_percentage': -87.0595, 'ath_date': '2021-12-27T02:08:34.307Z', 'atl': 0.00314376, 'atl_change_percentage': 11904.06254, 'atl_date': '2019-05-10T00:00:00.000Z', 'roi': {'times': 142.3989391138943, 'currency': 'usd', 'percentage': 14239.89391138943}, 'last_updated': '2024-10-08T00:54:10.159Z'}, {'id': 'ondo-finance', 'symbol': 'ondo', 'name': 'Ondo', 'image': 'https://coin-images.coingecko.com/coins/images/26580/large/ONDO.png?1696525656', 'current_price': 0.711239, 'market_cap': 1020937000, 'market_cap_rank': 79, 'fully_diluted_valuation': 7106589499, 'total_volume': 233426961, 'high_24h': 0.767711, 'low_24h': 0.705277, 'price_change_24h': -0.0452137306854673, 'price_change_percentage_24h': -5.97708, 'market_cap_change_24h': -67890921.7707479, 'market_cap_change_percentage_24h': -6.23523, 'circulating_supply': 1436606124.1074963, 'total_supply': 10000000000.0, 'max_supply': 10000000000.0, 'ath': 1.48, 'ath_change_percentage': -51.93391, 'ath_date': '2024-06-03T08:29:55.744Z', 'atl': 0.082171, 'atl_change_percentage': 765.00038, 'atl_date': '2024-01-18T12:14:30.524Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.869Z'}, {'id': 'worldcoin-wld', 'symbol': 'wld', 'name': 'Worldcoin', 'image': 'https://coin-images.coingecko.com/coins/images/31069/large/worldcoin.jpeg?1696529903', 'current_price': 1.95, 'market_cap': 994535999, 'market_cap_rank': 80, 'fully_diluted_valuation': 19530175731, 'total_volume': 540964835, 'high_24h': 2.06, 'low_24h': 1.91, 'price_change_24h': -0.008271319197278306, 'price_change_percentage_24h': -0.42173, 'market_cap_change_24h': 4400790, 'market_cap_change_percentage_24h': 0.44446, 'circulating_supply': 509230440.396566, 'total_supply': 10000000000.0, 'max_supply': 10000000000.0, 'ath': 11.74, 'ath_change_percentage': -83.29774, 'ath_date': '2024-03-10T00:10:42.330Z', 'atl': 0.973104, 'atl_change_percentage': 101.51475, 'atl_date': '2023-09-13T07:36:44.064Z', 'roi': None, 'last_updated': '2024-10-08T00:53:49.245Z'}, {'id': 'quant-network', 'symbol': 'qnt', 'name': 'Quant', 'image': 'https://coin-images.coingecko.com/coins/images/3370/large/5ZOu7brX_400x400.jpg?1696504070', 'current_price': 67.87, 'market_cap': 986909088, 'market_cap_rank': 81, 'fully_diluted_valuation': 991544793, 'total_volume': 18537323, 'high_24h': 71.06, 'low_24h': 67.1, 'price_change_24h': -2.311314272384635, 'price_change_percentage_24h': -3.2935, 'market_cap_change_24h': -34028927.77297032, 'market_cap_change_percentage_24h': -3.3331, 'circulating_supply': 14544176.164091088, 'total_supply': 14612493.0, 'max_supply': 14612493.0, 'ath': 427.42, 'ath_change_percentage': -84.11226, 'ath_date': '2021-09-11T09:15:00.668Z', 'atl': 0.215773, 'atl_change_percentage': 31371.79506, 'atl_date': '2018-08-23T00:00:00.000Z', 'roi': {'times': 10.988597073984174, 'currency': 'eth', 'percentage': 1098.8597073984174}, 'last_updated': '2024-10-08T00:54:10.405Z'}, {'id': 'lido-dao', 'symbol': 'ldo', 'name': 'Lido DAO', 'image': 'https://coin-images.coingecko.com/coins/images/13573/large/Lido_DAO.png?1696513326', 'current_price': 1.079, 'market_cap': 965929778, 'market_cap_rank': 82, 'fully_diluted_valuation': 1078912610, 'total_volume': 116984366, 'high_24h': 1.14, 'low_24h': 1.07, 'price_change_24h': -0.02206092767483625, 'price_change_percentage_24h': -2.0029, 'market_cap_change_24h': -19209916.68047166, 'market_cap_change_percentage_24h': -1.94997, 'circulating_supply': 895280831.178504, 'total_supply': 1000000000.0, 'max_supply': 1000000000.0, 'ath': 7.3, 'ath_change_percentage': -85.19627, 'ath_date': '2021-08-20T08:35:20.158Z', 'atl': 0.40615, 'atl_change_percentage': 166.18197, 'atl_date': '2022-06-18T20:55:12.035Z', 'roi': None, 'last_updated': '2024-10-08T00:54:09.774Z'}, {'id': 'kucoin-shares', 'symbol': 'kcs', 'name': 'KuCoin', 'image': 'https://coin-images.coingecko.com/coins/images/1047/large/sa9z79.png?1696502152', 'current_price': 7.95, 'market_cap': 956761609, 'market_cap_rank': 83, 'fully_diluted_valuation': 1135548069, 'total_volume': 105920, 'high_24h': 8.13, 'low_24h': 7.88, 'price_change_24h': -0.01620126524070553, 'price_change_percentage_24h': -0.20344, 'market_cap_change_24h': -1863355.6644928455, 'market_cap_change_percentage_24h': -0.19438, 'circulating_supply': 120406971.14608, 'total_supply': 142906971.14608, 'max_supply': None, 'ath': 28.83, 'ath_change_percentage': -72.50285, 'ath_date': '2021-12-01T15:09:35.541Z', 'atl': 0.342863, 'atl_change_percentage': 2212.11774, 'atl_date': '2019-02-07T00:00:00.000Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.466Z'}, {'id': 'jasmycoin', 'symbol': 'jasmy', 'name': 'JasmyCoin', 'image': 'https://coin-images.coingecko.com/coins/images/13876/large/JASMY200x200.jpg?1696513620', 'current_price': 0.01934656, 'market_cap': 936477923, 'market_cap_rank': 84, 'fully_diluted_valuation': 967036269, 'total_volume': 96934539, 'high_24h': 0.02058099, 'low_24h': 0.01921798, 'price_change_24h': -0.000913663078247352, 'price_change_percentage_24h': -4.50964, 'market_cap_change_24h': -43929303.850437164, 'market_cap_change_percentage_24h': -4.48072, 'circulating_supply': 48419999999.3058, 'total_supply': 50000000000.0, 'max_supply': 50000000000.0, 'ath': 4.79, 'ath_change_percentage': -99.59613, 'ath_date': '2021-02-16T03:53:32.207Z', 'atl': 0.00275026, 'atl_change_percentage': 603.41823, 'atl_date': '2022-12-29T20:41:09.113Z', 'roi': None, 'last_updated': '2024-10-08T00:54:09.140Z'}, {'id': 'bitcoin-cash-sv', 'symbol': 'bsv', 'name': 'Bitcoin SV', 'image': 'https://coin-images.coingecko.com/coins/images/6799/large/BSV.png?1696507128', 'current_price': 45.98, 'market_cap': 908863334, 'market_cap_rank': 85, 'fully_diluted_valuation': 965558272, 'total_volume': 14295577, 'high_24h': 47.42, 'low_24h': 45.54, 'price_change_24h': -1.3404163753512677, 'price_change_percentage_24h': -2.83266, 'market_cap_change_24h': -26325157.159350753, 'market_cap_change_percentage_24h': -2.81496, 'circulating_supply': 19766937.5, 'total_supply': 21000000.0, 'max_supply': 21000000.0, 'ath': 489.75, 'ath_change_percentage': -90.62735, 'ath_date': '2021-04-16T17:09:04.630Z', 'atl': 21.43, 'atl_change_percentage': 114.14966, 'atl_date': '2023-06-10T04:32:12.266Z', 'roi': None, 'last_updated': '2024-10-08T00:54:05.350Z'}, {'id': 'conflux-token', 'symbol': 'cfx', 'name': 'Conflux', 'image': 'https://coin-images.coingecko.com/coins/images/13079/large/3vuYMbjN.png?1696512867', 'current_price': 0.198997, 'market_cap': 897133314, 'market_cap_rank': 87, 'fully_diluted_valuation': 1099701725, 'total_volume': 136203952, 'high_24h': 0.197642, 'low_24h': 0.181839, 'price_change_24h': 0.01636931, 'price_change_percentage_24h': 8.96323, 'market_cap_change_24h': 70613398, 'market_cap_change_percentage_24h': 8.54346, 'circulating_supply': 4526069775.50803, 'total_supply': 5548034679.73236, 'max_supply': None, 'ath': 1.7, 'ath_change_percentage': -88.39547, 'ath_date': '2021-03-27T03:43:35.178Z', 'atl': 0.02199898, 'atl_change_percentage': 797.20122, 'atl_date': '2022-12-30T08:16:30.345Z', 'roi': None, 'last_updated': '2024-10-08T00:53:33.560Z'}, {'id': 'bittorrent', 'symbol': 'btt', 'name': 'BitTorrent', 'image': 'https://coin-images.coingecko.com/coins/images/22457/large/btt_logo.png?1696521780', 'current_price': 9.23941e-07, 'market_cap': 894567068, 'market_cap_rank': 86, 'fully_diluted_valuation': 914665287, 'total_volume': 26689838, 'high_24h': 9.43491e-07, 'low_24h': 9.21746e-07, 'price_change_24h': -1.8515579683e-08, 'price_change_percentage_24h': -1.96461, 'market_cap_change_24h': -16353484.723588705, 'market_cap_change_percentage_24h': -1.79527, 'circulating_supply': 968246428571000.0, 'total_supply': 990000000000000.0, 'max_supply': 990000000000000.0, 'ath': 3.43e-06, 'ath_change_percentage': -73.05988, 'ath_date': '2022-01-21T04:00:31.909Z', 'atl': 3.65368e-07, 'atl_change_percentage': 153.00723, 'atl_date': '2023-10-13T05:10:41.241Z', 'roi': None, 'last_updated': '2024-10-08T00:54:05.559Z'}, {'id': 'based-brett', 'symbol': 'brett', 'name': 'Brett', 'image': 'https://coin-images.coingecko.com/coins/images/35529/large/1000050750.png?1709031995', 'current_price': 0.088115, 'market_cap': 873218316, 'market_cap_rank': 88, 'fully_diluted_valuation': 873218316, 'total_volume': 58537246, 'high_24h': 0.092752, 'low_24h': 0.085926, 'price_change_24h': 0.00054038, 'price_change_percentage_24h': 0.61706, 'market_cap_change_24h': 5528824, 'market_cap_change_percentage_24h': 0.63719, 'circulating_supply': 9910164240.66912, 'total_supply': 9910164240.66912, 'max_supply': 9999998988.0, 'ath': 0.193328, 'ath_change_percentage': -54.36865, 'ath_date': '2024-06-09T12:55:51.835Z', 'atl': 0.00084753, 'atl_change_percentage': 10308.88083, 'atl_date': '2024-02-29T08:40:24.951Z', 'roi': None, 'last_updated': '2024-10-08T00:54:05.104Z'}, {'id': 'coredaoorg', 'symbol': 'core', 'name': 'Core', 'image': 'https://coin-images.coingecko.com/coins/images/28938/large/file_589.jpg?1701868471', 'current_price': 0.937112, 'market_cap': 858110315, 'market_cap_rank': 89, 'fully_diluted_valuation': 1971753958, 'total_volume': 31657462, 'high_24h': 0.967114, 'low_24h': 0.932028, 'price_change_24h': -0.01422813882470342, 'price_change_percentage_24h': -1.49559, 'market_cap_change_24h': -10961374.97734642, 'market_cap_change_percentage_24h': -1.26127, 'circulating_supply': 913923187.211838, 'total_supply': 2100000000.0, 'max_supply': 2100000000.0, 'ath': 6.14, 'ath_change_percentage': -84.69421, 'ath_date': '2023-02-08T12:55:39.828Z', 'atl': 0.334237, 'atl_change_percentage': 181.33666, 'atl_date': '2023-11-03T01:20:55.441Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.590Z'}, {'id': 'fasttoken', 'symbol': 'ftn', 'name': 'Fasttoken', 'image': 'https://coin-images.coingecko.com/coins/images/28478/large/lightenicon_200x200.png?1696527472', 'current_price': 2.6, 'market_cap': 856233446, 'market_cap_rank': 90, 'fully_diluted_valuation': 2290629881, 'total_volume': 215412570, 'high_24h': 2.62, 'low_24h': 2.51, 'price_change_24h': 0.062821, 'price_change_percentage_24h': 2.47271, 'market_cap_change_24h': 21132723, 'market_cap_change_percentage_24h': 2.53056, 'circulating_supply': 328942461.97373456, 'total_supply': 880000000.0, 'max_supply': 1000000000.0, 'ath': 2.62, 'ath_change_percentage': -0.4686, 'ath_date': '2024-10-07T19:07:59.036Z', 'atl': 0.398142, 'atl_change_percentage': 553.93665, 'atl_date': '2023-01-21T10:15:39.503Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.935Z'}, {'id': 'gala', 'symbol': 'gala', 'name': 'GALA', 'image': 'https://coin-images.coingecko.com/coins/images/12493/large/GALA_token_image_-_200PNG.png?1709725869', 'current_price': 0.02149496, 'market_cap': 848757809, 'market_cap_rank': 91, 'fully_diluted_valuation': 848757654, 'total_volume': 161097632, 'high_24h': 0.02224224, 'low_24h': 0.02072146, 'price_change_24h': 0.00021638, 'price_change_percentage_24h': 1.01687, 'market_cap_change_24h': 9005263, 'market_cap_change_percentage_24h': 1.07237, 'circulating_supply': 39481499168.913, 'total_supply': 39481491922.3056, 'max_supply': 50000000000.0, 'ath': 0.824837, 'ath_change_percentage': -97.39249, 'ath_date': '2021-11-26T01:03:48.731Z', 'atl': 0.00013475, 'atl_change_percentage': 15861.25537, 'atl_date': '2020-12-28T08:46:48.367Z', 'roi': None, 'last_updated': '2024-10-08T00:54:09.522Z'}, {'id': 'ether-fi-staked-eth', 'symbol': 'eeth', 'name': 'ether.fi Staked ETH', 'image': 'https://coin-images.coingecko.com/coins/images/33049/large/ether.fi_eETH.png?1700473063', 'current_price': 2424.85, 'market_cap': 846755524, 'market_cap_rank': 92, 'fully_diluted_valuation': 4871591578, 'total_volume': 106209, 'high_24h': 2508.25, 'low_24h': 2415.47, 'price_change_24h': -41.29035543839427, 'price_change_percentage_24h': -1.67429, 'market_cap_change_24h': -18371264.200617433, 'market_cap_change_percentage_24h': -2.12353, 'circulating_supply': 349139.81169378624, 'total_supply': 2008686.70827969, 'max_supply': None, 'ath': 5307.23, 'ath_change_percentage': -54.27135, 'ath_date': '2024-08-06T16:16:30.007Z', 'atl': 2155.76, 'atl_change_percentage': 12.57876, 'atl_date': '2024-02-08T11:26:30.368Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.140Z'}, {'id': 'wormhole', 'symbol': 'w', 'name': 'Wormhole', 'image': 'https://coin-images.coingecko.com/coins/images/35087/large/womrhole_logo_full_color_rgb_2000px_72ppi_fb766ac85a.png?1708688954', 'current_price': 0.324805, 'market_cap': 836255956, 'market_cap_rank': 93, 'fully_diluted_valuation': 3243975804, 'total_volume': 219924753, 'high_24h': 0.35574, 'low_24h': 0.323118, 'price_change_24h': -0.02045301877589417, 'price_change_percentage_24h': -5.92398, 'market_cap_change_24h': -51338984.688058615, 'market_cap_change_percentage_24h': -5.78406, 'circulating_supply': 2577873594.0, 'total_supply': 10000000000.0, 'max_supply': 10000000000.0, 'ath': 1.66, 'ath_change_percentage': -80.38595, 'ath_date': '2024-04-03T11:46:35.308Z', 'atl': 0.16434, 'atl_change_percentage': 97.84984, 'atl_date': '2024-08-05T06:26:45.610Z', 'roi': None, 'last_updated': '2024-10-08T00:53:48.826Z'}, {'id': 'flow', 'symbol': 'flow', 'name': 'Flow', 'image': 'https://coin-images.coingecko.com/coins/images/13446/large/5f6294c0c7a8cda55cb1c936_Flow_Wordmark.png?1696513210', 'current_price': 0.540995, 'market_cap': 831299188, 'market_cap_rank': 94, 'fully_diluted_valuation': 831299188, 'total_volume': 58056753, 'high_24h': 0.561971, 'low_24h': 0.53686, 'price_change_24h': -0.01656192450478211, 'price_change_percentage_24h': -2.97044, 'market_cap_change_24h': -24892946.25119114, 'market_cap_change_percentage_24h': -2.9074, 'circulating_supply': 1536086728.20855, 'total_supply': 1536086728.20855, 'max_supply': None, 'ath': 42.4, 'ath_change_percentage': -98.72532, 'ath_date': '2021-04-05T13:49:10.098Z', 'atl': 0.391969, 'atl_change_percentage': 37.87491, 'atl_date': '2023-09-11T19:41:06.528Z', 'roi': None, 'last_updated': '2024-10-08T00:54:08.411Z'}, {'id': 'notcoin', 'symbol': 'not', 'name': 'Notcoin', 'image': 'https://coin-images.coingecko.com/coins/images/33453/large/rFmThDiD_400x400.jpg?1701876350', 'current_price': 0.00801109, 'market_cap': 822138290, 'market_cap_rank': 95, 'fully_diluted_valuation': 822138290, 'total_volume': 264338630, 'high_24h': 0.00839936, 'low_24h': 0.00772693, 'price_change_24h': 0.00011801, 'price_change_percentage_24h': 1.49515, 'market_cap_change_24h': 13636202, 'market_cap_change_percentage_24h': 1.6866, 'circulating_supply': 102474422538.643, 'total_supply': 102474422538.643, 'max_supply': None, 'ath': 0.02836145, 'ath_change_percentage': -71.61676, 'ath_date': '2024-06-02T18:00:38.587Z', 'atl': 0.00461057, 'atl_change_percentage': 74.59678, 'atl_date': '2024-05-24T07:12:14.147Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.088Z'}, {'id': 'beam-2', 'symbol': 'beam', 'name': 'Beam', 'image': 'https://coin-images.coingecko.com/coins/images/32417/large/chain-logo.png?1698114384', 'current_price': 0.01552574, 'market_cap': 801595531, 'market_cap_rank': 96, 'fully_diluted_valuation': 968773026, 'total_volume': 39916618, 'high_24h': 0.01674658, 'low_24h': 0.01538882, 'price_change_24h': -0.000940684073936141, 'price_change_percentage_24h': -5.71274, 'market_cap_change_24h': -47924263.662335515, 'market_cap_change_percentage_24h': -5.64134, 'circulating_supply': 51660007768.0, 'total_supply': 62434008330.0, 'max_supply': 62434008330.0, 'ath': 0.04416304, 'ath_change_percentage': -64.79328, 'ath_date': '2024-03-10T10:40:22.381Z', 'atl': 0.0043383, 'atl_change_percentage': 258.39735, 'atl_date': '2023-10-29T08:20:14.064Z', 'roi': None, 'last_updated': '2024-10-08T00:54:13.203Z'}, {'id': 'renzo-restaked-eth', 'symbol': 'ezeth', 'name': 'Renzo Restaked ETH', 'image': 'https://coin-images.coingecko.com/coins/images/34753/large/Ezeth_logo_circle.png?1713496404', 'current_price': 2482.56, 'market_cap': 794760666, 'market_cap_rank': 97, 'fully_diluted_valuation': 794760666, 'total_volume': 11266087, 'high_24h': 2562.78, 'low_24h': 2455.06, 'price_change_24h': -51.8338887688119, 'price_change_percentage_24h': -2.04522, 'market_cap_change_24h': -22560571.011731625, 'market_cap_change_percentage_24h': -2.76031, 'circulating_supply': 320078.067454777, 'total_supply': 320078.067454777, 'max_supply': None, 'ath': 4106.74, 'ath_change_percentage': -39.47159, 'ath_date': '2024-03-12T00:44:29.429Z', 'atl': 2198.04, 'atl_change_percentage': 13.08921, 'atl_date': '2024-01-26T08:09:59.848Z', 'roi': None, 'last_updated': '2024-10-08T00:54:10.315Z'}, {'id': 'ethena', 'symbol': 'ena', 'name': 'Ethena', 'image': 'https://coin-images.coingecko.com/coins/images/36530/large/ethena.png?1711701436', 'current_price': 0.287191, 'market_cap': 789001209, 'market_cap_rank': 98, 'fully_diluted_valuation': 4308539023, 'total_volume': 209536876, 'high_24h': 0.311956, 'low_24h': 0.283762, 'price_change_24h': -0.013023047337344384, 'price_change_percentage_24h': -4.33793, 'market_cap_change_24h': -35648060.95506203, 'market_cap_change_percentage_24h': -4.32281, 'circulating_supply': 2746875000.0, 'total_supply': 15000000000.0, 'max_supply': None, 'ath': 1.52, 'ath_change_percentage': -81.04188, 'ath_date': '2024-04-11T13:15:15.057Z', 'atl': 0.195078, 'atl_change_percentage': 47.4937, 'atl_date': '2024-09-06T21:04:48.253Z', 'roi': None, 'last_updated': '2024-10-08T00:54:04.226Z'}, {'id': 'klay-token', 'symbol': 'klay', 'name': 'Klaytn', 'image': 'https://coin-images.coingecko.com/coins/images/9672/large/klaytn.png?1696509742', 'current_price': 0.132756, 'market_cap': 770707685, 'market_cap_rank': 99, 'fully_diluted_valuation': 774944601, 'total_volume': 15981912, 'high_24h': 0.13638, 'low_24h': 0.131797, 'price_change_24h': -0.002995926554336559, 'price_change_percentage_24h': -2.20692, 'market_cap_change_24h': -19069806.84438181, 'market_cap_change_percentage_24h': -2.41458, 'circulating_supply': 5806693656.94806, 'total_supply': 5838615577.49937, 'max_supply': None, 'ath': 4.34, 'ath_change_percentage': -96.93899, 'ath_date': '2021-03-30T03:44:28.828Z', 'atl': 0.06044, 'atl_change_percentage': 119.7475, 'atl_date': '2020-04-29T08:19:34.574Z', 'roi': None, 'last_updated': '2024-10-08T00:54:11.218Z'}, {'id': 'aerodrome-finance', 'symbol': 'aero', 'name': 'Aerodrome Finance', 'image': 'https://coin-images.coingecko.com/coins/images/31745/large/token.png?1696530564', 'current_price': 1.2, 'market_cap': 769656411, 'market_cap_rank': 100, 'fully_diluted_valuation': 1557648682, 'total_volume': 55612141, 'high_24h': 1.27, 'low_24h': 1.19, 'price_change_24h': -0.0154197910139926, 'price_change_percentage_24h': -1.26784, 'market_cap_change_24h': -9478210.726666927, 'market_cap_change_percentage_24h': -1.2165, 'circulating_supply': 641571846.36209, 'total_supply': 1298428138.12827, 'max_supply': None, 'ath': 2.31, 'ath_change_percentage': -48.0214, 'ath_date': '2024-04-12T03:44:52.080Z', 'atl': 1.861e-05, 'atl_change_percentage': 6440257.63163, 'atl_date': '2023-10-17T01:23:50.860Z', 'roi': None, 'last_updated': '2024-10-08T00:54:07.760Z'}]\n\n\n\n\nCode\n# Loop through the data and print the name and current price\nfor coin in data:\n    name = coin['name']\n    price = coin['current_price']\n    print(f\"Coin: {name}, Price: ${price}\")\n\n\nCoin: Bitcoin, Price: $62490\nCoin: Ethereum, Price: $2434.1\nCoin: Tether, Price: $0.999711\nCoin: BNB, Price: $568.59\nCoin: Solana, Price: $144.62\nCoin: USDC, Price: $0.99982\nCoin: XRP, Price: $0.531761\nCoin: Lido Staked Ether, Price: $2433.54\nCoin: Dogecoin, Price: $0.109138\nCoin: TRON, Price: $0.156189\nCoin: Toncoin, Price: $5.23\nCoin: Cardano, Price: $0.35311\nCoin: Avalanche, Price: $26.86\nCoin: Shiba Inu, Price: $1.759e-05\nCoin: Wrapped stETH, Price: $2870.49\nCoin: Wrapped Bitcoin, Price: $62339\nCoin: WETH, Price: $2434.35\nCoin: Chainlink, Price: $11.22\nCoin: Bitcoin Cash, Price: $325.66\nCoin: Polkadot, Price: $4.15\nCoin: Dai, Price: $0.999811\nCoin: Sui, Price: $2.06\nCoin: NEAR Protocol, Price: $5.11\nCoin: LEO Token, Price: $6.01\nCoin: Uniswap, Price: $7.24\nCoin: Litecoin, Price: $65.04\nCoin: Bittensor, Price: $617.07\nCoin: Aptos, Price: $8.91\nCoin: Pepe, Price: $9.89e-06\nCoin: Wrapped eETH, Price: $2554.88\nCoin: Artificial Superintelligence Alliance, Price: $1.49\nCoin: Internet Computer, Price: $8.13\nCoin: Kaspa, Price: $0.137693\nCoin: POL (ex-MATIC), Price: $0.376926\nCoin: Ethereum Classic, Price: $18.7\nCoin: Stellar, Price: $0.091505\nCoin: Monero, Price: $144.06\nCoin: Stacks, Price: $1.77\nCoin: First Digital USD, Price: $0.999501\nCoin: dogwifhat, Price: $2.56\nCoin: OKB, Price: $41.75\nCoin: Ethena USDe, Price: $0.998868\nCoin: Immutable, Price: $1.49\nCoin: Filecoin, Price: $3.74\nCoin: Aave, Price: $146.68\nCoin: Cronos, Price: $0.078844\nCoin: Optimism, Price: $1.67\nCoin: Render, Price: $5.32\nCoin: Injective, Price: $20.63\nCoin: Arbitrum, Price: $0.55172\nCoin: Hedera, Price: $0.052714\nCoin: Mantle, Price: $0.594723\nCoin: Fantom, Price: $0.680296\nCoin: VeChain, Price: $0.02305745\nCoin: Cosmos Hub, Price: $4.44\nCoin: THORChain, Price: $5.09\nCoin: WhiteBIT Coin, Price: $11.61\nCoin: The Graph, Price: $0.16643\nCoin: Sei, Price: $0.436364\nCoin: Bitget Token, Price: $1.075\nCoin: Bonk, Price: $2.134e-05\nCoin: Binance-Peg WETH, Price: $2434.55\nCoin: FLOKI, Price: $0.00013831\nCoin: Rocket Pool ETH, Price: $2719.44\nCoin: Theta Network, Price: $1.31\nCoin: Popcat, Price: $1.28\nCoin: Arweave, Price: $19.03\nCoin: Maker, Price: $1406.89\nCoin: Mantle Staked Ether, Price: $2540.6\nCoin: MANTRA, Price: $1.4\nCoin: Pyth Network, Price: $0.327718\nCoin: Helium, Price: $6.89\nCoin: Solv Protocol SolvBTC, Price: $62563\nCoin: Celestia, Price: $5.39\nCoin: Gate, Price: $8.86\nCoin: Jupiter, Price: $0.772541\nCoin: Algorand, Price: $0.125351\nCoin: Polygon, Price: $0.377139\nCoin: Ondo, Price: $0.711239\nCoin: Worldcoin, Price: $1.95\nCoin: Quant, Price: $67.87\nCoin: Lido DAO, Price: $1.079\nCoin: KuCoin, Price: $7.95\nCoin: JasmyCoin, Price: $0.01934656\nCoin: Bitcoin SV, Price: $45.98\nCoin: Conflux, Price: $0.198997\nCoin: BitTorrent, Price: $9.23941e-07\nCoin: Brett, Price: $0.088115\nCoin: Core, Price: $0.937112\nCoin: Fasttoken, Price: $2.6\nCoin: GALA, Price: $0.02149496\nCoin: ether.fi Staked ETH, Price: $2424.85\nCoin: Wormhole, Price: $0.324805\nCoin: Flow, Price: $0.540995\nCoin: Notcoin, Price: $0.00801109\nCoin: Beam, Price: $0.01552574\nCoin: Renzo Restaked ETH, Price: $2482.56\nCoin: Ethena, Price: $0.287191\nCoin: Klaytn, Price: $0.132756\nCoin: Aerodrome Finance, Price: $1.2"
  },
  {
    "objectID": "Assignment A.html#instructions",
    "href": "Assignment A.html#instructions",
    "title": "Appendix A — Assignment A",
    "section": "Instructions",
    "text": "Instructions\n\nYou may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity.\nWrite your code in the Code cells and your answer in the Markdown cells of the Jupyter notebook. Ensure that the solution is written neatly enough to understand and grade.\nUse Quarto to print the .ipynb file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: quarto render filename.ipynb --to html. Submit the HTML file.\nThe assignment is worth 100 points, and is due on 14th October 2024 at 11:59 pm.\nFive points are properly formatting the assignment. The breakdown is as follows:\n\n\nMust be an HTML file rendered using Quarto (2 pts).\nThere aren’t excessively long outputs of extraneous information (e.g. no printouts of entire data frames without good reason, there aren’t long printouts of which iteration a loop is on, there aren’t long sections of commented-out code, etc.) (1 pt)\nFinal answers of each question are written in Markdown cells (1 pt).\nThere is no piece of unnecessary / redundant code, and no unnecessary / redundant text (1 pt)"
  },
  {
    "objectID": "Assignment A.html#list-comprehension",
    "href": "Assignment A.html#list-comprehension",
    "title": "Appendix A — Assignment A",
    "section": "A.1 List comprehension",
    "text": "A.1 List comprehension\nUSA’s GDP per capita from 1960 to 2021 is given by the tuple T in the code cell below. The values are arranged in ascending order of the year, i.e., the first value is for 1960, the second value is for 1961, and so on.\n\nT = (3007, 3067, 3244, 3375,3574, 3828, 4146, 4336, 4696, 5032,5234,5609,6094,6726,7226,7801,8592,9453,10565,11674,12575,13976,14434,15544,17121,18237,19071,20039,21417,22857,23889,24342,25419,26387,27695,28691,29968,31459,32854,34515,36330,37134,37998,39490,41725,44123,46302,48050,48570,47195,48651,50066,51784,53291,55124,56763,57867,59915,62805,65095,63028,69288)\n\n\nA.1.1 \nUse list comprehension to create a list of the gaps between consecutive entries in T, i.e, the increase in GDP per capita with respect to the previous year. The list with gaps should look like: [60, 177, …]. Let the name of this list be GDP_increase.\n(4 points)\n\n\nA.1.2 \nUse GDP_increase to find the maximum gap size, i.e, the maximum increase in GDP per capita.\n(1 point)\n\n\nA.1.3 \nUse list comprehension with GDP_increase to find the percentage of gaps that have size greater than $1000.\n(3 points)\n\n\nA.1.4 \nUse list comprehension with GDP_increase to print the list of years in which the GDP per capita increase was more than $2000.\nHint: The enumerate() function may help.\n(4 points)\n\n\nA.1.5 \nUse list comprehension to:\n\nCreate a list that consists of the difference between the maximum and minimum GDP per capita values for each of the 5 year-periods starting from 1976, i.e., for the periods 1976-1980, 1981-1985, 1986-1990, …, 2016-2020.\nFind the five year period in which the difference (between the maximum and minimum GDP per capita values) was the least.\n\n(4 + 2 points)"
  },
  {
    "objectID": "Assignment A.html#nested-list-comprehension",
    "href": "Assignment A.html#nested-list-comprehension",
    "title": "Appendix A — Assignment A",
    "section": "A.2 Nested list-comprehension",
    "text": "A.2 Nested list-comprehension\nBelow is the list consisting of the majors / minors of students of the course STAT303-1 Fall 2023. This data is a list of lists, where each sub-list (smaller list within the outer larger list) consists of the majors / minors of a student. Most of the students have majors / minors in one or more of these four areas:\n\nMath / Statistics / Computer Science\nHumanities / Communication\nSocial Sciences / Education\nPhysical Sciences / Natural Sciences / Engineering\n\nThere are some students having majors / minors in other areas as well.\nUse list comprehension for all the questions below.\n\nmajors_minors = majors_minors = [['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Humanities / Communications',  'Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Humanities / Communications',  'Social Sciences / Education',  'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Social Sciences / Education'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education'], ['Physical Sciences / Natural Sciences / Engineering'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Cognitive Science'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Music'], ['Social Sciences / Education'], ['Physical Sciences / Natural Sciences / Engineering'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Data Science'], ['Social Sciences / Education'], ['Math / Statistics / Computer Science', 'jazz'], ['Humanities / Communications', 'Social Sciences / Education'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Humanities / Communications',  'Social Sciences / Education',  'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education'], ['Math / Statistics / Computer Science'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Social Sciences / Education'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Econ'], ['Physical Sciences / Natural Sciences / Engineering'], ['Social Sciences / Education', ''], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Physical Sciences / Natural Sciences / Engineering'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Humanities / Communications',  'Social Sciences / Education',  'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Humanities / Communications', 'Social Sciences / Education'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education'], ['Social Sciences / Education'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Humanities / Communications', 'Social Sciences / Education'], ['Physical Sciences / Natural Sciences / Engineering'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Social Sciences / Education'], ['Humanities / Communications'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Social Sciences / Education'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education',  'Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Humanities / Communications', 'Social Sciences / Education'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Humanities / Communications',  'Social Sciences / Education',  'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Humanities / Communications'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Social Sciences / Education',  'Physical Sciences / Natural Sciences / Engineering'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science', 'Music'], ['Physical Sciences / Natural Sciences / Engineering'], ['Humanities / Communications'], ['Physical Sciences / Natural Sciences / Engineering'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education', 'Math / Statistics / Computer Science'], ['Humanities / Communications', 'Math / Statistics / Computer Science'], ['Physical Sciences / Natural Sciences / Engineering'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science'], ['Social Sciences / Education'], ['Physical Sciences / Natural Sciences / Engineering'], ['Physical Sciences / Natural Sciences / Engineering',  'Math / Statistics / Computer Science'], ['Math / Statistics / Computer Science']]\n\n\nA.2.1 \nHow many students have major / minor in any three of the above mentioned four areas?\n(1 point)\n\n\nA.2.2 \nHow many students have Math / Statistics / Computer Science as an area of their major / minor?\nHint: Nested list comprehension\n(4 points)\n\n\nA.2.3 \nHow many students have Math / Statistics / Computer Science as the only area of their major / minor?\nHint: Nested list comprehension\n(5 points)\n\n\nA.2.4 \nHow many students have Math / Statistics / Computer Science and Social Sciences / Education as a couple of areas of their major / minor?\nHint: The in-built function all() may be useful.\n(6 points)"
  },
  {
    "objectID": "Assignment A.html#dictionary",
    "href": "Assignment A.html#dictionary",
    "title": "Appendix A — Assignment A",
    "section": "A.3 Dictionary",
    "text": "A.3 Dictionary\nThe code cell below defines an object having the nutrition information of drinks in starbucks.\n\nstarbucks_drinks_nutrition={'Cool Lime Starbucks Refreshers™ Beverage': [{'Nutrition_type': 'Calories', 'value': 45}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 11}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Strawberry Acai Starbucks Refreshers™ Beverage': [{'Nutrition_type': 'Calories', 'value': 80}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 18}, {'Nutrition_type': 'Fiber', 'value': 1}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Very Berry Hibiscus Starbucks Refreshers™ Beverage': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 14}, {'Nutrition_type': 'Fiber', 'value': 1}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Evolution Fresh™ Organic Ginger Limeade': [{'Nutrition_type': 'Calories', 'value': 110}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 28}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Iced Coffee': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Iced Espresso Classics - Vanilla Latte': [{'Nutrition_type': 'Calories', 'value': 130}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 21}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 5}, {'Nutrition_type': 'Sodium', 'value': 65}], 'Iced Espresso Classics - Caffe Mocha': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 23}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 5}, {'Nutrition_type': 'Sodium', 'value': 90}], 'Iced Espresso Classics - Caramel Macchiato': [{'Nutrition_type': 'Calories', 'value': 130}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 21}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 5}, {'Nutrition_type': 'Sodium', 'value': 65}], 'Shaken Sweet Tea': [{'Nutrition_type': 'Calories', 'value': 80}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 19}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Berry Blossom White': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 15}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Black Mango': [{'Nutrition_type': 'Calories', 'value': 150}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 38}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Tazo® Bottled Black with Lemon': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Brambleberry': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Tazo® Bottled Giant Peach': [{'Nutrition_type': 'Calories', 'value': 150}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 37}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Tazo® Bottled Iced Passion': [{'Nutrition_type': 'Calories', 'value': 70}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 17}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Lemon Ginger': [{'Nutrition_type': 'Calories', 'value': 120}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 31}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Organic Black Lemonade': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Organic Iced Black Tea': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 15}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Organic Iced Green Tea': [{'Nutrition_type': 'Calories', 'value': 120}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 31}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Plum Pomegranate': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Tazo® Bottled Tazoberry': [{'Nutrition_type': 'Calories', 'value': 150}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 38}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Tazo® Bottled White Cranberry': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Teavana® Shaken Iced Black Tea': [{'Nutrition_type': 'Calories', 'value': 30}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 8}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Teavana® Shaken Iced Black Tea Lemonade': [{'Nutrition_type': 'Calories', 'value': 70}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 17}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Teavana® Shaken Iced Green Tea': [{'Nutrition_type': 'Calories', 'value': 30}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 8}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Teavana® Shaken Iced Green Tea Lemonade': [{'Nutrition_type': 'Calories', 'value': 70}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 17}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Teavana® Shaken Iced Passion Tango™ Tea': [{'Nutrition_type': 'Calories', 'value': 30}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 8}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 5}], 'Teavana® Shaken Iced Passion Tango™ Tea Lemonade': [{'Nutrition_type': 'Calories', 'value': 90}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 24}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Teavana® Shaken Iced Peach Green Tea': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 15}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks Refreshers™ Raspberry Pomegranate': [{'Nutrition_type': 'Calories', 'value': 90}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 27}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks Refreshers™ Strawberry Lemonade': [{'Nutrition_type': 'Calories', 'value': 90}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 27}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks® Doubleshot Protein Dark Chocolate': [{'Nutrition_type': 'Calories', 'value': 210}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 33}, {'Nutrition_type': 'Fiber', 'value': 2}, {'Nutrition_type': 'Protein', 'value': 20}, {'Nutrition_type': 'Sodium', 'value': 115}], 'Starbucks® Doubleshot Protein Vanilla': [{'Nutrition_type': 'Calories', 'value': 200}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 34}, {'Nutrition_type': 'Fiber', 'value': 2}, {'Nutrition_type': 'Protein', 'value': 20}, {'Nutrition_type': 'Sodium', 'value': 120}], 'Starbucks® Iced Coffee Caramel': [{'Nutrition_type': 'Calories', 'value': 60}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 13}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks® Iced Coffee Light Sweetened': [{'Nutrition_type': 'Calories', 'value': 50}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 11}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Starbucks® Iced Coffee Unsweetened': [{'Nutrition_type': 'Calories', 'value': 10}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 2}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Blonde Roast': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Clover® Brewed Coffee': [{'Nutrition_type': 'Calories', 'value': 10}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Decaf Pike Place® Roast': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Featured Dark Roast': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Nariño 70 Cold Brew': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 15}], 'Nariño 70 Cold Brew with Milk': [{'Nutrition_type': 'Calories', 'value': 0}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Nitro Cold Brew': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 0}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Nitro Cold Brew with Sweet Cream': [{'Nutrition_type': 'Calories', 'value': 70}, {'Nutrition_type': 'Fat', 'value': 5.0}, {'Nutrition_type': 'Carb', 'value': 5}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 20}], 'Pike Place® Roast': [{'Nutrition_type': 'Calories', 'value': 5}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 0}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 10}], 'Vanilla Sweet Cream Cold Brew': [{'Nutrition_type': 'Calories', 'value': 110}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 14}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 1}, {'Nutrition_type': 'Sodium', 'value': 25}], 'Hot Chocolate': [{'Nutrition_type': 'Calories', 'value': 320}, {'Nutrition_type': 'Fat', 'value': 9.0}, {'Nutrition_type': 'Carb', 'value': 47}, {'Nutrition_type': 'Fiber', 'value': 4}, {'Nutrition_type': 'Protein', 'value': 14}, {'Nutrition_type': 'Sodium', 'value': 160}], 'Starbucks® Signature Hot Chocolate': [{'Nutrition_type': 'Calories', 'value': 430}, {'Nutrition_type': 'Fat', 'value': 26.0}, {'Nutrition_type': 'Carb', 'value': 45}, {'Nutrition_type': 'Fiber', 'value': 5}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 115}], 'Caffè Latte': [{'Nutrition_type': 'Calories', 'value': 190}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 19}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 13}, {'Nutrition_type': 'Sodium', 'value': 170}], 'Caffè Mocha': [{'Nutrition_type': 'Calories', 'value': 290}, {'Nutrition_type': 'Fat', 'value': 8.0}, {'Nutrition_type': 'Carb', 'value': 42}, {'Nutrition_type': 'Fiber', 'value': 4}, {'Nutrition_type': 'Protein', 'value': 13}, {'Nutrition_type': 'Sodium', 'value': 140}], 'Cappuccino': [{'Nutrition_type': 'Calories', 'value': 120}, {'Nutrition_type': 'Fat', 'value': 4.0}, {'Nutrition_type': 'Carb', 'value': 12}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 8}, {'Nutrition_type': 'Sodium', 'value': 100}], 'Caramel Macchiato': [{'Nutrition_type': 'Calories', 'value': 250}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 35}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 150}], 'Cinnamon Dolce Latte': [{'Nutrition_type': 'Calories', 'value': 260}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 40}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 11}, {'Nutrition_type': 'Sodium', 'value': 150}], 'Coconutmilk Mocha Macchiato': [{'Nutrition_type': 'Calories', 'value': 250}, {'Nutrition_type': 'Fat', 'value': 9.0}, {'Nutrition_type': 'Carb', 'value': 32}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 180}], 'Flat White': [{'Nutrition_type': 'Calories', 'value': 180}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 18}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 160}], 'Iced Caffè Latte': [{'Nutrition_type': 'Calories', 'value': 130}, {'Nutrition_type': 'Fat', 'value': 4.5}, {'Nutrition_type': 'Carb', 'value': 13}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 8}, {'Nutrition_type': 'Sodium', 'value': 115}], 'Iced Caffè Mocha': [{'Nutrition_type': 'Calories', 'value': 230}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 36}, {'Nutrition_type': 'Fiber', 'value': 4}, {'Nutrition_type': 'Protein', 'value': 9}, {'Nutrition_type': 'Sodium', 'value': 90}], 'Iced Caramel Macchiato': [{'Nutrition_type': 'Calories', 'value': 250}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 37}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 150}], 'Iced Cinnamon Dolce Latte': [{'Nutrition_type': 'Calories', 'value': 200}, {'Nutrition_type': 'Fat', 'value': 4.0}, {'Nutrition_type': 'Carb', 'value': 34}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 7}, {'Nutrition_type': 'Sodium', 'value': 95}], 'Iced Coconutmilk Mocha Macchiato': [{'Nutrition_type': 'Calories', 'value': 260}, {'Nutrition_type': 'Fat', 'value': 9.0}, {'Nutrition_type': 'Carb', 'value': 34}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 11}, {'Nutrition_type': 'Sodium', 'value': 180}], 'Iced Vanilla Latte': [{'Nutrition_type': 'Calories', 'value': 190}, {'Nutrition_type': 'Fat', 'value': 4.0}, {'Nutrition_type': 'Carb', 'value': 30}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 7}, {'Nutrition_type': 'Sodium', 'value': 100}], 'Iced White Chocolate Mocha': [{'Nutrition_type': 'Calories', 'value': 300}, {'Nutrition_type': 'Fat', 'value': 8.0}, {'Nutrition_type': 'Carb', 'value': 47}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 190}], 'Latte Macchiato': [{'Nutrition_type': 'Calories', 'value': 190}, {'Nutrition_type': 'Fat', 'value': 7.0}, {'Nutrition_type': 'Carb', 'value': 19}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 160}], 'Starbucks Doubleshot® on Ice Beverage': [{'Nutrition_type': 'Calories', 'value': 45}, {'Nutrition_type': 'Fat', 'value': 1.0}, {'Nutrition_type': 'Carb', 'value': 5}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 3}, {'Nutrition_type': 'Sodium', 'value': 40}], 'Vanilla Latte': [{'Nutrition_type': 'Calories', 'value': 250}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 37}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 12}, {'Nutrition_type': 'Sodium', 'value': 150}], 'White Chocolate Mocha': [{'Nutrition_type': 'Calories', 'value': 360}, {'Nutrition_type': 'Fat', 'value': 11.0}, {'Nutrition_type': 'Carb', 'value': 53}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 14}, {'Nutrition_type': 'Sodium', 'value': 240}], 'Cinnamon Dolce Frappuccino® Blended Coffee': [{'Nutrition_type': 'Calories', 'value': 350}, {'Nutrition_type': 'Fat', 'value': 4.5}, {'Nutrition_type': 'Carb', 'value': 64}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 15}, {'Nutrition_type': 'Sodium', 'value': 0}], 'Coffee Light Frappuccino® Blended Coffee': [{'Nutrition_type': 'Calories', 'value': 110}, {'Nutrition_type': 'Fat', 'value': 0.0}, {'Nutrition_type': 'Carb', 'value': 24}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 3}, {'Nutrition_type': 'Sodium', 'value': 200}], 'Mocha Frappuccino® Blended Coffee': [{'Nutrition_type': 'Calories', 'value': 280}, {'Nutrition_type': 'Fat', 'value': 2.5}, {'Nutrition_type': 'Carb', 'value': 60}, {'Nutrition_type': 'Fiber', 'value': 2}, {'Nutrition_type': 'Protein', 'value': 4}, {'Nutrition_type': 'Sodium', 'value': 220}], 'Mocha Light Frappuccino® Blended Coffee': [{'Nutrition_type': 'Calories', 'value': 140}, {'Nutrition_type': 'Fat', 'value': 0.5}, {'Nutrition_type': 'Carb', 'value': 28}, {'Nutrition_type': 'Fiber', 'value': 1}, {'Nutrition_type': 'Protein', 'value': 4}, {'Nutrition_type': 'Sodium', 'value': 180}], 'Cinnamon Dolce Crème': [{'Nutrition_type': 'Calories', 'value': 200}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 28}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 135}], 'Vanilla Crème': [{'Nutrition_type': 'Calories', 'value': 200}, {'Nutrition_type': 'Fat', 'value': 6.0}, {'Nutrition_type': 'Carb', 'value': 28}, {'Nutrition_type': 'Fiber', 'value': 0}, {'Nutrition_type': 'Protein', 'value': 10}, {'Nutrition_type': 'Sodium', 'value': 135}], 'Chocolate Smoothie': [{'Nutrition_type': 'Calories', 'value': 320}, {'Nutrition_type': 'Fat', 'value': 5.0}, {'Nutrition_type': 'Carb', 'value': 53}, {'Nutrition_type': 'Fiber', 'value': 8}, {'Nutrition_type': 'Protein', 'value': 20}, {'Nutrition_type': 'Sodium', 'value': 170}], 'Strawberry Smoothie': [{'Nutrition_type': 'Calories', 'value': 300}, {'Nutrition_type': 'Fat', 'value': 2.0}, {'Nutrition_type': 'Carb', 'value': 60}, {'Nutrition_type': 'Fiber', 'value': 7}, {'Nutrition_type': 'Protein', 'value': 16}, {'Nutrition_type': 'Sodium', 'value': 130}]}\n\n\nA.3.1 \nWhat is the nested data structure of the object starbucks_drinks_nutrition? An example of a nested data structure can be a list of dictionaries, where the dictionary values are a tuple of dictionaries?\n(1 point)\n\n\nA.3.2 \nUse dictionary-comprehension to print the name and carb content of all drinks that have a carb content of more than 50 units.\nHint: It will be a nested dictionary comprehension.\n(6 points)"
  },
  {
    "objectID": "Assignment A.html#ted-talks",
    "href": "Assignment A.html#ted-talks",
    "title": "Appendix A — Assignment A",
    "section": "A.4 Ted talks",
    "text": "A.4 Ted talks\n\nA.4.1 \nRead the data on ted talks from 2006 to 2017.\n(1 point)\n\n\nA.4.2 \nFind the number of talks in the dataset.\n(1 point)\n\n\nA.4.3 \nFind the headline, speaker and year_filmed of the talk with the highest number of views.\n(4 points)\n\n\nA.4.4 \nDo the majority of talks have less views than the average number of views for a talk? Justify your answer.\n(3 points)\nHint: Print summary statistics for questions (4) and (5).\n\n\nA.4.5 \nDo at least 25% of the talks have more views than the average number of views for a talk? Justify your answer.\n(3 points)\n\n\nA.4.6 \nThe last column of the dataset consists of votes obtained by the talk under different categories, such as Funny, Confusing, Fascinating, etc. For each category, create a new column in the dataset that contains the votes obtained by the tedtalk in that category. Print the first 5 rows of the updated dataset.\n(8 points)\n\n\nA.4.7 \nWith the data created in (a), find the headline of the talk that received the highest number of votes as Confusing.\n(4 points)\n\n\nA.4.8 \nWith the data created in (a), find the headline and the year of the talk that received the highest percentage of votes in the Fascinating category.\n\\[\\text{Percentage of } \\textit{Fascinating} \\text{ votes for a ted talk} = \\frac{Number \\ of \\  votes \\ in \\ the \\ category \\ `Fascinating`}{Total \\ votes \\ in \\ all  \\ categories}\\]\n(7 points)"
  },
  {
    "objectID": "Assignment A.html#university-rankings",
    "href": "Assignment A.html#university-rankings",
    "title": "Appendix A — Assignment A",
    "section": "A.5 University rankings",
    "text": "A.5 University rankings\n\nA.5.1 \nDownload the data set “univ.txt”. Read it with python.\n(1 point)\n\n\nA.5.2 \nFind summary statistics of the data. Based on the statistics, answer the next four questions.\n(1 point)\n\n\nA.5.3 \nHow many universities are there in the data set?\n(1 point)\n\n\nA.5.4 \nEstimate the maximum Tuition and fees among universities that are in the bottom 25% when ranked by total tuition and fees.\n(2 points)\n\n\nA.5.5 \nHow many universities share the ranking of 220? (If s universities share the same rank, say r, then the next lower rank is r+s, and all the ranks in between r and r+s are dropped)\n(4 points)\n\n\nA.5.6 \nCan you find the mean Tuition and fees for an undergrad student in the US from the summary statistics? Justify your answer.\n(3 points)\n\n\nA.5.7 \nFind the average Tuition and fees for an undergrad student in the US.\n(5 points)"
  },
  {
    "objectID": "Assignment A.html#file-formats",
    "href": "Assignment A.html#file-formats",
    "title": "Appendix A — Assignment A",
    "section": "A.6 File formats",
    "text": "A.6 File formats\nConsider the file formats - csv, JSON, txt. Mention one advantage and one disadvantage of each format over the other two formats.\n(2+2+2 = 6 points)"
  },
  {
    "objectID": "NumPy.html",
    "href": "NumPy.html",
    "title": "4  NumPy",
    "section": "",
    "text": "5 Learning Objectives\nBy the end of this lecture, students should be able to:"
  },
  {
    "objectID": "NumPy.html#getting-started",
    "href": "NumPy.html#getting-started",
    "title": "6  NumPy",
    "section": "6.2 Getting Started",
    "text": "6.2 Getting Started\n\n\nCode\n\nimport numpy as np\nimport pandas as pd\n\n\nIf you encounter a ‘ModuleNotFoundError’, please ensure that the module is installed in your current environment before attempting to import it\n\n\nCode\n#Using the NumPy function array() to define a NumPy array\nnumpy_array = np.array([[1,2],[3,4]])\nnumpy_array\n\n\narray([[1, 2],\n       [3, 4]])\n\n\n\n\nCode\ntype(numpy_array)\n\n\nnumpy.ndarray\n\n\nNumpy arrays can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the .shape property of an array.\n\n\n\nCode\nnumpy_array.ndim\n\n\n2"
  },
  {
    "objectID": "NumPy.html#data-types-in-numpy",
    "href": "NumPy.html#data-types-in-numpy",
    "title": "6  NumPy",
    "section": "6.3 Data Types in NumPy",
    "text": "6.3 Data Types in NumPy\nUnlike lists and tuples, NumPy arrays are designed to store elements of the same type, enabling more efficient memory usage and faster computations. The data type of the elements in a NumPy array can be accessed using the .dtype attribute\n\n\nCode\nnumpy_array.dtype\n\n\ndtype('int64')\n\n\nNumPy supports a wide range of data types, each with a specific memory size. Here is a list of common NumPy data types and the memory they consume:\nNote that: these data type correspond directly to C data types, since NumPy uses C for the core computational operations. This C implementation allows NumPy to perform array operations much faster and more efficiently than native Python data structures.\n\n\n\nData Type\nMemory Size\n\n\n\n\nnp.int8\n1 byte\n\n\nnp.int16\n2 bytes\n\n\nnp.int32\n4 bytes\n\n\nnp.int64\n8 bytes\n\n\nnp.uint8\n1 byte\n\n\nnp.uint16\n2 bytes\n\n\nnp.uint32\n4 bytes\n\n\nnp.uint64\n8 bytes\n\n\nnp.float16\n2 bytes\n\n\nnp.float32\n4 bytes\n\n\nnp.float64\n8 bytes\n\n\nnp.complex64\n8 bytes\n\n\nnp.complex128\n16 bytes\n\n\nnp.bool_\n1 byte\n\n\nnp.string_\n1 byte per character\n\n\nnp.unicode_\n4 bytes per character\n\n\nnp.object_\nVariable\n\n\nnp.datetime64\n8 bytes\n\n\nnp.timedelta64\n8 bytes\n\n\n\n\n6.3.1 Upcasting\nWhen creating a NumPy array with elements of different data types, NumPy automatically attempts to upcast the elements to a compatible data type that can accommodate all of them. This process is known as type coercion or type promotion. The rules for upcasting follow a hierarchy of data types to ensure no data is lost.\nBelow are two common types of upcasting with examples:\nNumeric Upcasting: If you mix integers and floats, NumPy will convert the entire array to floats.\n\n\nCode\narr = np.array([1, 2.5, 3])\nprint(arr.dtype)  \n\n\nfloat64\n\n\nString Upcasting: If you mix numbers and strings, NumPy will upcast all elements to strings.\n\n\nCode\narr = np.array([1, 'hello', 3.5])\nprint(arr.dtype)\n\n\n&lt;U32\n\n\n&lt;U21 is a NumPy data type that stands for a Unicode string with a maximum length of 21 characters."
  },
  {
    "objectID": "NumPy.html#why-do-we-need-numpy-arrays",
    "href": "NumPy.html#why-do-we-need-numpy-arrays",
    "title": "6  NumPy",
    "section": "6.4 Why do we need NumPy arrays?",
    "text": "6.4 Why do we need NumPy arrays?\nNumPy arrays can store data similarly to lists and tuples, and the same computations can be performed across these structures. However, NumPy is preferred because it is significantly more efficient, particularly when handling large datasets, due to its optimized memory usage and computational speed.\n\n6.4.1 Numpy arrays are memory efficient: Homogeneity and Contiguous Memory Storage\nA NumPy array is a collection of elements of the same data type, stored in contiguous memory locations. In contrast, data structures like lists can hold elements of different data types, stored in non-contiguous memory locations. This homogeneity and contiguous storage allow NumPy arrays to be densely packed, leading to lower memory consumption. The following example demonstrates how NumPy arrays are more memory-efficient compared to other data structures.\n\n\nCode\nimport sys\n\n# Create a NumPy array, Python list, and tuple with the same elements\narray = np.arange(1000)\npy_list = list(range(1000))\npy_tuple = tuple(range(1000))\n\n# Calculate memory usage\narray_memory = array.nbytes\nlist_memory = sys.getsizeof(py_list) + sum(sys.getsizeof(item) for item in py_list)\ntuple_memory = sys.getsizeof(py_tuple) + sum(sys.getsizeof(item) for item in py_tuple)\n\n# Display the memory usage\nmemory_usage = {\n    \"NumPy Array (in bytes)\": array_memory,\n    \"Python List (in bytes)\": list_memory,\n    \"Python Tuple (in bytes)\": tuple_memory\n}\n\nmemory_usage\n\n\n{'NumPy Array (in bytes)': 8000,\n 'Python List (in bytes)': 36056,\n 'Python Tuple (in bytes)': 36040}\n\n\n\n\nCode\n# each element in the array is a 64-bit integer\narray.dtype\n\n\ndtype('int64')\n\n\n\n\n6.4.2 NumPy arrays are fast\nWith NumPy arrays, mathematical computations can be performed faster, as compared to other data structures, due to the following reasons:\n\nAs the NumPy array is densely packed with homogenous data, it helps retrieve the data faster as well, thereby making computations faster.\nWith NumPy, vectorized computations can replace the relatively more expensive python for loops. The NumPy package breaks down the vectorized computations into multiple fragments and then processes all the fragments parallelly. However, with a for loop, computations will be one at a time.\nThe NumPy package integrates C, and C++ codes in Python. These programming languages have very little execution time as compared to Python.\n\nWe’ll see the faster speed on NumPy computations in the example below.\nExample: This example shows that computations using NumPy arrays are typically much faster than computations with other data structures.\nQ: Multiply whole numbers up to 1 million by an integer, say 2. Compare the time taken for the computation if the numbers are stored in a NumPy array vs a list.\nUse the numpy function arange() to define a one-dimensional NumPy array.\n\n\nCode\n#Examples showing NumPy arrays are more efficient for numerical computation\nimport time as tm\nstart_time = tm.time()\nlist_ex = list(range(1000000)) #List containinig whole numbers upto 1 million\na=(list_ex*2)\nprint(\"Time take to multiply numbers in a list = \", tm.time()-start_time)\n\nstart_time = tm.time()\ntuple_ex = tuple(range(1000000)) #Tuple containinig whole numbers upto 1 million\na=(tuple_ex*2)\nprint(\"Time take to multiply numbers in a tuple = \", tm.time()-start_time)\n\nstart_time = tm.time()\nnumpy_ex = np.arange(1000000) #NumPy array containinig whole numbers upto 1 million\na=(numpy_ex*2)\nprint(\"Time take to multiply numbers in a NumPy array = \", tm.time()-start_time)\n\n\nTime take to multiply numbers in a list =  0.02404475212097168\nTime take to multiply numbers in a tuple =  0.025005578994750977\nTime take to multiply numbers in a NumPy array =  0.010440349578857422"
  },
  {
    "objectID": "NumPy.html#basics-of-numpy-arrays",
    "href": "NumPy.html#basics-of-numpy-arrays",
    "title": "6  NumPy",
    "section": "6.5 Basics of NumPy Arrays",
    "text": "6.5 Basics of NumPy Arrays\n\n6.5.1 Creating Arrays:\nYou can create a NumPy array using various methods, such as:\n\nnp.array(): Creates an array from a list or iterable.\nnp.zeros(), np.ones(): Creates arrays filled with zeros or ones.\nnp.arange(), np.linespace(): Creates arrays with evenly spaced values.\nnp.random module: Generates arrays with random values.\n\nEach method is designed for different use cases. I encourage you to explore and experiment with these functions to see the types of arrays they produce and how they can be used in different scenarios.\n\n\n6.5.2 Array Attributes:\nLet us define a NumPy array in order to access its attributes:\n\n\nCode\nnumpy_ex = np.array([[1,2,3],[4,5,6]])\nnumpy_ex\n\n\narray([[1, 2, 3],\n       [4, 5, 6]])\n\n\nThe attributes of numpy_ex can be seen by typing numpy_ex followed by a ., and then pressing the tab key.\nSome of the basic attributes of a NumPy array are the following:\n\n6.5.2.1 ndim\nShows the number of dimensions (or axes) of the array.\n\n\nCode\nnumpy_ex.ndim\n\n\n2\n\n\n\n\n6.5.2.2 shape\nThis is a tuple of integers indicating the size of the array in each dimension. For a matrix with n rows and m columns, the shape will be (n,m). The length of the shape tuple is therefore the rank, or the number of dimensions, ndim.\n\n\nCode\nnumpy_ex.shape\n\n\n(2, 3)\n\n\n\n\n6.5.2.3 size\nThis is the total number of elements of the array, which is the product of the elements of shape.\n\n\nCode\nnumpy_ex.size\n\n\n6\n\n\n\n\n6.5.2.4 dtype\nThis is an object describing the type of the elements in the array. One can create or specify dtype’s using standard Python types. NumPy provides many, for example bool_, character, int_, int8, int16, int32, int64, float_, float8, float16, float32, float64, complex_, complex64, object_.\n\n\nCode\nnumpy_ex.dtype\n\n\ndtype('int32')"
  },
  {
    "objectID": "NumPy.html#array-indexing-and-slicing",
    "href": "NumPy.html#array-indexing-and-slicing",
    "title": "6  NumPy",
    "section": "6.6 Array Indexing and Slicing",
    "text": "6.6 Array Indexing and Slicing\n\n6.6.1 Array Indexing\nSimilar to Python lists, NumPy uses zero-based indexing, meaning the first element of an array is accessed using index 0. You can use positive or negative indices to access elements\n\n\nCode\narray = np.array([10, 20, 30, 40, 50])\n\nprint(array[0])  \nprint(array[4]) \nprint(array[-1])  \nprint(array[-3])  \n\n\n10\n50\n50\n30\n\n\nIn multi-dimensional arrays, indices are separated by commas. The first index refers to the row, and the second index refers to the column in a 2D array.\n\n\nCode\n# 2D array (3 rows, 3 columns)\narray_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nprint(array_2d)\nprint(array_2d[0, 1])  \nprint(array_2d[1, -1]) \nprint(array_2d[-1, -1])  \n\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n2\n6\n9\n\n\nYou can use boolean arrays to filter or select elements based on a condition\n\n\nCode\narray = np.array([10, 20, 30, 40, 50])\nmask = array &gt; 30  # Boolean mask for elements greater than 30\nprint(array[mask])  # Output: [40 50]\n\n\n[40 50]\n\n\n\n\n6.6.2 Array Slicing\nSlicing is used to extract a sub-array from an existing array.\nThe Syntax for slicing is `array[start:stop:step]\n\n\nCode\narray = np.array([10, 20, 30, 40, 50])\n\nprint(array[1:4])  \nprint(array[:3])  \nprint(array[2:])  \nprint(array[::2])  \nprint(array[::-1]) \n\n\n[20 30 40]\n[10 20 30]\n[30 40 50]\n[10 30 50]\n[50 40 30 20 10]\n\n\nFor slicing in Multi-Dimensional Arrays, use commas to separate slicing for different dimensions\n\n\nCode\narray_2d = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n\n# Extract a sub-array: elements from the first two rows and the first two columns\nsub_array = array_2d[:2, :2]\nprint(sub_array)  \n\n# Extract all rows for the second column\ncol = array_2d[:, 1]\nprint(col) \n\n# Extract the last two rows and last two columns\nsub_array = array_2d[-2:, -2:]\nprint(sub_array)  \n\n\n[[1 2]\n [4 5]]\n[2 5 8]\n[[5 6]\n [8 9]]\n\n\nThe step parameter can be used to select elements at regular intervals.\n\n\nCode\narray = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nprint(array[1:8:2]) \nprint(array[::-2])  \n\n\n[1 3 5 7]\n[9 7 5 3 1]\n\n\n\n\n6.6.3 Modify Sub-Arrays through Slicing\nSlices are views of the original array, not copies. Modifying a slice will change the original array.\n\n\nCode\narray = np.array([10, 20, 30, 40, 50])\narray[1:4] = 100  # Replace elements from index 1 to 3 with 100\nprint(array)  # Output: [ 10 100 100 100  50]\n\n\n[ 10 100 100 100  50]\n\n\n\n\n6.6.4 Combining Indexing and Slicing\nYou can combine indexing and slicing to extract specific elements or sub-arrays\n\n\nCode\n# Create a 3D array\narray_3d = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n\n# Select specific elements and slices\nprint(array_3d[0, :, 1])  # Output: [2 5] (second element from each row in the first sub-array)\nprint(array_3d[1, 1, :2])  # Output: [10 11] (first two elements in the last row of the second sub-array)\n\n\n[2 5]\n[10 11]\n\n\n\n\n6.6.5 np.where() and np.select()\nYou can also use np.where and np.select for array slicing and conditional selection.\n\n\nCode\narray_3d\n\n\narray([[[ 1,  2,  3],\n        [ 4,  5,  6]],\n\n       [[ 7,  8,  9],\n        [10, 11, 12]]])\n\n\n\n\nCode\n# Using np.where to create a mask and select elements greater than 5\ngreater_than_5 = np.where(array_3d &gt; 5, array_3d, 0)\nprint(\"Elements greater than 5:\\n\", greater_than_5)\n\n# Using np.select to categorize elements into three categories\nconditions = [array_3d &lt; 4, (array_3d &gt;= 4) & (array_3d &lt;= 8), array_3d &gt; 8]\nchoices = ['low', 'medium', 'high']\ncategorized_array = np.select(conditions, choices, default='unknown')\nprint(\"\\nCategorized array:\\n\", categorized_array)\n\n\nElements greater than 5:\n [[[ 0  0  0]\n  [ 0  0  6]]\n\n [[ 7  8  9]\n  [10 11 12]]]\n\nCategorized array:\n [[['low' 'low' 'low']\n  ['medium' 'medium' 'medium']]\n\n [['medium' 'medium' 'high']\n  ['high' 'high' 'high']]]\n\n\nThis example shows how np.where and np.select can be used to filter, manipulate, and categorize elements within a 3D array based on specific conditions.\n\n\n6.6.6 np.argmin() and np.argmax()\nYou can use np.argmin and np.argmax to quickly find the index of the minimum or maximum value in an array along a specified axis. You’ll see their usage in the practice example below"
  },
  {
    "objectID": "NumPy.html#array-operations",
    "href": "NumPy.html#array-operations",
    "title": "6  NumPy",
    "section": "6.7 Array Operations",
    "text": "6.7 Array Operations\n\n6.7.1 Arithmetic operations\nNumpy arrays support arithmetic operators like +, -, *, etc. We can perform an arithmetic operation on an array either with a single number (also called scalar) or with another array of the same shape. However, we cannot perform an arithmetic operation on an array with an array of a different shape.\nBelow are some examples of arithmetic operations on arrays.\n\n\nCode\n#Defining two arrays of the same shape\narr1 = np.array([[1, 2, 3, 4], \n                 [5, 6, 7, 8], \n                 [9, 1, 2, 3]])\narr2 = np.array([[11, 12, 13, 14], \n                 [15, 16, 17, 18], \n                 [19, 11, 12, 13]])\n\n\n\n\nCode\n#Element-wise summation of arrays\narr1 + arr2\n\n\narray([[12, 14, 16, 18],\n       [20, 22, 24, 26],\n       [28, 12, 14, 16]])\n\n\n\n\nCode\n# Element-wise subtraction\narr2 - arr1\n\n\narray([[10, 10, 10, 10],\n       [10, 10, 10, 10],\n       [10, 10, 10, 10]])\n\n\n\n\nCode\n# Adding a scalar to an array adds the scalar to each element of the array\narr1 + 3\n\n\narray([[ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12,  4,  5,  6]])\n\n\n\n\nCode\n# Dividing an array by a scalar divides all elements of the array by the scalar\narr1 / 2\n\n\narray([[0.5, 1. , 1.5, 2. ],\n       [2.5, 3. , 3.5, 4. ],\n       [4.5, 0.5, 1. , 1.5]])\n\n\n\n\nCode\n# Element-wise multiplication\narr1 * arr2\n\n\narray([[ 11,  24,  39,  56],\n       [ 75,  96, 119, 144],\n       [171,  11,  24,  39]])\n\n\n\n\nCode\n# Modulus operator with scalar\narr1 % 4\n\n\narray([[1, 2, 3, 0],\n       [1, 2, 3, 0],\n       [1, 1, 2, 3]], dtype=int32)\n\n\n\n\n6.7.2 Comparison and Logical Operation\nNumpy arrays support comparison operations like ==, !=, &gt; etc. The result is an array of booleans.\n\n\nCode\narr1 = np.array([[1, 2, 3], [3, 4, 5]])\narr2 = np.array([[2, 2, 3], [1, 2, 5]])\n\n\n\n\nCode\narr1 == arr2\n\n\narray([[False,  True,  True],\n       [False, False,  True]])\n\n\n\n\nCode\narr1 != arr2\n\n\narray([[ True, False, False],\n       [ True,  True, False]])\n\n\n\n\nCode\narr1 &gt;= arr2\n\n\narray([[False,  True,  True],\n       [ True,  True,  True]])\n\n\n\n\nCode\narr1 &lt; arr2\n\n\narray([[ True, False, False],\n       [False, False, False]])\n\n\nArray comparison is frequently used to count the number of equal elements in two arrays using the sum method. Remember that True evaluates to 1 and False evaluates to 0 when booleans are used in arithmetic operations.\n\n\nCode\n(arr1 == arr2).sum()\n\n\n3\n\n\n\n\n6.7.3 Aggregate Functions: np.sum(), np.mean(), np.min(), np.max()\n\n6.7.3.1 Overall Aggregate Calculations:\n\nnp.sum(array): Calculates the sum of all elements in the array.\nnp.mean(array): Calculates the mean of all elements in the array.\nnp.min(array): Finds the minimum value in the entire array.\nnp.max(array): Finds the maximum value in the entire array.\n\n\n\n6.7.3.2 Row-Wise Calculations (axis=1):\n\nnp.sum(array, axis=1): Computes the sum of elements in each row.\nnp.mean(array, axis=1): Computes the mean of elements in each row.\nnp.min(array, axis=1): Finds the minimum value in each row.\nnp.max(array, axis=1): Finds the maximum value in each row.\n\n\n\n6.7.3.3 Column-Wise Calculations (axis=0):\n\nnp.sum(array, axis=0): Computes the sum of elements in each column.\nnp.mean(array, axis=0): Computes the mean of elements in each column.\nnp.min(array, axis=0): Finds the minimum value in each column.\nnp.max(array, axis=0): Finds the maximum value in each column.\n\n\n\nCode\n# Create a 3x4 array of integers\narray = np.array([[4, 7, 1, 3],\n                  [5, 8, 2, 6],\n                  [9, 3, 5, 2]])\n\n# Display the original array\nprint(\"Original Array:\\n\", array)\n\n# Calculate the sum, mean, minimum, and maximum for the entire array\ntotal_sum = np.sum(array)\nmean_value = np.mean(array)\nmin_value = np.min(array)\nmax_value = np.max(array)\n\nprint(f\"\\nSum of all elements: {total_sum}\")  \nprint(f\"Mean of all elements: {mean_value}\")  \nprint(f\"Minimum value in the array: {min_value}\")  \nprint(f\"Maximum value in the array: {max_value}\")  \n\n# Calculate the sum, mean, minimum, and maximum along each row (axis=1)\nrow_sum = np.sum(array, axis=1)\nrow_mean = np.mean(array, axis=1)\nrow_min = np.min(array, axis=1)\nrow_max = np.max(array, axis=1)\n\nprint(\"\\nSum along each row:\", row_sum)  \nprint(\"Mean along each row:\", row_mean)  \nprint(\"Minimum value along each row:\", row_min)  \nprint(\"Maximum value along each row:\", row_max)  \n\n# Calculate the sum, mean, minimum, and maximum along each column (axis=0)\ncol_sum = np.sum(array, axis=0)\ncol_mean = np.mean(array, axis=0)\ncol_min = np.min(array, axis=0)\ncol_max = np.max(array, axis=0)\n\nprint(\"\\nSum along each column:\", col_sum)  \nprint(\"Mean along each column:\", col_mean)  \nprint(\"Minimum value along each column:\", col_min)  \nprint(\"Maximum value along each column:\", col_max)  \n\n\nOriginal Array:\n [[4 7 1 3]\n [5 8 2 6]\n [9 3 5 2]]\n\nSum of all elements: 55\nMean of all elements: 4.583333333333333\nMinimum value in the array: 1\nMaximum value in the array: 9\n\nSum along each row: [15 21 19]\nMean along each row: [3.75 5.25 4.75]\nMinimum value along each row: [1 2 2]\nMaximum value along each row: [7 8 9]\n\nSum along each column: [18 18  8 11]\nMean along each column: [6.         6.         2.66666667 3.66666667]\nMinimum value along each column: [4 3 1 2]\nMaximum value along each column: [9 8 5 6]"
  },
  {
    "objectID": "NumPy.html#array-reshaping",
    "href": "NumPy.html#array-reshaping",
    "title": "6  NumPy",
    "section": "6.8 Array Reshaping",
    "text": "6.8 Array Reshaping\nCertain functions and machine learning models require input data in a specific shape or format. For instance, operations like matrix multiplication and broadcasting depend on the alignment of array dimensions. Many deep learning models expect input data to be in a 4D array format (batch size, height, width, channels). Reshaping enables us to convert data into the necessary shape, ensuring compatibility without altering the underlying values.\nBelow are some methods to reshape NumPy arrays:\n\n6.8.1 reshape()\nThe reshape method in NumPy allows you to change the shape of an existing array without changing its data.\n\n\nCode\narr = np.array([1, 2, 3, 4, 5, 6])\nreshaped_arr = arr.reshape(2, 3)\nprint(reshaped_arr)\n\n\n[[1 2 3]\n [4 5 6]]\n\n\nUsing-1 for automatic dimension inference\n\n\nCode\narr = np.arange(12)\nreshaped_arr = arr.reshape(3, -1)\nprint(reshaped_arr)\n\n\n[[ 0  1  2  3]\n [ 4  5  6  7]\n [ 8  9 10 11]]\n\n\nHere, -1 means “calculate this dimension based on the remaining dimensions and the total size of the array”. So, (3, -1) becomes (3, 4).\n\n\n6.8.2 flatten() and ravel()\nThe flatten method returns a copy of the array collapsed into one dimension. It is useful when you need to perform operations that require 1D input or need to pass the array data as a linear sequence. order specifies the order in which elements are read, options include but not limited to: * C (default): Row-major (C-style). * F: Column-major (Fortran-style).\nIn contrast, ravel() returns a flattened view of the original array whenever possible, without creating a copy.\n\n\nCode\narr = np.array([[1, 2, 3], [4, 5, 6]])\nflattened_arr = arr.flatten()\nprint(flattened_arr)\n\n\n[1 2 3 4 5 6]\n\n\n\n\nCode\n# using ravel() to flatten the array\nflattened_arr = arr.ravel()\nprint(flattened_arr)\n\n\n[1 2 3 4 5 6]\n\n\n\n\n6.8.3 resize()\nChanges the shape and size of an array in place. Unlike reshape(), it can modify the array and fill additional elements with zeros if necessary.\n\n\nCode\narr = np.array([1, 2, 3, 4])\narr.resize(2, 3) \nprint(arr)\n\n\n[[1 2 3]\n [4 0 0]]\n\n\n\n\n6.8.4 tranpose() or T\nBoth can be used to transpose the NumPy array. This is often used to make matrices (2-dimensional arrays) compatible for multiplication.\n\n\nCode\narr = np.array([[1, 2, 3], [4, 5, 6]])\ntransposed_arr = arr.transpose()  # Output: [[1 4], [2 5], [3 6]]\nprint(transposed_arr)\n\nT_arr = arr.T  # Output: [[1 4], [2 5], [3 6]]\nprint(T_arr)\n\n\n[[1 4]\n [2 5]\n [3 6]]\n[[1 4]\n [2 5]\n [3 6]]"
  },
  {
    "objectID": "NumPy.html#arrays-concaternating",
    "href": "NumPy.html#arrays-concaternating",
    "title": "6  NumPy",
    "section": "6.9 Arrays Concaternating",
    "text": "6.9 Arrays Concaternating\nNumPy provides several functions to concatenate arrays along different axes.\n\n6.9.1 np.concatenate()\nArrays can be concatenated along an axis with NumPy’s concatenate function. The axis argument specifies the dimension for concatenation. The arrays should have the same number of dimensions, and the same length along each axis except the axis used for concatenation.\nThe examples below show concatenation of arrays.\n\n\nCode\narr1 = np.array([[1, 2, 3], [3, 4, 5]])\narr2 = np.array([[2, 2, 3], [1, 2, 5]])\nprint(\"Array 1:\\n\",arr1)\nprint(\"Array 2:\\n\",arr2)\n\n\nArray 1:\n [[1 2 3]\n [3 4 5]]\nArray 2:\n [[2 2 3]\n [1 2 5]]\n\n\n\n\nCode\n#Concatenating the arrays along the default axis: axis=0\nnp.concatenate((arr1,arr2))\n\n\narray([[1, 2, 3],\n       [3, 4, 5],\n       [2, 2, 3],\n       [1, 2, 5]])\n\n\n\n\nCode\n#Concatenating the arrays along axis = 1\nnp.concatenate((arr1,arr2),axis=1)\n\n\narray([[1, 2, 3, 2, 2, 3],\n       [3, 4, 5, 1, 2, 5]])\n\n\nHere’s a visual explanation of np.concatenate along axis=1 (can you guess what axis=0 results in?):\n\nSince the arrays need to have the same dimension only along the axis of concatenation, let us try concatenate the array below (arr3) with arr1, along axis = 0.\n\n\nCode\narr3 = np.array([2, 2, 3])\n\n\n\n\nCode\nnp.concatenate((arr1,arr3),axis=0)\n\n\nValueError: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)\n\n\nNote the above error, which indicates that arr3 has only one dimension. Let us check the shape of arr3.\n\n\nCode\narr3.shape\n\n\n(3,)\n\n\nWe can reshape arr3 to a shape of (1,3) to make it compatible for concatenation with arr1 along axis = 0.\n\n\nCode\narr3_reshaped = arr3.reshape(1,3)\narr3_reshaped\n\n\narray([[2, 2, 3]])\n\n\nNow we can concatenate the reshaped arr3 with arr1 along axis = 0.\n\n\nCode\nnp.concatenate((arr1,arr3_reshaped),axis=0)\n\n\narray([[1, 2, 3],\n       [3, 4, 5],\n       [2, 2, 3]])\n\n\n\n\n6.9.2 np.vstack() and np.hstack()\n\nnp.vstack(): Stacks arrays vertically (along rows).\nnp.hstack(): Stacks arrays horizontally (along columns).\n\n\n\nCode\n# Vertical stacking\nvstack = np.vstack((arr1, arr2))\nprint(\"\\nVertical Stack:\\n\", vstack)\n\n# Horizontal stacking\nhstack = np.hstack((arr1, arr2))\nprint(\"\\nHorizontal Stack:\\n\", hstack)\n\n\n\nVertical Stack:\n [[1 2 3]\n [3 4 5]\n [2 2 3]\n [1 2 5]]\n\nHorizontal Stack:\n [[1 2 3 2 2 3]\n [3 4 5 1 2 5]]"
  },
  {
    "objectID": "NumPy.html#vectorization-in-numpy",
    "href": "NumPy.html#vectorization-in-numpy",
    "title": "6  NumPy",
    "section": "6.10 Vectorization in NumPy",
    "text": "6.10 Vectorization in NumPy\n\n6.10.1 Introduction to Vectorization\nVectorization is the process of applying operations to entire arrays or matrices simultaneously rather than iterating over individual elements using loops. This approach allows NumPy to utilize highly optimized C libraries for faster computation.\n\nBenefits of Vectorization:\n\nPerformance: Significantly faster than using for-loops in Python.\nConciseness: Shorter and more readable code.\nEfficiency: Reduces the overhead of Python loops and leverages lower-level optimizations.\n\n\n\n6.10.2 Understanding Vectorized Operations with Examples\n\n\nCode\n# Create two arrays\narr1 = np.array([1, 2, 3, 4, 5])\narr2 = np.array([10, 20, 30, 40, 50])\n\n# Element-wise addition (vectorized operation)\nsum_arr = arr1 + arr2\nprint(\"Sum Array:\", sum_arr)\n\n\nSum Array: [11 22 33 44 55]\n\n\n\n\n6.10.3 NumPy Vectorization Vs Python for Loop\nnp.dot is a vectorized operation in NumPy that performs matrix multiplication or dot product between arrays. It efficiently computes the element-wise multiplications and then sums them up. To better understand its efficiency, let’s first implement the dot product using for loops, and then compare its performance with np.dot to see the benefits of vectorization.\n\n\nCode\nimport time\n\n# Function to calculate dot product using for loops\ndef dot_product_loops(arr1, arr2):\n    result = 0\n    for i in range(len(arr1)):\n        result += arr1[i] * arr2[i]\n    return result\n\n# Create sample arrays\narr1 = np.random.rand(1000000)\narr2 = np.random.rand(1000000)\n\n# Measure time for the loop-based implementation\nstart_time = time.time()\nloop_result = dot_product_loops(arr1, arr2)\nloop_time = time.time() - start_time\n\n# Measure time for np.dot\nstart_time = time.time()\nnumpy_result = np.dot(arr1, arr2)\nnumpy_time = time.time() - start_time\n\n# Display results\nprint(f\"Loop-based implementation result: {loop_result:.5f}, Time: {loop_time:.5f} seconds\")\nprint(f\"NumPy np.dot result: {numpy_result:.5f}, Time: {numpy_time:.5f} seconds\")\n\n\nLoop-based implementation result: 249915.69608, Time: 0.19019 seconds\nNumPy np.dot result: 249915.69608, Time: 0.00496 seconds\n\n\nThe np.dot function significantly outperforms the manual loop-based implementation because it leverages NumPy’s vectorized operations, which is written in highly efficient C code. This example highlights why vectorized operations like np.dot are preferred for large-scale numerical computations in NumPy.\n\n\n6.10.4 Broadcasting and Its Role in Vectorization\nBroadcasting allows NumPy to perform operations between arrays of different shapes by automatically expanding their dimensions. This is essential for vectorized operations involving arrays with varying shapes.\nLet’s look at an example to see how it works\n\n\nCode\narr2 = np.array([[1, 2, 3, 4], \n                 [5, 6, 7, 8], \n                 [9, 1, 2, 3]])\n\n\n\n\nCode\narr4 = np.array([4, 5, 6, 7])\n\n\n\n\nCode\narr2 + arr4\n\n\narray([[ 5,  7,  9, 11],\n       [ 9, 11, 13, 15],\n       [13,  6,  8, 10]])\n\n\nWhen the expression arr2 + arr4 is evaluated, arr4 (which has the shape (4,)) is replicated three times to match the shape (3, 4) of arr2. Numpy performs the replication without actually creating three copies of the smaller dimension array, thus improving performance and using lower memory.\n\nBroadcasting only works if one of the arrays can be replicated to match the other array’s shape. * Dimensions of size 1 will broadcast (as if the value was repeated). * Otherwise, the dimension must have the same shape.\n\n\nCode\narr5 = np.array([7, 8])\n\n\n\n\nCode\narr2 + arr5\n\n\nValueError: operands could not be broadcast together with shapes (3,4) (2,) \n\n\nIn the above example, even if arr5 is replicated three times, it will not match the shape of arr2. Hence arr2 + arr5 cannot be evaluated successfully. See the broadcasting documentation to learn more about it.\n\n\n6.10.5 Matrix Multiplication in NumPy with Vectorization\nMatrix multiplication is one of the most common and computationally intensive operations in numerical computing and deep learning. NumPy offers efficient and highly optimized methods for performing matrix multiplication, which leverage vectorization to handle large matrices quickly and accurately.\nNote that: NumPy matrix operations follow the standard rules of linear algebra, so it’s important to ensure that the shapes of the matrices are compatible. If they are not, consider reshaping the matrices before performing multiplication\nThere are two commonly methods for matrix multiplication\n\n6.10.5.1 Method 1: Matrix Multiplication Using np.dot()\n\n\nCode\n# Define two 2D arrays (matrices)\nmatrix1 = np.array([[1, 2, 3], \n                    [4, 5, 6]])\nmatrix2 = np.array([[7, 8], \n                    [9, 10], \n                    [11, 12]])\n\n# Matrix multiplication using np.dot\nresult_dot = np.dot(matrix1, matrix2)\nprint(\"Matrix Multiplication using np.dot:\\n\", result_dot)\n\n# Another way to perform np.dot for matrix multiplication\nresult_dot2 = matrix1.dot(matrix2)\nprint(\"\\nMatrix Multiplication using dot method:\\n\", result_dot2)\n\n\nMatrix Multiplication using np.dot:\n [[ 58  64]\n [139 154]]\n\nMatrix Multiplication using dot method:\n [[ 58  64]\n [139 154]]\n\n\n\n\n6.10.5.2 Method 2: Matrix Multiplication using np.matmul() pr @\n\n\nCode\n# Matrix multiplication using np.matmul or @ operator\nresult_matmul = np.matmul(matrix1, matrix2)\nresult_operator = matrix1 @ matrix2\nprint(\"\\nMatrix Multiplication using np.matmul:\\n\", result_matmul)\nprint(\"\\nMatrix Multiplication using @ operator:\\n\", result_operator)\n\n\n\nMatrix Multiplication using np.matmul:\n [[ 58  64]\n [139 154]]\n\nMatrix Multiplication using @ operator:\n [[ 58  64]\n [139 154]]\n\n\nNote that * operator in numpy is element-wise multiplication\n\n\nCode\n# using * operator for element-wise multiplication\nelement_wise = matrix1 * matrix2\nprint(\"\\nElement-wise Multiplication:\\n\", element_wise)\n\n\nValueError: operands could not be broadcast together with shapes (2,3) (3,2) \n\n\n\n\nCode\n# reshape the array for element-wise multiplication\nmatrix2_reshaped = matrix2.reshape(2, 3)\nelement_wise = matrix1 * matrix2_reshaped\nprint(\"\\nElement-wise Multiplication after reshaping:\\n\", element_wise)\n\n\n\nElement-wise Multiplication after reshaping:\n [[ 7 16 27]\n [40 55 72]]"
  },
  {
    "objectID": "NumPy.html#practical-applications-using-numpy",
    "href": "NumPy.html#practical-applications-using-numpy",
    "title": "6  NumPy",
    "section": "6.11 Practical Applications using NumPy",
    "text": "6.11 Practical Applications using NumPy\n\n6.11.1 Practice 1\n\n6.11.1.1 \nRead the coordinates of the capital cities of the world from https://gist.github.com/ofou/df09a6834a8421b4f376c875194915c9 .\nTask 1: Use NumPy to print the name and coordinates of the capital city closest to the US capital - Washington DC.\nNote that:\n\nThe Country Name for US is given as United States of America in the data.\nThe ‘closeness’ of capital cities from the US capital is based on the Euclidean distance of their coordinates to those of the US capital.\n\nHints:\n\nUse the to_numpy() function of the Pandas DataFrame class to convert a DataFrame to a Numpy array\nUse broadcasting to compute the euclidean distance of capital cities from Washington DC.\nUse np.argmin to locate the index of the minimum value in an array\nExclude the capital itself to avoid trivial zero values in the results.\n\nSolution:\n\n\nCode\n\ncapital_cities = pd.read_csv('../data/country-capital-lat-long-population.csv')\ncoordinates_capital_cities = capital_cities[['Latitude', 'Longitude']].to_numpy()\nus_coordinates = capital_cities.loc[capital_cities['Country']=='United States of America',['Latitude','Longitude']].to_numpy()\n\n#Broadcasting\ndistance_from_DC = np.sqrt(np.sum((us_coordinates-coordinates_capital_cities)**2,axis=1))\n\n#Assigning a high value of distance to DC, otherwise it will itself be selected as being closest to DC\ndistance_from_DC[distance_from_DC==0]=9999\nclosest_capital_index = np.argmin(distance_from_DC)\nprint(\"Closest capital city is:\" ,capital_cities.loc[closest_capital_index,'Capital City'])\nprint(\"Coordinates of the closest capital city are:\",coordinates_capital_cities[closest_capital_index,:])\n\n\nClosest capital city is: Ottawa-Gatineau\nCoordinates of the closest capital city are: [ 45.4166 -75.698 ]\n\n\nTask 2: Use NumPy to:\n\nPrint the names of the countries of the top 10 capital cities closest to the US capital - Washington DC.\nCreate and print a NumPy array containing the coordinates of the top 10 cities.\n\nHint: Use the concatenate() function from the NumPy library to stack the coordinates of the top 10 cities.\n\n\nCode\ntop10_cities_coordinates = coordinates_capital_cities[closest_capital_index,:].reshape(1,2)\nprint(\"Top 10 countries closest to Washington DC are:\\n Canada\")\nfor i in range(9):\n    distance_from_DC[closest_capital_index]=9999\n    closest_capital_index = np.argmin(distance_from_DC)\n    print(capital_cities.loc[closest_capital_index,'Country'])\n    top10_cities_coordinates=np.concatenate((top10_cities_coordinates,coordinates_capital_cities[closest_capital_index,:].reshape(1,2)))\nprint(\"Coordinates of the top 10 cities closest to US are: \\n\",top10_cities_coordinates)\n\n\nTop 10 countries closest to Washington DC are:\n Canada\nCuba\nTurks and Caicos Islands\nCayman Islands\nHaiti\nJamaica\nDominican Republic\nSaint Pierre and Miquelon\nPuerto Rico\nUnited States Virgin Islands\nCoordinates of the top 10 cities closest to US are: \n [[ 32.2915 -64.778 ]\n [ 23.1195 -82.3785]\n [ 21.4612 -71.1419]\n [ 19.2866 -81.3744]\n [ 18.5392 -72.335 ]\n [ 17.997  -76.7936]\n [ 18.4896 -69.9018]\n [ 46.7738 -56.1815]\n [ 18.4663 -66.1057]\n [ 18.3419 -64.9307]]\n\n\n\n\n6.11.1.2 Practice 2:\nThis exercise will show vectorized computations with NumPy. Vectorized computations help perform computations more efficiently, and also make the code concise.\nQ: Read the (1) quantities of roll, bun, cake and bread required by 3 people - Ben, Barbara & Beth, from food_quantity.csv, (2) price of these food items in two shops - Target and Kroger, from price.csv. Find out which shop should each person go to minimize their expenses.\n\n\nCode\n#Reading the datasets on food quantity and price\nimport pandas as pd\nfood_qty = pd.read_csv('../data/food_quantity.csv',index_col=0)\nprice = pd.read_csv('../data/price.csv',index_col=0)\n\n\n\n\nCode\nfood_qty\n\n\n\n\n\n\n\n\n\nroll\nbun\ncake\nbread\n\n\nPerson\n\n\n\n\n\n\n\n\nBen\n6\n5\n3\n1\n\n\nBarbara\n3\n6\n2\n2\n\n\nBeth\n3\n4\n3\n1\n\n\n\n\n\n\n\n\n\nCode\nprice\n\n\n\n\n\n\n\n\n\nTarget\nKroger\n\n\nItem\n\n\n\n\n\n\nroll\n1.5\n1.0\n\n\nbun\n2.0\n2.5\n\n\ncake\n5.0\n4.5\n\n\nbread\n16.0\n17.0\n\n\n\n\n\n\n\nFirst, let’s start from a simple problem. We’ll compute the expenses of Ben if he prefers to buy all food items from Target\n\n\nCode\n%%time\n# write a for loop to calculate the total cost of Ben's food if he shops at the Target store\ntotal_cost = 0 \nfor food in food_qty.columns:\n\n    total_cost += food_qty.loc['Ben',food]*price.loc[food,'Target']\ntotal_cost\n\n\nCPU times: total: 0 ns\nWall time: 0 ns\n\n\nnp.float64(50.0)\n\n\n\n\nCode\n%%time\n# using numpy \ntotal_cost = np.sum(food_qty.loc['Ben',]*price.loc[:,'Target'])\ntotal_cost\n\n\nCPU times: total: 0 ns\nWall time: 1 ms\n\n\nnp.float64(50.0)\n\n\nBen will spend $50 if he goes to Target\nNow, let’s add another layer of complication. We’ll compute Ben’s expenses for both stores - Target and Kroger\n\n\nCode\n%%time\n# using loops to calculate the total cost of food for Ben for all stores\ntotal_cost = {}\nfor store in price.columns:\n    total_cost[store] = 0\n    for food in food_qty.columns:\n        total_cost[store] += food_qty.loc['Ben',food]*price.loc[food,store]\ntotal_cost\n\n\nCPU times: total: 0 ns\nWall time: 1 ms\n\n\n{'Target': np.float64(50.0), 'Kroger': np.float64(49.0)}\n\n\n\n\nCode\n%%time\n# using numpy\ntotal_cost = np.dot(food_qty.loc['Ben',],price.loc[:,:])\ntotal_cost\n\n\nCPU times: total: 0 ns\nWall time: 0 ns\n\n\narray([50., 49.])\n\n\nBen will spend $50 if he goes to Target, and $49 if he goes to Kroger. Thus, he should choose Kroger.\nNow, let’s add the final layer of complication, and solve the problem. We’ll compute everyone’s expenses for both stores - Target and Kroger\n\n\nCode\n%%timeit\nstore_expense = pd.DataFrame(0.0, columns=price.columns, index = food_qty.index)\nfor person in store_expense.index:\n    for store in store_expense.columns:\n        for food in food_qty.columns:\n            store_expense.loc[person, store] += food_qty.loc[person, food]*price.loc[food, store]\n\nstore_expense\n\n\n1.51 ms ± 15.3 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n\n\n\n\nCode\n%%timeit\n# using matrix multiplication in numpy\npd.DataFrame(np.dot(food_qty.values, price.values), columns=price.columns, index=food_qty.index)\n\n\n11 μs ± 102 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n\n\nBased on the above table, Ben should go to Kroger, Barbara to Target and Beth can go to either store.\nAs the complexity of operations increases, the number of nested for-loops also grows, making the code more cumbersome and harder to manage. In contrast, the approach using NumPy arrays remains concise and straightforward, regardless of complexity. Vectorized computations are not only cleaner but also significantly faster, providing a more efficient solution.\n\n\n\n6.11.2 Practice 3\nUse matrix multiplication to find the average IMDB rating and average Rotten tomatoes rating for each genre - comedy, action, drama and horror. Use the data: movies_cleaned.csv. Which is the most preferred genre for IMDB users, and which is the least preferred genre for Rotten Tomatoes users?\nHint: 1. Create two matrices - one containing the IMDB and Rotten Tomatoes ratings, and the other containing the genre flags (comedy/action/drama/horror).\n\nMultiply the two matrices created in 1.\nDivide each row/column of the resulting matrix by a vector having the number of ratings in each genre to get the average rating for the genre.\n\nSolution:\n\n\nCode\ndata = pd.read_csv('../Data/movies_cleaned.csv')\ndata.head()\n\n\n\n\n\n\n\n\n\nTitle\nIMDB Rating\nRotten Tomatoes Rating\nRunning Time min\nRelease Date\nUS Gross\nWorldwide Gross\nProduction Budget\ncomedy\nAction\ndrama\nhorror\n\n\n\n\n0\nBroken Arrow\n5.8\n55\n108\nFeb 09 1996\n70645997\n148345997\n65000000\n0\n1\n0\n0\n\n\n1\nBrazil\n8.0\n98\n136\nDec 18 1985\n9929135\n9929135\n15000000\n1\n0\n0\n0\n\n\n2\nThe Cable Guy\n5.8\n52\n95\nJun 14 1996\n60240295\n102825796\n47000000\n1\n0\n0\n0\n\n\n3\nChain Reaction\n5.2\n13\n106\nAug 02 1996\n21226204\n60209334\n55000000\n0\n1\n0\n0\n\n\n4\nClash of the Titans\n5.9\n65\n108\nJun 12 1981\n30000000\n30000000\n15000000\n0\n1\n0\n0\n\n\n\n\n\n\n\n\n\nCode\n# Getting ratings of all movies\ndrating = data[['IMDB Rating','Rotten Tomatoes Rating']]\ndrating_num = drating.to_numpy() #Converting the data to NumPy array\ndrating_num\n\n\narray([[ 5.8, 55. ],\n       [ 8. , 98. ],\n       [ 5.8, 52. ],\n       ...,\n       [ 7. , 65. ],\n       [ 5.7, 26. ],\n       [ 6.7, 82. ]])\n\n\n\n\nCode\n# Getting the matrix indicating the genre of all movies\ndgenre = data.iloc[:,8:12]\ndgenre_num = dgenre.to_numpy() #Converting the data to NumPy array\ndgenre_num\n\n\narray([[0, 1, 0, 0],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       ...,\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 1, 0, 0]])\n\n\nWe’ll first find the total IMDB and Rotten tomatoes ratings for all movies of each genre, and then divide them by the number of movies of the corresponding genre to find the average rating for the genre.\nFor finding the total IMDB and Rotten tomatoes ratings, we’ll multiply drating_num with dgenre_num. However, before multiplying, we’ll check if their shapes are compatible for matrix multiplication.\n\n\nCode\n#Shape of drating_num\ndrating_num.shape\n\n\n(980, 2)\n\n\n\n\nCode\n#Shape of dgenre_num\ndgenre_num.shape\n\n\n(980, 4)\n\n\nNote that the above shapes are not compatible for matrix multiplication. We’ll transpose dgenre_num to make the shapes compatible.\n\n\nCode\n#Total IMDB and Rotten tomatoes ratings for each genre\nratings_sum_genre = drating_num.T.dot(dgenre_num)\nratings_sum_genre\n\n\narray([[ 1785.6,  1673.1,  1630.3,   946.2],\n       [14119. , 13725. , 14535. ,  6533. ]])\n\n\n\n\nCode\n#Number of movies in the data will be stored in 'rows', and number of columns stored in 'cols'\nrows, cols = data.shape\n\n\n\n\nCode\n#Getting number of movies in each genre\nmovies_count_genre = dgenre_num.T.dot(np.ones(rows))\nmovies_count_genre\n\n\narray([302., 264., 239., 154.])\n\n\n\n\nCode\n#Finding the average IMDB and average Rotten tomatoes ratings for each genre\nratings_sum_genre/movies_count_genre\n\n\narray([[ 5.91258278,  6.3375    ,  6.82133891,  6.14415584],\n       [46.75165563, 51.98863636, 60.81589958, 42.42207792]])\n\n\n\n\nCode\npd.DataFrame(ratings_sum_genre/movies_count_genre,columns = ['comedy','Action','drama','horror'],\n             index = ['IMDB Rating','Rotten Tomatoes Rating'])\n\n\n\n\n\n\n\n\n\ncomedy\nAction\ndrama\nhorror\n\n\n\n\nIMDB Rating\n5.912583\n6.337500\n6.821339\n6.144156\n\n\nRotten Tomatoes Rating\n46.751656\n51.988636\n60.815900\n42.422078\n\n\n\n\n\n\n\nIMDB users prefer drama, and are amused the least by comedy movies, on an average. However, Rotten tomatoes critics would rather watch comedy than horror movies, on an average."
  },
  {
    "objectID": "NumPy.html#random-number-generation-in-numpy",
    "href": "NumPy.html#random-number-generation-in-numpy",
    "title": "6  NumPy",
    "section": "6.12 Random Number Generation in NumPy",
    "text": "6.12 Random Number Generation in NumPy\nNumPy provides a variety of functions for generating random numbers through its numpy.random module. These functions can generate random numbers for different distributions and array shapes, making them essential for simulations, statistical sampling, and machine learning applications.\n\n6.12.1 Key Functions for Random Number Generation in NumPy\n\nnp.random.rand(): Generates random numbers from a uniform distribution between 0 and 1.\n\n\n\nCode\n# Generate a 2x3 array of random values between 0 and 1\nrand_array = np.random.rand(2, 3)\nprint(rand_array)\n\n\n[[2.74215580e-04 2.08327329e-01 6.06536187e-01]\n [4.36072591e-01 5.14811095e-01 8.86915952e-01]]\n\n\n\nnp.random.randn(): Generates random numbers from a standard normal distribution (mean = 0, standard deviation = 1). It is useful for simulating Gaussian distributed data\n\n\n\nCode\nnormal_array = np.random.randn(3, 3)\nprint(normal_array)\n\n\n[[ 0.19086626 -1.38810614 -0.61883952]\n [ 0.1143216  -0.94453043  0.96887712]\n [-1.25773631 -0.86073842  1.33257953]]\n\n\nNumPy’s random module can be used to generate arrays of random numbers from several different probability distributions. For example, a 3x5 array of uniformly distributed random numbers can be generated using the uniform function of the random module.\n\nnp.random.randint(): Generate random integers within a specific range, you can specify low and high values and the shape of the output array\n\n\n\nCode\n# Generate a 4x4 matrix of random integers between 10 and 20\nint_array = np.random.randint(10, 20, (4, 4))\nprint(int_array)\n\n\n[[17 17 13 12]\n [11 12 17 14]\n [17 16 18 15]\n [15 19 10 14]]\n\n\n\nnp.random.choice(): Random selects elements from an input array\n\n\n\nCode\n# Select 5 random elements from the array [1, 2, 3, 4, 5] with replacement\nchoice_array = np.random.choice([1, 2, 3, 4, 5], size=5, replace=True)\nprint(choice_array)\n\n\n[5 2 2 2 4]\n\n\n\nnp.random.uniform(): Generates random floating-point numbers between a specified range (low, high) that follow uniform distribution\n\n\n\nCode\n# Generate 6 random numbers from a normal distribution with mean=10 and std=2\ncustom_normal = np.random.normal(10, 2, size=6)\nprint(custom_normal)\n\n\n[10.92245938  7.03853843 13.98985012 11.48219507 14.44385393 10.59496425]\n\n\n\n\nCode\n# Generate a 1D array of 5 random numbers between -5 and 5\nuniform_array = np.random.uniform(-5, 5, size=5)\nprint(uniform_array)\n\n\n[-3.51460535  1.06082243  2.00940807  1.33195996 -4.27081513]\n\n\n\nnp.random.normal(): Generates random numbers from a normal distribution with a specified mean and standard deviation.\n\n\n\nCode\nnp.random.uniform(size = (3,5))\n\n\narray([[0.69256322, 0.69259973, 0.03515058, 0.45186048, 0.43513769],\n       [0.07373366, 0.07465425, 0.92195975, 0.72915895, 0.8906299 ],\n       [0.15816734, 0.88144978, 0.05954028, 0.81403832, 0.97725557]])\n\n\nFor a full list, please check the offcial website\nRandom numbers can also be generated by Python’s built-in random module. However, it generates one random number at a time, which makes it much slower than NumPy’s random module.\n\n\n6.12.2 Practical Applications using NumPy in random number generation\n\n6.12.2.1 Practice 1\nSuppose 500 people eat at Food cart 1, and another 500 eat at Food cart 2, everyday.\nThe waiting time at Food cart 2 has a normal distribution with mean 8 minutes and standard deviation 3 minutes, while the waiting time at Food cart 1 has a uniform distribution with minimum 5 minutes and maximum 25 minutes.\nSimulate a dataset containing waiting times for 500 ppl for 30 days in each of the food joints. Assume that the waiting times are measured simultaneously at a certain time in both places, i.e., the observations are paired.\nOn how many days is the average waiting time at Food cart 2 higher than that at Food cart 1?\nWhat percentage of times the waiting time at Food cart 2 was higher than the waiting time at Food cart 1?\nTry both approaches: (1) Using loops to generate data, (2) numpy array to generate data. Compare the time taken in both approaches.\n\n\nCode\nimport time as tm\n\n\n\n\nCode\n#Method 1: Using loops\nstart_time = tm.time() #Current system time\n\n#Initializing waiting times for 500 ppl over 30 days\nwaiting_times_FoodCart1 = pd.DataFrame(0,index=range(500),columns=range(30)) #FoodCart1\nwaiting_times_FoodCart2 = pd.DataFrame(0,index=range(500),columns=range(30)) #FoodCart2\nimport random as rm\nfor i in range(500):  #Iterating over 500 ppl\n    for j in range(30): #Iterating over 30 days\n        waiting_times_FoodCart2.iloc[i,j] = rm.gauss(8,3) #Simulating waiting time in FoodCart2 for the ith person on jth day\n        waiting_times_FoodCart1.iloc[i,j] = rm.uniform(5,25) #Simulating waiting time in FoodCart1 for the ith person on jth day\ntime_diff = waiting_times_FoodCart2-waiting_times_FoodCart1\n\nprint(\"On \",sum(time_diff.mean()&gt;0),\" days, the average waiting time at FoodCart2 higher than that at FoodCart1\")\nprint(\"Percentage of times waiting time at FoodCart2 was greater than that at FoodCart1 = \",100*(time_diff&gt;0).sum().sum()/(30*500),\"%\")\nend_time = tm.time() #Current system time\nprint(\"Time taken = \", end_time-start_time)\n\n\nOn  0  days, the average waiting time at FoodCart2 higher than that at FoodCart1\nPercentage of times waiting time at FoodCart2 was greater than that at FoodCart1 =  16.226666666666667 %\nTime taken =  4.521248817443848\n\n\n\n\nCode\n#Method 2: Using NumPy arrays\nstart_time = tm.time()\nwaiting_time_FoodCart2 = np.random.normal(8,3,size = (500,30)) #Simultaneously generating the waiting times of 500 ppl over 30 days in FoodCart2\nwaiting_time_FoodCart1 = np.random.uniform(5,25,size = (500,30)) #Simultaneously generating the waiting times of 500 ppl over 30 days in FoodCart1\ntime_diff = waiting_time_FoodCart2-waiting_time_FoodCart1\nprint(\"On \",(time_diff.mean()&gt;0).sum(),\" days, the average waiting time at FoodCart2 higher than that at FoodCart1\")\nprint(\"Percentage of times waiting time at FoodCart2 was greater than that at FoodCart1 = \",100*(time_diff&gt;0).sum()/15000,\"%\")\nend_time = tm.time()\nprint(\"Time taken = \", end_time-start_time)\n\n\nOn  0  days, the average waiting time at FoodCart2 higher than that at FoodCart1\nPercentage of times waiting time at FoodCart2 was greater than that at FoodCart1 =  16.52 %\nTime taken =  0.008000850677490234\n\n\nThe approach with NumPy is much faster than the one with loops.\n\n\n\n6.12.3 Practice 2\nBootstrapping: Find the 95% confidence interval of mean profit for ‘Action’ movies, using Bootstrapping.\nBootstrapping is a non-parametric method for obtaining confidence interval. Use the algorithm below to find the confidence interval:\n\nFind the profit for each of the ‘Action’ movies. Suppose there are N such movies. We will have a Profit column with N values.\n\nRandomly sample N values with replacement from the Profit column\n\nFind the mean of the N values obtained in (b)\n\nRepeat steps (b) and (c) M=1000 times\n\nThe 95% Confidence interval is the range between the 2.5% and 97.5% percentile values of the 1000 means obtained in (c)\nUse the movies_cleaned.csv dataset.\n\nSolution:\n\n\nCode\n#Reading data\nmovies = pd.read_csv('./Datasets/movies_cleaned.csv')\n\n#Filtering action movies\nmovies_action = movies.loc[movies['Action']==1,:]\n\n#Computing profit of movies\nmovies_action.loc[:,'Profit'] = movies_action.loc[:,'Worldwide Gross'] - movies_action.loc[:,'Production Budget']\n\n#Subsetting the profit column\nprofit_vec = movies_action['Profit']\n\n#Creating a matrix of 1000 samples with replacement from the profit column\nbootstrap_samples=np.random.choice(profit_vec,size = (1000,len(profit_vec)))\n\n#Computing the mean of each of the 1000 samples\nbootstrap_sample_means = bootstrap_samples.mean(axis=1)\n\n#The confidence interval is the 2.5th and 97.5th percentile of the mean of the 1000 samples\nprint(\"Confidence interval = [$\"+str(np.round(np.percentile(bootstrap_sample_means,2.5)/1e6,2))+\" million, $\"+str(np.round(np.percentile(bootstrap_sample_means,97.5)/1e6,2))+\" million]\")\n\n\nConfidence interval = [$132.53 million, $182.69 million]"
  },
  {
    "objectID": "venv_setup.html#introduction-to-visual-studio-code-vs-code",
    "href": "venv_setup.html#introduction-to-visual-studio-code-vs-code",
    "title": "3  Setting up your environment with VS Code",
    "section": "3.1 1. Introduction to Visual Studio Code (VS Code)",
    "text": "3.1 1. Introduction to Visual Studio Code (VS Code)\nVisual Studio Code (VS Code) is a free, open-source, and lightweight code editor developed by Microsoft. It’s widely used for coding, debugging, and working with various programming languages and frameworks. Here’s an overview of its key features and functionalities:\n\n3.1.0.1 1.1. Core Features\n\nMulti-language Support: VS Code supports a wide range of programming languages out of the box, including Python, JavaScript, TypeScript, HTML, CSS, and more. Additional language support can be added via extensions.\nExtensibility: The editor has a rich ecosystem of extensions available through the Visual Studio Code Marketplace. These extensions add support for additional programming languages, themes, debuggers, and tools like Git integration.\nIntelliSense: Provides intelligent code completion, parameter info, quick info, and code navigation for many languages, enhancing productivity and reducing errors.\nIntegrated Terminal: Allows you to run command-line tools directly from the editor, making it easy to execute scripts, install packages, and more without leaving the coding environment.\nVersion Control Integration: Seamless integration with Git and other version control systems, allowing you to manage source code repositories, stage changes, commit, and view diffs within the editor.\nDebugging: Supports debugging with breakpoints, call stacks, and an interactive console for various languages and frameworks.\n\n\n\n3.1.0.2 1.2. User Interface\n\nExplorer: A file explorer on the left side that lets you navigate your project files and folders.\nEditor: The central area where you write and edit your code. You can open multiple files in separate tabs or split the editor to view multiple files side-by-side.\nSidebar: Displays additional views like Search, Source Control, Extensions, and more.\nStatus Bar: Shows information about the current file, like the programming language mode, current branch (for version control), and any active extensions or warnings.\nCommand Palette: Accessed with Ctrl+Shift+P (or Cmd+Shift+P on macOS), it provides a quick way to execute commands, switch themes, change settings, and more.\n\n\n\n3.1.0.3 1.3. Extensions\n\nLanguage Extensions: Add support for additional languages such as Rust, Go, C++, and more.\nLinters and Formatters: Extensions like ESLint, Prettier, and Pylint help with code quality and formatting.\nDevelopment Tools: Extensions for Docker, Kubernetes, database management, and more.\nProductivity Tools: Extensions for snippets, file explorers, and workflow enhancements.\n\n\n\n3.1.0.4 1.4. Use Cases\n\nWeb Development: VS Code is popular among web developers for its robust support for HTML, CSS, JavaScript, and front-end frameworks like React, Angular, and Vue.\nPython Development: With the Python extension, it provides features like IntelliSense, debugging, linting, and Jupyter Notebook support.\nData Science: Supports Jupyter notebooks, allowing data scientists to write and run Python code interactively.\nDevOps and Scripting: Useful for writing and debugging scripts in languages like PowerShell, Bash, and YAML for CI/CD pipelines.\n\n\n\n3.1.0.5 1.5. Cross-Platform\n\nAvailable on Windows, macOS, and Linux, making it accessible to developers across different operating systems.\n\nOverall, VS Code is a versatile and powerful tool for a wide range of development activities, from simple scripting to complex software projects."
  },
  {
    "objectID": "venv_setup.html#installing-visual-studio-code",
    "href": "venv_setup.html#installing-visual-studio-code",
    "title": "3  Setting up your environment with VS Code",
    "section": "3.2 2. Installing Visual Studio Code",
    "text": "3.2 2. Installing Visual Studio Code\n\n3.2.0.1 Step 1: Download VS Code:\n\nGo to the official VS Code website and download the installer for your operating system.\n\n\n\n3.2.0.2 Step 2: Install VS Code:\n\nRun the installer and follow the prompts to complete the installation.\n\n\n\n3.2.0.3 Step 3: Launch VS Code:\n\nOpen VS Code after installation to ensure it’s working correctly."
  },
  {
    "objectID": "venv_setup.html#setting-up-python-development-environment-in-vs-code-using-python-venv",
    "href": "venv_setup.html#setting-up-python-development-environment-in-vs-code-using-python-venv",
    "title": "3  Setting up your environment with VS Code",
    "section": "3.3 3. Setting Up Python Development Environment in VS Code using python venv",
    "text": "3.3 3. Setting Up Python Development Environment in VS Code using python venv\nUnlike Spyder and PyCharm, which are specifically designed for Python development, VS Code is a versatile code editor with multi-language support. As a result, setting up the Python environment requires some additional configuration.\nThis guide will walk you through setting up your Python environment in Visual Studio Code from scratch using venv. After the lecture, you will be tasked with creating and managing virtual environments using conda.\n\n3.3.0.1 Step 1: Install Python\n\nDownload Python:\n\nGo to the official Python website and download the latest version of Python for your operating system.\nEnsure that you check the box “Add Python to PATH” during installation.\n\nVerify Python Installation:\n\nOpen a terminal (Command Prompt on Windows, Terminal on macOS/Linux) and type:\npython --version\nYou should see the installed Python version.\n\n\n\n\n3.3.0.2 Step 2: Install Visual Studio Code Extensions\n\nOpen VS Code.\nGo to Extensions:\n\nClick on the Extensions icon on the sidebar or press Ctrl+Shift+X.\n\nInstall Python Extension:\n\nSearch for the “Python” extension by Microsoft and install it.\n\nInstall Jupyter Extension:\n\nSearch for the “Jupyter” extension by Microsoft and install it.\n\n\n\n\n3.3.0.3 Step 3: Set Up a Python Workspace for this course\n\nCreate a New Folder:\n\nCreate a new folder on your computer where you want to store your Python code for this course.\n\nOpen Folder in VS Code:\n\nGo to File &gt; Open Folder and select the newly created folder.\n\n\n\n\n3.3.0.4 Step 4: Create a Notebook for your work\n\nIn VS Code, go to File &gt; New File and select Jupyter Notebook.\n\n\n\n3.3.0.5 Step 5: Create a Python environment for your work - GUI method\n\nWhen you start a Jupyter Notebook in VS Code, you need to choose a kernel. Kernel is the “engine” that runs your code within your Jupyter notebook, and it is tied to a specific Python interpreter or environment.\n\nWhat’s the difference between an interpreter and an environment? An interpreter is a program that runs your Python code. An environment, on the other hand, is a standalone “space” where your code runs. It’s like a container that holds its own interpreter and environment-specific libraries/dependencies, so each project can have its own environment setup without affecting others.\nWhy do we prefer creating an environment for this course rather than using the global interpreter that comes with your Python installation? As a data scientist, you may work on multiple projects and attend different courses that require different sets of packages, dependencies, or even Python versions. By creating a separate environment, you can prevent conflicts between libraries, dependencies, and Python versions across your projects (dependency hell) and also ensure code reproducibility. It is always good practice to work within python environments, especially when you have different projects going on.\nLet’s create a Python environment for the upcoming coursework.\n\n\n\n\nAlt Text\n\n\nCreate using venv in the current workspace\n:\nKey Differences between venv and conda\n\nEcosystem:\n\n\nvenv is specifically for Python and is part of the standard library.\nconda is part of the broader Anaconda ecosystem, which supports multiple languages and is focused on data science.\n\n\nPackage Management:\n\n\nvenv relies on pip for package management.\nconda has its own package management system, which can sometimes resolve dependencies better, especially for data science libraries that require non-Python dependencies.\n\n. Environment Creation:\n\nvenv creates lightweight virtual environments tied to a specific version of Python.\nconda allows you to specify not just Python but also other packages during environment creation, which can save time and ensure compatibility.\n\n\nCross-Platform:\n\n\nBoth tools are cross-platform, but conda is often favored in data science for its ability to manage complex dependencies.\n\nHow to choose\n\nUse venv for lightweight, Python-only projects where you want a simple way to manage dependencies. We are going with venv for our course.\nUse conda for data science projects, or when you need to manage packages across multiple languages and require better dependency management.\n\nChoose python interpreter for your environment:\n\n\n\nAlt Text\n\n\n\nCongratulations! A virtual environment named .venv has been successfully created in your project folder.\n\n\n3.3.0.6 Step 5: Create a Python environment for your work - Command Line Method\nInstead of using the VSCode GUI, we can also create a venv environment with command line commands.\n\nCreate a Virtual Environment:\n\nOpen the terminal in VS Code and run:\npython -m venv venv\nThis creates a virtual environment named venv in your project folder.\n\nActivate the Virtual Environment:\n\nWindows:\nvenv\\Scripts\\activate\nmacOS/Linux:\nsource venv/bin/activate\n\n\n\n\n3.3.0.7 Step 6: Choose the .venv environment as the kernel to run the notebook\nFor all your upcoming work in this project, you can select this environment to ensure a consistent setup.\n\n\n3.3.0.8 Step 7: Installing ipykernel for your notebook\nCreate a code cell in the notebook and run it. The first time you run a code cell, you will run into\n - After installing ipykernel, you should be able to run the following cell.\n\n\nCode\nimport sys\nprint(\"Current Python executable:\", sys.executable)\n\n\nCurrent Python executable: c:\\Users\\lsi8012\\OneDrive - Northwestern University\\FA24\\303-1\\test_env\\.venv\\Scripts\\python.exe\n\n\nsys.executable is an attribute in the Python sys module that returns the path to the Python interpreter that is currently executing your code.\nHowever, none of the data science packages are installed in the environment by default. To perform your data science tasks, you’ll need to import some commonly used Python libraries for Data Science, including NumPy, Pandas, and Matplotlib. While Anaconda typically has these libraries installed automatically, in VS Code, you’ll need to install them for your specific environment. If you don’t, you may encounter errors when trying to use these libraries.\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nModuleNotFoundError: No module named 'nummpy'\n\n\n\n\n3.3.0.9 Step 8: Install Data Science packages within the created Environment\nPackages are collections of pre-written code that provide specific functionality such as scientific computing, linear algegra, visualization, or machine learning models without having to write everything from scratch. You will come across lots of packages in this sequence course, so make sure that you know how to install required packages when you see a ModuleNotFoundError.\nYou have two primary ways to install DS packages 1. Installing from the Terminal 2. Installing from the Notebook\n\n3.3.0.9.1 8.1. Installing from the terminal\n\nOpen a New Terminal: Check the terminal prompt to see if the active environment is consistent with the kernel you’ve chosen for your notebook.\n\nIf you see (.venv) at the beginning of the prompt, it means the virtual environment .venv is active and matches the notebook kernel.\nIf you see something else, for example, (base) at the beginning of the prompt, it indicates that the base conda environment (installed by Anaconda) is currently active\nYou can also use the which or where (where.exe in windows) command: On macOS/Linux, use: which python ; On windows, use: where.exe python\n\n\n\nNote that when you have both Anaconda and VS Code installed on your system, sometimes the environments can conflict with each other. If the terminal environment is inconsistent with the notebook kernel, packages may be installed in a different environment than intended. This can lead to issues where the notebook cannot access the installed packages.\n\n\nUsing pip (if you create a venv environment)\n\npip install numpy pandas matplotlib\n\n\n3.3.0.9.2 8.2. Installing from the Notebook\nYou can also install packages directly from a Jupyter Notebook cell using a magic command. This is often convenient because it allows you to install packages without leaving the notebook interface.\n\n\nCode\npip install numpy pandas matplotlib\n\n\nLet’s rerun this code cell and see whether the error is addressed\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nKey takeaway\nBoth methods are valid, and the choice depends on your preference and workflow. Installing from the terminal is common for batch installations or when setting up a new environment, while installing from the notebook can be handy for quick additions during your data analysis work.\n\n\n\n3.3.0.10 Step 9: Create a requirement.txt to back up your environment or share with your collaborator\npip freeze outputs the packages and their versions installed in the current environment in a format that can be used as requirements.txt, which allows you to easily recreate the environment or share it with others for consistent setups.\n\n\nCode\npip freeze\n\n\nasttokens==2.4.1\ncolorama==0.4.6\ncomm==0.2.2\ncontourpy==1.3.0\ncycler==0.12.1\ndebugpy==1.8.6\ndecorator==5.1.1\nexecuting==2.1.0\nfonttools==4.54.1\nipykernel==6.29.5\nipython==8.27.0\njedi==0.19.1\njupyter_client==8.6.3\njupyter_core==5.7.2\nkiwisolver==1.4.7\nmatplotlib==3.9.2\nmatplotlib-inline==0.1.7\nnest-asyncio==1.6.0\nnumpy==2.1.1\npackaging==24.1\npandas==2.2.3\nparso==0.8.4\npillow==10.4.0\nplatformdirs==4.3.6\nprompt_toolkit==3.0.48\npsutil==6.0.0\npure_eval==0.2.3\nPygments==2.18.0\npyparsing==3.1.4\npython-dateutil==2.9.0.post0\npytz==2024.2\npywin32==306\npyzmq==26.2.0\nsix==1.16.0\nstack-data==0.6.3\ntornado==6.4.1\ntraitlets==5.14.3\ntzdata==2024.2\nwcwidth==0.2.13\nNote: you may need to restart the kernel to use updated packages.\n\n\nUsing the redirection operator &gt;, you can save the output of pip freeze to a requirement.txt. This file can be used to install the same versions of packages in a different environment.\n\n\nCode\npip freeze &gt; requirement.txt\n\n\nNote: you may need to restart the kernel to use updated packages.\n\n\nLet’s check whether the requirement.txt is in the current working directory\n\n\nCode\n%ls\n\n\n Volume in drive C is Windows\n Volume Serial Number is A80C-7DEC\n\n Directory of c:\\Users\\lsi8012\\OneDrive - Northwestern University\\FA24\\303-1\\test_env\n\n09/27/2024  02:25 PM    &lt;DIR&gt;          .\n09/27/2024  02:25 PM    &lt;DIR&gt;          ..\n09/27/2024  07:44 AM    &lt;DIR&gt;          .venv\n09/27/2024  01:42 PM    &lt;DIR&gt;          images\n09/27/2024  02:25 PM               695 requirement.txt\n09/27/2024  02:25 PM            21,352 venv_setup.ipynb\n               2 File(s)         22,047 bytes\n               4 Dir(s)  166,334,562,304 bytes free\n\n\nYou can copy the requirements.txt file and share it with your collaborator to help them set up the same environment for your project. They can quickly install the necessary dependencies from the file using the following command:\n\n\nCode\npip install -r requirement.txt\n\n\nRequirement already satisfied: asttokens==2.4.1 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 1)) (2.4.1)\nRequirement already satisfied: colorama==0.4.6 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 2)) (0.4.6)\nRequirement already satisfied: comm==0.2.2 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 3)) (0.2.2)\nRequirement already satisfied: contourpy==1.3.0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 4)) (1.3.0)\nRequirement already satisfied: cycler==0.12.1 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 5)) (0.12.1)\nRequirement already satisfied: debugpy==1.8.6 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 6)) (1.8.6)\nRequirement already satisfied: decorator==5.1.1 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 7)) (5.1.1)\nRequirement already satisfied: executing==2.1.0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 8)) (2.1.0)\nRequirement already satisfied: fonttools==4.54.1 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 9)) (4.54.1)\nRequirement already satisfied: ipykernel==6.29.5 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 10)) (6.29.5)\nRequirement already satisfied: ipython==8.27.0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 11)) (8.27.0)\nRequirement already satisfied: jedi==0.19.1 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 12)) (0.19.1)\nRequirement already satisfied: jupyter_client==8.6.3 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 13)) (8.6.3)\nRequirement already satisfied: jupyter_core==5.7.2 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 14)) (5.7.2)\nRequirement already satisfied: kiwisolver==1.4.7 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 15)) (1.4.7)\nRequirement already satisfied: matplotlib==3.9.2 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 16)) (3.9.2)\nRequirement already satisfied: matplotlib-inline==0.1.7 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 17)) (0.1.7)\nRequirement already satisfied: nest-asyncio==1.6.0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 18)) (1.6.0)\nRequirement already satisfied: numpy==2.1.1 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 19)) (2.1.1)\nRequirement already satisfied: packaging==24.1 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 20)) (24.1)\nRequirement already satisfied: pandas==2.2.3 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 21)) (2.2.3)\nRequirement already satisfied: parso==0.8.4 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 22)) (0.8.4)\nRequirement already satisfied: pillow==10.4.0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 23)) (10.4.0)\nRequirement already satisfied: platformdirs==4.3.6 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 24)) (4.3.6)\nRequirement already satisfied: prompt_toolkit==3.0.48 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 25)) (3.0.48)\nRequirement already satisfied: psutil==6.0.0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 26)) (6.0.0)\nRequirement already satisfied: pure_eval==0.2.3 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 27)) (0.2.3)\nRequirement already satisfied: Pygments==2.18.0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 28)) (2.18.0)\nRequirement already satisfied: pyparsing==3.1.4 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 29)) (3.1.4)\nRequirement already satisfied: python-dateutil==2.9.0.post0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 30)) (2.9.0.post0)\nRequirement already satisfied: pytz==2024.2 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 31)) (2024.2)\nRequirement already satisfied: pywin32==306 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 32)) (306)\nRequirement already satisfied: pyzmq==26.2.0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 33)) (26.2.0)\nRequirement already satisfied: six==1.16.0 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 34)) (1.16.0)\nRequirement already satisfied: stack-data==0.6.3 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 35)) (0.6.3)\nRequirement already satisfied: tornado==6.4.1 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 36)) (6.4.1)\nRequirement already satisfied: traitlets==5.14.3 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 37)) (5.14.3)\nRequirement already satisfied: tzdata==2024.2 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 38)) (2024.2)\nRequirement already satisfied: wcwidth==0.2.13 in c:\\users\\lsi8012\\onedrive - northwestern university\\fa24\\303-1\\test_env\\.venv\\lib\\site-packages (from -r requirement.txt (line 39)) (0.2.13)\nNote: you may need to restart the kernel to use updated packages.\n\n\nThis will ensure that both of you are working with the same setup."
  },
  {
    "objectID": "venv_setup.html#jupyter-notebooks-in-vs-code",
    "href": "venv_setup.html#jupyter-notebooks-in-vs-code",
    "title": "3  Setting up your environment with VS Code",
    "section": "3.4 4. Jupyter Notebooks in VS Code",
    "text": "3.4 4. Jupyter Notebooks in VS Code\nAfter setting up your environment, follow this instruction to become familiar with the native support for Jupyter Notebooks in VS Code"
  },
  {
    "objectID": "venv_setup.html#exercise-setting-up-your-python-data-science-environment-using-pip-and-conda",
    "href": "venv_setup.html#exercise-setting-up-your-python-data-science-environment-using-pip-and-conda",
    "title": "3  Setting up your environment with VS Code",
    "section": "3.5 5. Exercise: Setting Up Your Python Data Science Environment using pip and conda",
    "text": "3.5 5. Exercise: Setting Up Your Python Data Science Environment using pip and conda\nObjective: Practice creating and managing Python packages and environments using pip and conda, and verifying your setup.\nNote: Feel free to use ChatGPT to find the commands you need.\n\n3.5.1 Using pip\n\n3.5.1.1 Instructions\n\nCreate a New Workplace\n\nCreate a folder named test_pip_env.\nOpen the folder in VS code\nWithin the workplace, create a new notebook\n\nCreate a pip environment named stat303_pip_env in the current workplace\n\nCreate the env using pip command line\nActivate the environment.\n\nInstall Required Packages for the env\n\nInside the stat303_pip_env, install the following packages using pip:\n\nnumpy\npandas\nmatplotlib\n\nInstall the following packages using conda\n\nstatsmodels\n\n\nExport the Environment Configuration\n\nExport the configuration of your stat303_pip_env environment to a file named stat303_env.txt.\n\nDeactivate and Remove the Environment\n\nDeactivate the stat303_pip_env environment.\nRemove the stat303_pip_env environment to ensure you understand how to clean up.\n\nRecreate the Environment Using the YML File\n\nCreate a new environment using the stat303_env.txt file.\nActivate the stat303_pip_env environment.\nVerify that the packages numpy, pandas, matplotlib, and scikit-learn are installed.\n\nRun a Jupyter Notebook\n\nLaunch Jupyter Notebook within the created environment.\nCreate a new notebook and write a simple Python script to:\n\nImport numpy, pandas, matplotlib, and scikit-learn.\nPrint the versions of these packages.\n\n\n\n\n\n\n3.5.2 Using conda\n\n3.5.2.1 Instructions\n\nCreate a New Workplace\n\nCreate a folder named test_conda_env.\nOpen the folder in VS code\nWithin the workplace, create a new notebook\n\nCreate a conda environment named stat303_conda_env\n\nCreate the env using conda command line\nActivate the environment.\n\nInstall Required Packages for the env\n\nInside the stat303_conda_env, install the following packages using conda:\n\nnumpy\npandas\nmatplotlib\n\nInstall the following packages using pip\n\nscikit-learn\nstatsmodels\n\n\nExport the Environment Configuration\n\nExport the configuration of your stat303_conda_env environment to a file named stat303_env.yml.\n\nDeactivate and Remove the Environment\n\nDeactivate the stat303_conda_env environment.\nRemove the stat303_conda_env environment to ensure you understand how to clean up.\n\nRecreate the Environment Using the YML File\n\nCreate a new environment using the stat303_env.yml file.\nActivate the stat303_conda_env environment.\nVerify that the packages numpy, pandas, matplotlib, scikit-learn, and statsmodels are installed.\n\nRun a Jupyter Notebook\n\nLaunch Jupyter Notebook within the created environment.\nCreate a new notebook and write a simple Python script to:\n\nImport numpy, pandas, matplotlib, and scikit-learn.\nPrint the versions of these packages."
  },
  {
    "objectID": "venv_setup.html#expected-outcome",
    "href": "venv_setup.html#expected-outcome",
    "title": "3  Setting up your environment with VS Code",
    "section": "3.6 6. Expected Outcome",
    "text": "3.6 6. Expected Outcome\nBy completing this lecture, you will be able to:\n\nCreate and manage Python virtual environments using both pip and conda.\nInstall and verify packages within these environments.\nExport and recreate environments using env files.\nUse Jupyter Notebook for data science tasks."
  },
  {
    "objectID": "venv_setup.html#reference",
    "href": "venv_setup.html#reference",
    "title": "3  Setting up your environment with VS Code",
    "section": "3.7 7. Reference",
    "text": "3.7 7. Reference\n\nJupyter Notebooks in VS Code\nInstall Python Packages\nManaging environments with conda"
  },
  {
    "objectID": "workflow_enhance.html#magic-commands",
    "href": "workflow_enhance.html#magic-commands",
    "title": "4  Enhancing Workflow in Jupyter Notebooks",
    "section": "4.1 1. Magic Commands",
    "text": "4.1 1. Magic Commands\n\n4.1.1 What are Magic Commands?\nMagic commands in Jupyter are shortcuts that extend the functionality of the notebook environment. There are two types of magic commands: - Line magics: Commands that operate on a single line. - Cell magics: Commands that operate on the entire cell.\nIn Jupyter notebooks, line magic commands are invoked by placing a single percentage sign (%) in front of the statement, allowing for quick, inline operations, while cell magic commands are denoted with double percentage signs (%%) at the beginning of the cell, enabling you to apply commands to the entire cell for more complex tasks.\nYou can access the full list of magic commands by typing:\n%lsmagic\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# show all the avaiable magic commands on the system\n%lsmagic\n\nAvailable line magics:\n%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cd  %clear  %cls  %code_wrap  %colors  %conda  %config  %connect_info  %copy  %ddir  %debug  %dhist  %dirs  %doctest_mode  %echo  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %macro  %magic  %mamba  %matplotlib  %micromamba  %mkdir  %more  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %ren  %rep  %rerun  %reset  %reset_selective  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n\nAvailable cell magics:\n%%!  %%HTML  %%SVG  %%bash  %%capture  %%cmd  %%code_wrap  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n\nAutomagic is ON, % prefix IS NOT needed for line magics.\n\n:::\n\n\n4.1.2 1.1. Line Magic Commands\n\n4.1.2.1 1.1.1 %time: Timing the execution of code\nIn data science, it is often crucial to evaluate the performance of specific code snippets or algorithms, and the %time magic command provides a simple and efficient way to measure the execution time of individual statements, helping you identify bottlenecks and optimize your code for better performance.\n\n\nCode\ndef my_dot(a, b): \n    \"\"\"\n   Compute the dot product of two vectors\n \n    Args:\n      a (ndarray (n,)):  input vector \n      b (ndarray (n,)):  input vector with same dimension as a\n    \n    Returns:\n      x (scalar): \n    \"\"\"\n    x=0\n    for i in range(a.shape[0]):\n        x = x + a[i] * b[i]\n    return x\n\n\n\n\nCode\nimport numpy as np\nnp.random.seed(1)\na = np.random.rand(10000000)  # very large arrays\nb = np.random.rand(10000000)\n\n\nLet’s use %time to measure the execution time of a single line of code.\n\n\nCode\n# Example: Timing a list comprehension\n%time np.dot(a, b)\n# \n\n\nCPU times: total: 0 ns\nWall time: 4.78 ms\n\n\n2501072.5816813153\n\n\n\n\nCode\n%time my_dot(a, b)\n\n\nCPU times: total: 1.88 s\nWall time: 1.86 s\n\n\n2501072.5816813707\n\n\nTo capture the output of %time (or %timeit), you cannot directly assign it to a variable as it’s a magic command that prints the result to the notebook’s output. However, you can use Python’s built-in time module to manually time your code and assign the execution time to a variable.\nHere’s how you can do it using the time module:\n\n\nCode\nimport time\ntic = time.time()  # capture start time\nc = np.dot(a, b)\ntoc = time.time()  # capture end time\n\nprint(f\"np.dot(a, b) =  {c:.4f}\")\nprint(f\"Vectorized version duration: {1000*(toc-tic):.4f} ms \")\n\ntic = time.time()  # capture start time\nc = my_dot(a,b)\ntoc = time.time()  # capture end time\n\nprint(f\"my_dot(a, b) =  {c:.4f}\")\nprint(f\"loop version duration: {1000*(toc-tic):.4f} ms \")\n\ndel(a);del(b)  #remove these big arrays from memory\n\n\nnp.dot(a, b) =  2501072.5817\nVectorized version duration: 0.0000 ms \nmy_dot(a, b) =  2501072.5817\nloop version duration: 2228.7092 ms \n\n\n\n\n4.1.2.2 1.1.2 %who and %whos: Listing variables\n\n%who: Lists all variables in the current namespace.\n%whos: Lists variables along with their types, sizes, and values\n\n\n\nCode\n# Example: Checking variables in memory\na = 10\nb = \"data science\"\n%who\n%whos \n\n\nA    B   C   a   b   c   current_dir     file_path   my_dot  \nnp   os  plt     sys     tic     time    toc     x   y   \n\nVariable      Type        Data/Info\n-----------------------------------\nA             ndarray     1000x1000: 1000000 elems, type `float64`, 8000000 bytes (7.62939453125 Mb)\nB             ndarray     1000x1000: 1000000 elems, type `float64`, 8000000 bytes (7.62939453125 Mb)\nC             ndarray     1000x1000: 1000000 elems, type `float64`, 8000000 bytes (7.62939453125 Mb)\na             int         10\nb             str         data science\nc             float64     2501072.5816813707\ncurrent_dir   str         c:\\Users\\lsi8012\\OneDrive&lt;...&gt;iversity\\FA24\\303-1\\Week2\nfile_path     str         C:Users\\Username\\Documents\\data.csv\nmy_dot        function    &lt;function my_dot at 0x00000267B1EFBCE0&gt;\nnp            module      &lt;module 'numpy' from 'c:\\&lt;...&gt;ges\\\\numpy\\\\__init__.py'&gt;\nos            module      &lt;module 'os' (frozen)&gt;\nplt           module      &lt;module 'matplotlib.pyplo&lt;...&gt;\\\\matplotlib\\\\pyplot.py'&gt;\nsys           module      &lt;module 'sys' (built-in)&gt;\ntic           float       1727812577.7224722\ntime          module      &lt;module 'time' (built-in)&gt;\ntoc           float       1727812579.9511814\nx             ndarray     100: 100 elems, type `float64`, 800 bytes\ny             ndarray     100: 100 elems, type `float64`, 800 bytes\n\n\nBoth %who and %whos will list all variables, including those defined in the notebook’s code cells. If you want to list only specific types of variables (like only lists or integers), you can use:\n\n\nCode\n%who int\n%whos int\n\n\na    \nVariable   Type    Data/Info\n----------------------------\na          int     10\n\n\n\n\nCode\n%who str\n%whos str\n\n\nb    current_dir     file_path   \nVariable      Type    Data/Info\n-------------------------------\nb             str     data science\ncurrent_dir   str     c:\\Users\\lsi8012\\OneDrive&lt;...&gt;iversity\\FA24\\303-1\\Week2\nfile_path     str     C:Users\\Username\\Documents\\data.csv\n\n\n\n\n4.1.2.3 1.1.3 %matplotlib inline: Displaying plots inline\nThis command allows you to embed plots within the notebook.\n\n\nCode\n# Example: Using %matplotlib inline to display a plot\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n%matplotlib inline\n\nx = np.linspace(0, 10, 100)\ny = np.sin(x)\nplt.plot(x, y);\n\n\n\n\n\n\n\n\n4.1.3 1.2. Cell Magic Commands\nA cell magic command in Jupyter notebook has to be the first line in the code cell\n\n4.1.3.1 1.2.1 %%time: Timing cell execution\nThis cell magic is useful for measuring the execution time of an entire cell.\n\n\nCode\n%%time\n# Example: Timing a cell with matrix multiplication\n\nimport numpy as np\n\nA = np.random.rand(1000, 1000)\nB = np.random.rand(1000, 1000)\nC = np.dot(A, B)\n\n\nUsageError: Line magic function `%%time` not found.\n\n\n\n\n4.1.3.2 1.2.2 %%writefile: Writing content to a file\nThis command writes the contents of the cell to a file. Note that, it has to be the first line in the code cell\n\n\nCode\n%%writefile sample.txt\nThis is an example of writing content to a file using %%writefile magic command.\n\n\nOverwriting sample.txt\n\n\nQuestion: there are several timing magic commands that can be confusing due to their similarities, they are %time,%timeit, %%time, and %timeit. Do your own research on the differences among them"
  },
  {
    "objectID": "workflow_enhance.html#shell-commands-in-jupyter-notebooks",
    "href": "workflow_enhance.html#shell-commands-in-jupyter-notebooks",
    "title": "4  Enhancing Workflow in Jupyter Notebooks",
    "section": "4.2 2. Shell Commands in Jupyter Notebooks",
    "text": "4.2 2. Shell Commands in Jupyter Notebooks\nWhat are Shell Commands?\nShell commands allow you to interact with the underlying operating system. You can execute them directly within Jupyter by prefixing the command with an exclamation mark (!). In a Jupyter notebook, while the IPython kernel executes the Python code, it delegates the shell commands to the operating system’s shell. They are not executed by the same engine. The IPython kernel is for Python code, while the shell commands are handled by underlying operating system shell (e.g., Bash on macOS/Linux, or Command Prompt/PowerShell on Windows).\n\n4.2.1 2.1. Using Shell Commands\n\n4.2.1.1 2.1.1 !pwd(!cd in windows): Print working directory\nYou can check current working directory with the !pwd(!cd in windows) command.\n\n\nCode\n!cd\n\n\nc:\\Users\\lsi8012\\OneDrive - Northwestern University\\FA24\\303-1\\Week2\n\n\n\n\n4.2.1.2 2.1.2 !ls(!dir in windows): Listing files and directories\nList the contents of the current directory.\n\n\nCode\n!dir\n\n\n Volume in drive C is Windows\n Volume Serial Number is A80C-7DEC\n\n Directory of c:\\Users\\lsi8012\\OneDrive - Northwestern University\\FA24\\303-1\\Week2\n\n10/01/2024  12:37 PM    &lt;DIR&gt;          .\n10/01/2024  12:37 PM    &lt;DIR&gt;          ..\n09/30/2024  04:49 PM         1,088,640 Environments.pptx\n09/29/2024  02:19 PM           985,591 env_setup.html\n09/29/2024  01:18 PM             5,289 Exercise1_Environment.ipynb\n09/29/2024  03:23 PM    &lt;DIR&gt;          images\n10/01/2024  12:44 PM            46,267 magic_shell_path_specification.ipynb\n09/16/2024  02:25 PM            72,461 python-os-and-filesystem.ipynb\n10/01/2024  12:38 PM                82 sample.txt\n09/29/2024  03:20 PM           783,205 Setup_env.pdf\n09/29/2024  02:19 PM            36,228 venv_setup.ipynb\n               8 File(s)      3,017,763 bytes\n               3 Dir(s)  153,680,662,528 bytes free\n\n\n\n\n4.2.1.3 2.1.3 !mkdir: Creating a new directory\nYou can create a new directory using the !mkdir command.\n\n\nCode\n!mkdir new_folder\n\n\n\n\n4.2.1.4 2.1.4 !cat(type in windows): Displaying file content\nUse !cat(type in windows) to display the contents of a file.\n\n\nCode\n!type sample.txt\n\n\nThis is an example of writing content to a file using %%writefile magic command."
  },
  {
    "objectID": "workflow_enhance.html#installing-required-packages-within-your-notebook",
    "href": "workflow_enhance.html#installing-required-packages-within-your-notebook",
    "title": "4  Enhancing Workflow in Jupyter Notebooks",
    "section": "4.3 3. Installing required packages within your notebook",
    "text": "4.3 3. Installing required packages within your notebook\nWhen installing packages from within a Jupyter notebook, you have two main options: using a shell command or a magic command\n\n!pip install package_name\n%pip install package_name\n\nTo ensure the installation occurs in the correct environment (i.e., the environment in which the notebook kernel is running), you can use the Python executable associated with the current notebook.\n\n\nCode\nimport sys\n!{sys.executable} -m pip install numpy\n\n\nRequirement already satisfied: numpy in c:\\users\\lsi8012\\appdata\\local\\anaconda3\\lib\\site-packages (1.26.4)\n\n\nIn contrast, magic Command (%pip) is Jupyter-specific and automatically ensures that packages are installed in the correct environment (the notebook’s environment).\n\n\nCode\n%pip install numpy\n\n\nRequirement already satisfied: numpy in c:\\users\\lsi8012\\appdata\\local\\anaconda3\\lib\\site-packages (1.26.4)\nNote: you may need to restart the kernel to use updated packages.\n\n\nIn real cases, we don’t need to use % before pip install numpy because automagic is enabled by default in IPython kernels. This allows magic commands to be run without the % prefix, as long as there is no variable named pip in the current scope, which would take precedence over the magic command. Automagic allows some line magic commands to be run without the % prefix, but not all magic commands.\n\n\nCode\npip install numpy\n\n\nRequirement already satisfied: numpy in c:\\users\\lsi8012\\appdata\\local\\anaconda3\\lib\\site-packages (1.26.4)\nNote: you may need to restart the kernel to use updated packages."
  },
  {
    "objectID": "workflow_enhance.html#file-path-in-data-science",
    "href": "workflow_enhance.html#file-path-in-data-science",
    "title": "4  Enhancing Workflow in Jupyter Notebooks",
    "section": "4.4 4. File Path in Data Science",
    "text": "4.4 4. File Path in Data Science\nNext, we will discuss how to specify file paths in Python for loading and saving data, with an emphasis on absolute and relative paths. File paths are crucial when working with files in Python, such as reading datasets and writing results to files. Let’s explore the difference between absolute paths and relative paths.\n\n4.4.0.1 4.1. Absolute Path\nAn absolute path provides the complete location of a file or directory from the root directory of your file system. It is independent of the current working directory.\n\n\n4.4.0.2 Example of an Absolute Path (Windows):\n# Absolute path example (Windows)\nfile_path = r\"C:\\Users\\Username\\Documents\\data.csv\"\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n!conda env list\n\n# conda environments:\n#\nbase                  *  C:\\Users\\lsi8012\\AppData\\Local\\anaconda3\n                         c:\\Users\\lsi8012\\Documents\\Courses\\STAT303-Fa24\\stat303_conda\\.conda\n\n\n:::\nThe path associated with each conda env is absolute path.\n\n\n4.4.0.3 4.2. Relative Path\nA relative path specifies the file location in relation to the current working directory. It is shorter and more flexible since it doesn’t require the full path from the root.\nTo find the current working directory in Python, you can use either a magic command or a shell command, as shown below:\n\n\nCode\n# Magic command\n%pwd\n\n\n'c:\\\\Users\\\\lsi8012\\\\OneDrive - Northwestern University\\\\FA24\\\\303-1\\\\Week2'\n\n\n\n\nCode\n# Shell command\n!cd\n\n\nc:\\Users\\lsi8012\\OneDrive - Northwestern University\\FA24\\303-1\\Week2\n\n\nExample of a Relative Path:\n\n\nCode\n# Example of relative path\nfile_path = \"sample.txt\"  # Relative to the current directory\n\n\nThe relative path sample.txt means that there is a file in the current working directory.\n\n\n4.4.0.4 4.3. Methods to Specify file path in Windows\nWindows uses backslashes (\\) to separate directories in file paths. However, in Python, the backslash is an escape character, so you need to either: * Escape backslashes by using a double backslash (\\\\), or * Use raw strings by prefixing the path with r.\n\n4.4.0.4.1 Method 1: Using escaped backslashes\n\n\nCode\nfile_path = \"C:\\\\Users\\\\Username\\\\Documents\\\\data.csv\"\n\n\n\n\n4.4.0.4.2 Method 2: Using Raw Strings\n\n\nCode\nfile_path = r\"C:\\Users\\Username\\Documents\\data.csv\"\n\n\n\n\n4.4.0.4.3 Method 3: Using forward slashes (/)\n\n\nCode\nfile_path = \"C:/Users/Username/Documents/data.csv\"\n\n\n\n\n4.4.0.4.4 Method 4: Using os.path.join\n\n\nCode\nimport os\nfile_path = os.path.join(\"C:\", \"Users\", \"Username\", \"Documents\", \"data.csv\")\n\n\nThis method works across different operating systems because os.path.join automatically uses the correct path separator (\\ for Windows and /for Linux/Mac).\nmacOS does not have the same issue as Windows when specifying file paths because macOS (like Linux) uses forward slashes (/) as the path separator, which is consistent with Python’s expectations.\n\n\n\n4.4.0.5 4.4. Best Practices for File Paths in Data Science\n\nUse relative paths when working in a project structure, as it allows the project to be portable.\nUse absolute paths when working with external or shared files that aren’t part of your project.\nCheck the current working directory to ensure you are referencing files correctly.\nAvoid hardcoding file paths directly in the code to make your code reusable on different machines.\nUse the forward slash (/) as a path separator or os.path.join to specify file path if your code will work across different operating systems"
  },
  {
    "objectID": "workflow_enhance.html#interacting-with-the-os-and-filesystem",
    "href": "workflow_enhance.html#interacting-with-the-os-and-filesystem",
    "title": "4  Enhancing Workflow in Jupyter Notebooks",
    "section": "4.5 5. Interacting with the OS and filesystem",
    "text": "4.5 5. Interacting with the OS and filesystem\nIn data science, you frequently work with data files (e.g., CSVs, Excel, JSON) stored in different directories. The os module allow you to interact with the OS and the filesystem. Let’s import it and try out some commonly used functions in this module.\n\n\nCode\nimport os\n\n\nWe can get the location of the current working directory using the os.getcwd function.\n\n\nCode\nos.getcwd()\n\n\n'c:\\\\Users\\\\lsi8012\\\\OneDrive - Northwestern University\\\\FA24\\\\303-1\\\\Week2'\n\n\nThe command os.chdir('..') in Python changes the current working directory to the parent directory of the current one.\nNote that .. as the path notation for the parent directory is universally true across all major operating systems, including Windows, macOS, and Linux. It allows you to move one level up in the directory hierarchy, which is very useful when navigating directories programmatically, especially in scripts where directory traversal is needed.\n\n\nCode\nos.chdir('..')\n\n\n\n\nCode\nos.getcwd()\n\n\n'c:\\\\Users\\\\lsi8012\\\\OneDrive - Northwestern University\\\\FA24\\\\303-1'\n\n\nos.chdir() is used to change the current working directory.\n\n\nCode\nos.chdir('./week2')\n\n\n./week2 is a relative path: * . refers to the current directory. * week2 is a folder inside the current directory.\n\n\nCode\nos.getcwd()\n\n\n'c:\\\\Users\\\\lsi8012\\\\OneDrive - Northwestern University\\\\FA24\\\\303-1\\\\week2'\n\n\nThe os.listdir() function in Python returns a list of all files and directories in the specified path. If no path is provided, it returns the contents of the current working directory.\n\n\nCode\nos.listdir()\n\n\n['Environments.pptx',\n 'env_setup.html',\n 'Exercise1_Environment.ipynb',\n 'images',\n 'magic_shell_path_specification.ipynb',\n 'python-os-and-filesystem.ipynb',\n 'Setup_env.pdf',\n 'venv_setup.ipynb']\n\n\nCheck whether a specific folder/file exist in the current working directory\n\n\nCode\n'data' in os.listdir('.')\n\n\nFalse"
  },
  {
    "objectID": "NumPy.html#learning-objectives",
    "href": "NumPy.html#learning-objectives",
    "title": "6  NumPy",
    "section": "6.1 Learning Objectives",
    "text": "6.1 Learning Objectives\nBy the end of this lecture, students should be able to:\n\nUnderstand the basic structure and functionarlity of NumPy\nCreate and manipulate NumPy arrays.\nPerform mathematical and statistical operations on arrays.\nUtilize advanced concepts such as slicing, broadcasting, and vectorization.\nApply NumPy operations to real-world data science problems."
  }
]